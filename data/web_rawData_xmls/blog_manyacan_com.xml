<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
xmlns:content="http://purl.org/rss/1.0/modules/content/"
xmlns:dc="http://purl.org/dc/elements/1.1/"
xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
xmlns:atom="http://www.w3.org/2005/Atom"
xmlns:wfw="http://wellformedweb.org/CommentAPI/">
<channel>
<title>亚灿网志</title>
<link>https://blog.manyacan.com/</link>
<atom:link href="https://blog.manyacan.com/feed/" rel="self" type="application/rss+xml" />
<language>zh-CN</language>
<description>曼亚灿的个人博客</description>
<lastBuildDate>Tue, 16 Jan 2024 15:39:36 +0800</lastBuildDate>
<pubDate>Tue, 16 Jan 2024 15:39:36 +0800</pubDate>
<item>
<title>你好2023，那就再见吧~</title>
<link>https://blog.manyacan.com/archives/2045/</link>
<guid>https://blog.manyacan.com/archives/2045/</guid>
<pubDate>Wed, 13 Dec 2023 20:03:00 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[⏱️ 倒计时距离2024年元旦还有： #countdown-box { width: fit-content; margin: 10px auto; } #countdown-box>span ...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<h2 id="toc_0">⏱️ 倒计时</h2>距离<span style="font-size: 200%; font-weight:600">2024年元旦</span>还有：<style> #countdown-box { width: fit-content; margin: 10px auto; } #countdown-box>span { display: inline-block; width: 3em; height: 3em; background-color: #333; color: #fff; font-weight: 900; text-align: center; line-height: 3em; } #countdown-box strong { font-size: 150%; font-weight: 600; margin: 0 10px}</style><div id="countdown-box"><span class="day">00</span><strong>:</strong><span class="hour">00</span><strong>:</strong><span class="minute">00</span><strong>:</strong><span class="second">00</span></div><script> var countdown_box = document.querySelector("#countdown-box"); var day = countdown_box.querySelector(".day"); var hour = countdown_box.querySelector(".hour"); var minute = countdown_box.querySelector(".minute"); var second = countdown_box.querySelector(".second"); var inputTime = +new Date("2024-01-01 00:00:00"); countDown(); setInterval(countDown, 1000); function countDown() { var nowTime = +new Date(); var times = (inputTime - nowTime) / 1000; if (times > 0) { var d = parseInt(times / 60 / 60 / 24); day.innerHTML = d< 10 ? "0" + d : d; var h = parseInt(times / 60 / 60 % 24); hour.innerHTML = h< 10 ? "0" + h : h; var m = parseInt(times / 60 % 60); minute.innerHTML = m< 10 ? "0" + m : m; var s = parseInt(times % 60); second.innerHTML = s< 10 ? "0" + s : s; } }</script><hr><script>$(function(){$('.unselect-ele').attr('unselectable','on').css({'-moz-user-select':'-moz-none','-moz-user-select':'none','-o-user-select':'none','-khtml-user-select':'none','-webkit-user-select':'none','-ms-user-select':'none','user-select':'none'}).bind('selectstart',function(){return false;});var wrapperDivTopDis=$(".wrapper-2010").offset().top+$(".wrapper-2010").height(),createSpanTimer=setInterval(createSpan,50)
$(window).scroll(function(){if($(this).scrollTop()<=wrapperDivTopDis){if(!createSpanTimer)createSpanTimer=setInterval(createSpan,50)}
else{clearTimeout(createSpanTimer)
createSpanTimer=0}});var blessingWords=['新年快乐','福如东海','百事可乐','万事如意','全家福气','四季平安','寿比南山','神采奕奕','一帆风顺','顺理成章','章月句星','泰然自若','升官发财','财源广进','近水楼台','四海增辉','鹏程万里','生意兴隆','大吉大利','生意兴隆','大吉大利','家庭和睦','事业有成']
function createSpan(){let positionX=1+~~(Math.random()*$(".wrapper-2010").width()),positionY=1+~~(Math.random()*$(".wrapper-2010").height()),$i=$('<span class="unselect-ele"></span>').text(blessingWords[Math.floor(Math.random()*blessingWords.length)]);$i.css({"z-index":99999999999999,"top":positionY-20,"left":positionX,"position":"absolute","font-weight":"bold","color":'#'+('00000'+(Math.random()*0xffffff<<0).toString(16)).substr(-6)});$(".wrapper-2010").append($i);$i.animate({"top":positionY-700,"opacity":0},5000,function(){$i.remove()})}})
</script><style> .wrapper-2010 { background: #252854; height: 20rem; width: 100%; border-radius: 5px; position: relative; margin: 2rem auto; } .text-2010 { flex: 0 0 100%; font-size: 8rem; font-weight: 900; color: #00000000; text-align: center; font-family: 'Lato', sans-serif; position: absolute; left: 50%; top: 50%; transform: translate(-50%, -50%); border-bottom: 1px solid #d4d7ff; border-top: 1px solid #d4d7ff; background: url(https://image.manyacan.com/202211251726210.gif); background-clip: text; -webkit-background-clip: text; width: 100%; height: 80%; } .text-2010:after { content: attr(data-text); -webkit-text-stroke: 1.5px #d4d7ff; position: absolute; left: 50%; top: 50%; transform: translate(-50%, -49%); background: url(https://image.manyacan.com/202211251726210.gif); background-clip: text; -webkit-background-clip: text; background-size: 43%; width: max-content; }</style><div class="wrapper-2010 unselect-ele"><div class="text-2010" data-text="2024"></div></div><hr><h2 id="toc_1">1. 引</h2><p>2023年12月08日，皖A，天气不错，冬季慵懒的午后，是时候来写今年的年终总结了。</p><p><figure><img class="" alt="要降温了，冬天真的来啦~" data-src="https://image.manyacan.com/202312081457803.png-wms#vwid=1028&vhei=654" src="https://image.manyacan.com/202312081457803.png-wms#vwid=1028&vhei=654"><figcaption>要降温了，冬天真的来啦~</figcaption></figure></p><p>其实今年发生的大部分事都在<a href="https://blog.manyacan.com/archives/2042/">「你好 2023」</a>中叙述过了，但是作为每年的年终惯例，这个年度总结还是要来水一水的🤪。首先简单总结下今年的生活，忙碌且充实。真的是非常非常非常忙碌……</p><p><a href="https://blog.manyacan.com/archives/2042/">「你好 2023」</a>中采用了记流水账的方式回忆了今年前半年的生活，那么这篇年终总结就换个方式来写✍︎吧~</p><h2 id="toc_2">2. 保持身体健康永远是人生中权重最高的任务</h2><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312081505527.jpg-wms#vwid=600&vhei=300" src="https://image.manyacan.com/202312081505527.jpg-wms#vwid=600&vhei=300"></figure></p><p>2022年末，疫情放开，几乎身边所有人都感染了一遍新冠，不知道这是不是人类历史上最严重的一次疫情。</p><p>疫情放开的时候，因为家里一些事情，不得不每天需要接触很多人。在那一周的时间里，我一直处于反复感染的状态，晚上睡觉吃了药，早上醒来感觉似乎是好了，但是白天一出去接触冷空气就再次发烧。就这样反反复复持续了半个月左右。</p><p>在疫情之前，我一直对自己的身体特别自信，因为我几乎没有怎么吃过药。甚至一直到疫情，我都觉得凭我的身体条件很容易就可以扛过去。</p><p>今年算是彻底让现实打醒了我。</p><ul><li>五一前的一波流感，我中招了，我天真的以为凭我的身体条件扛扛就过去了。结果扛了三天实在是扛不过去，🐱🐱买的奥司他韦💊救了我一命。</li><li>七月份，一个周日的晚上我出去吃了烧烤，然后那晚还熬了夜，第二天早上起来就得了水痘成年版——疱疹，这个病折磨了我一个多月。</li><li>九月底在家，一个晚上从县城开车回家，路上开窗吹着秋风听着小歌儿，好不快活。结果，第二天就感冒发烧了，短短七天的假期又让我生病了一天。</li></ul><p>不到一年的时间里，我得到三次病，而且还有一次非常严重的。甚至医生都说，这个病就是免疫力低才会得，以前普遍出现在老年人群体中，而疫情之后很多年轻人也开始中招了。</p><p>回想这一年，确实自己因为毕业等一系列事情导致锻炼的机会很少，但是我觉得也不至于这么虚。可能最主要的原因还是由于新冠带给我的伤害。</p><p>从九月份开学开始，我就开始尽量在11点半之前睡觉，早上七点二十起床，养成一个规律的作息，并坚持锻炼身体。</p><p>希望自己能够早日恢复吧！！！🙏🙏🙏</p><h2 id="toc_3">3. 学习这件事，靠的是日积月累，不能急于求成</h2><p>哪位博导收了我，简直是太走运了（此时我的博导在办公室打了个喷嚏🫣）。我在学习上，有一个很大的缺点就是喜欢自我PUSH，你没有听错，这个世界上竟然会有人自我PUSH，我就是这样的性格。每次遇到什么工作，我总是回想把它尽力做到最好。就是在这样的心态影响下，每次有什么工作，我总是想一口气把它干完。</p><p><figure><img class="" alt="博士入学前学习规划" data-src="https://image.manyacan.com/202312171018432.webp-wms#vwid=4233&vhei=2608" src="https://image.manyacan.com/202312171018432.webp-wms#vwid=4233&vhei=2608"><figcaption>博士入学前学习规划</figcaption></figure></p><p>这样的心态很不好，在今年我有了非常深的体会。今年是比较特殊的一年，上半年忙着预答辩、盲审、毕业的事；毕业后又无缝衔接开始博士阶段的工作。我总告诉自己，赶紧办这件事办完，你就可以休息了。</p><p>这样的心态，不仅让我所做当下事的质量大大下降，也让我养成了经常PUSH自己的习惯。仔细回想下，今年的多次生病，其实就是由于经常性的自我PUSH，导致晚上休息不好，再加上缺乏锻炼所导致。</p><p>六月刚刚过来的时候，因为博导给我定了课题，而我自己对这个全新的知识领域是一片未知，那段时间就有点急于求成了。总想着赶快把基础知识学完，开始自己的课题研究。然而，越是这样的心态，越是反而学得不扎实，还让自己过的很累。</p><p>十一月从大连回来，开始了重庆项目的线上部署（<a href="https://blog.manyacan.com/archives/2046/">Python程序设计——供水调度项目总结</a>），那段时间程序暴露出很多以前没有遇到的问题。那段时间，我甚至听到微信消息都心里惊一下——甲方又来反馈BUG了。每次遇到BUG，我总是抱着不解决它就不干别的事的决心。这也是自我PUSH的表现。事实也向我证明了这样的做法是不行的，非但不能解决问题，反而会让自己钻牛角尖，深陷其中。</p><p>遇到BUG不要慌，下去散散步、烧烧香，回来接着干！</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202312131925899.png-wms#vwid=467&vhei=454" src="https://image.manyacan.com/202312131925899.png-wms#vwid=467&vhei=454"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202312251452883.png-wms#vwid=500&vhei=845" src="https://image.manyacan.com/202312251452883.png-wms#vwid=500&vhei=845"></figure></div><p>综上所述，接下来的工作中，我决定改掉自己的这个坏毛病，以后要杜绝自我PUSH，慢才是快！！！</p><h2 id="toc_4">4. 车轮不息</h2><p>今年买了人生第三辆单车，每周周末抽出一天和工作日晚上抽出1~2晚出去骑骑车，放松下心情。</p><p>🚵‍♂️身体才是革命的本钱！！！💪💪💪</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202312171950190.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202312171950190.jpg-wms#vwid=960&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202312171950940.jpg-wms#vwid=1706&vhei=1280" src="https://image.manyacan.com/202312171950940.jpg-wms#vwid=1706&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202312171952544.jpg-wms#vwid=1080&vhei=2316" src="https://image.manyacan.com/202312171952544.jpg-wms#vwid=1080&vhei=2316"></figure></div><h2 id="toc_5">5. 潘总的婚礼</h2><p>2023年10月2号，终于等到了潘总的婚礼。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202310040918582.webp-wms#vwid=1568&vhei=253" src="https://image.manyacan.com/202310040918582.webp-wms#vwid=1568&vhei=253"></figure></p><p>作为安理大自由社成员中第一个结婚的，潘总表示这都是小场面。</p><p>毕业三年，疫情三年。我们几个大学玩儿的好的三年都没有聚齐过了，要不是潘总结婚，可能还要再往后推推了。</p><p>时间可真是快啊~</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312172012106.webp-wms#vwid=853&vhei=640" src="https://image.manyacan.com/202312172012106.webp-wms#vwid=853&vhei=640"></figure></p><p>大学四年，可真是这辈子最无忧无虑的四年了。</p><p>会想起我们从大学到现在，七八年的时间也算是一起见证了大家的成长。</p><p>啥也不说了，祝金寨潘总新婚快乐！！！</p><blockquote><p>YH那天因为一些很特殊的事情没能去成。加油，都会过去的，努力好好撑起这个家吧！！！</p></blockquote><hr><p>就补充这么多吧~</p><p>目前看来，今年的生活惊险刺激，还算可以。</p><p>自己学到了很多，也成长了很多。</p><p>认识了很多新朋友，老朋友们也都苟活得还行。</p><p>那么，就好好享受接下来的四年生活吧！加油，曼亚灿！</p>
]]></content:encoded>
<slash:comments>14</slash:comments>
<comments>https://blog.manyacan.com/archives/2045/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2045/</wfw:commentRss>
</item>
<item>
<title>你好 2023</title>
<link>https://blog.manyacan.com/archives/2042/</link>
<guid>https://blog.manyacan.com/archives/2042/</guid>
<pubDate>Sun, 13 Aug 2023 13:05:00 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[引新建这个Markdown文件的时间是2023年08月12日：2023年已经度过了66%，时间真的是太快了。原本打算6月份写今年的年终报告，竟然拖到了现在。最近这段时间确实有点忙。那就趁这个周末...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<h2 id="toc_6">引</h2><p>新建这个<code>Markdown</code>文件的时间是2023年08月12日：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308121135984.png-wms#vwid=519&vhei=292" src="https://image.manyacan.com/202308121135984.png-wms#vwid=519&vhei=292"></figure></p><p>2023年已经度过了66%，时间真的是太快了。</p><p>原本打算6月份写今年的年终报告，竟然拖到了现在。最近这段时间确实有点忙。</p><p>那就趁这个周末，来记录下今年的生活吧。</p><h2 id="toc_7">毕业论文预答辩&博士申请材料准备</h2><p>2023年的农历寒假，发生了很多事。具体都记录在了<a href="https://blog.manyacan.com/archives/2022/">2023农历新年纪实</a>。过完年学校通知3月20号就要进行毕业论文预答辩，因此时间非常紧张，过完年的那几天白天基本都是在疯狂肝论文。</p><p>回到学校之后，每天的任务也都是疯狂改论文。其中，我的论文还在预答辩的前一个星期被导师指出结构上的问题，进行了大篇幅的修改。那几天，差点要了我的小命。</p><p>那个时候的我还要准备申请博士的材料，这些东西虽然不怎么需要动脑子，但是却十分麻烦。光是找学校各个部门盖章，有时候都要去四五次才能找到负责人给盖章。学校里面搞行政的，都一个个跟大爷似的。</p><p>不过幸好都在最后时刻准备好了。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308121312186.jpg-wms#vwid=1706&vhei=1280" src="https://image.manyacan.com/202308121312186.jpg-wms#vwid=1706&vhei=1280"></figure></p><p>预答辩的前一晚，我们几个还是老老实实自己组织去1601办公室进行了一遍预演。</p><p>关于毕业这件事，其实大家都是很上心的！！！</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308121314053.jpg-wms#vwid=1920&vhei=895" src="https://image.manyacan.com/202308121314053.jpg-wms#vwid=1920&vhei=895"></figure></p><p>答辩那天，大家也算是有惊无险，顺顺利利通过。感恩各位答辩专家！！！</p><p>那天晚上跟孝林还有他小舅子一起去翡翠湖大学城吃了饭，感觉自己毕业有望！！！</p><div class="photos large"><figure><img class="" alt="草莓熊最近为什么这么火" data-src="https://image.manyacan.com/202308121317490.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308121317490.jpg-wms#vwid=960&vhei=1280"><figcaption>草莓熊最近为什么这么火</figcaption></figure><figure><img class="" alt="萧县烤全羊YYDS" data-src="https://image.manyacan.com/202308121317204.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308121317204.jpg-wms#vwid=960&vhei=1280"><figcaption>萧县烤全羊YYDS</figcaption></figure></div><p>我记得当时工大的报名材料提交时间是截至到3月1日，2月28号当天我才把材料准备好，慌慌张张打车到工大，然后麻烦我的H同学将材料送到办公室。</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202308121320813.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308121320813.jpg-wms#vwid=960&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308122243804.jpg-wms#vwid=895&vhei=1920" src="https://image.manyacan.com/202308122243804.jpg-wms#vwid=895&vhei=1920"></figure></div><p>当时其实并不太想来工大。因为我已经在安徽待了好多年了（本硕4+3），实在是不想在这里了。合肥这个地方，没有什么能吸引外地人的，再加上劝退的房价，实在是很难让我这一个外省的人爱上这座城市。</p><p>直到——3月8号，那天S老师约我来工大和Z老师还有她见一面。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308122248952.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308122248952.jpg-wms#vwid=960&vhei=1280"></figure></p><p>虽然来之前还不是很想来工大，但是毕竟是和博导见面，所以还是提前准备了下。</p><p>见面那天S老师去参加妇女节活动了。所以，我就先和Z老师见了面，Z老师给我的第一印象就是情商、智商都很高，讲话很有逻辑，特别是谈到一些专业话题时，讲话非常能抓住重点，而且条理清晰。这就是我对Z老师的第一印象——就是厉害（虽然回去看了老师的简历，才发现Z老师是真的厉害）。</p><p>再跟Z老师谈话结束后，S老师那边活动也结束了，然后就和两位老师一起聊了聊，给我的感觉就是两位老师都是非常体贴学生的老师，而且愿意倾听学生。“体贴”、“倾听”，简简单单两个词，但是能做到的老师，其实并不多。</p><p>那天回去的路上，我心里的想法就改变了，我想要来工大。虽然我不是很喜欢合肥，工大也是一个近几年一直在走下坡路的学校，但是两位老师确实给了我非常好的印象，我太需要这样的老师了。</p><p>对于我来说，老师的重要性远远大于学校。</p><p>人生最有意思的一件事就是，每次站在人生十字路口的那种未知性，你永远不能确定你明天的下一步会发生什么，这本身就是一种会让你着迷的期待。</p><p>就像读大学前，我从来不知道河南的东部有一个叫做安徽的省份；考研一志愿复试被刷之前，我也不知道有建大这个学校；而今年的3月8号之前，我也从来没有想过我会来工大读博。</p><h2 id="toc_8">博士申请复试</h2><p>4月11日学校官网发出通知，将在两天后举行复试综合考核。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131034260.png-wms#vwid=750&vhei=835" src="https://image.manyacan.com/202308131034260.png-wms#vwid=750&vhei=835"></figure></p><p>赶紧来吧！太煎熬了这段时间！这就是我当时的想法。</p><p>由于提前Z老师已经帮我看了很多遍的PPT，所以面试还是比较有信心的。自己提前也练了好多遍了，所以面试当天我觉得表现的还行。</p><h2 id="toc_9">室友的婚礼</h2><p>4月28号，前往池州参加大学室友G的婚礼。室友G大学毕业进了某中字头施工单位，干了俩月不到就跑路开始考公，现在在家附近的小公司找了个工作。</p><div class="photos large"><figure><img class="" alt="到达池州站" data-src="https://image.manyacan.com/202308131004940.jpg-wms#vwid=1080&vhei=1920" src="https://image.manyacan.com/202308131004940.jpg-wms#vwid=1080&vhei=1920"><figcaption>到达池州站</figcaption></figure><figure><img class="" alt="还是读大学时侯的大裤衩" data-src="https://image.manyacan.com/202308131005111.jpg-wms#vwid=1080&vhei=1920" src="https://image.manyacan.com/202308131005111.jpg-wms#vwid=1080&vhei=1920"><figcaption>还是读大学时侯的大裤衩</figcaption></figure><figure><img class="" alt="室友的新房" data-src="https://image.manyacan.com/202308131005599.jpg-wms#vwid=1920&vhei=1080" src="https://image.manyacan.com/202308131005599.jpg-wms#vwid=1920&vhei=1080"><figcaption>室友的新房</figcaption></figure></div><p>截止到目前为止，我身边结婚的同龄人全是两个人都在家工作，然后家里也有一定的经济基础。我们这代人其实有点讽刺，所有人都告诉我们高考可以改变命运。但是，现在回头看看，我的那些读个大专就毕业回家的很多高中同学的生活幸福指数要远远高于我那些超过一本线的大学同学。</p><p>想靠读书改变命运，我只能说越来越难哇~</p><p>那个大学时天天打游戏到凌晨的傻瓜娃子都要成家了，时间真是快啊！</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131011234.jpg-wms#vwid=1080&vhei=1920" src="https://image.manyacan.com/202308131011234.jpg-wms#vwid=1080&vhei=1920"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131011811.jpg-wms#vwid=3520&vhei=1980" src="https://image.manyacan.com/202308131011811.jpg-wms#vwid=3520&vhei=1980"></figure></div><p>祝G新婚快乐！🎆🎆🎆百年好合！👰‍♀🤵还有，早生贵子（替他爸妈催一下）😁😁😁！</p><p>池州地区的婚礼习俗与北方不太一样，当天晚上才举行婚宴。因此，下午的时候我和SD在池州逛了逛。</p><div class="photos large"><figure><img class="" alt="长江边" data-src="https://image.manyacan.com/202308131441902.jpg-wms#vwid=1706&vhei=1280" src="https://image.manyacan.com/202308131441902.jpg-wms#vwid=1706&vhei=1280"><figcaption>长江边</figcaption></figure><figure><img class="" alt="太平湖" data-src="https://image.manyacan.com/202308131441084.jpg-wms#vwid=1920&vhei=1080" src="https://image.manyacan.com/202308131441084.jpg-wms#vwid=1920&vhei=1080"><figcaption>太平湖</figcaption></figure></div><p>池州的自然资源太好了，市区的太平湖风景特别好，最重要的是可以开车进，我和蛋总围着湖绕了一圈，感觉心情都变好了。</p><p>当天婚礼结束后，我就匆匆返回合肥。因为我们的小分队要在合肥集合，开始我们的五一活动。</p><h2 id="toc_10">五一</h2><p>30号那天，P总对象也来了合肥。由于这是我们毕业第一次聚这么齐（只差了福建三明的Q总），而且是跟未来的嫂子见面，所以大家都非常“正式”地在庐州太太吃了顿饭。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131016688.jpg-wms#vwid=1920&vhei=1080" src="https://image.manyacan.com/202308131016688.jpg-wms#vwid=1920&vhei=1080"></figure></p><p>当时我们还说P总再有小半年就要结婚了，感觉还有挺长的时间。</p><p>但是今天一看，就只剩下不到两个月了。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131019235.png-wms#vwid=1047&vhei=664" src="https://image.manyacan.com/202308131019235.png-wms#vwid=1047&vhei=664"></figure></p><p>这个由我亲手设计（照抄）的Web倒计时页面，还真挺有用😛。</p><p>饭后P总带着老婆回六安，我们几个开始转战滁州。路上大家还在说，这以后一结婚，P总就不是我们的人啦~🥴</p><div class="photos large"><figure><img class="" alt="转战滁州" data-src="https://image.manyacan.com/202308131023150.jpg-wms#vwid=1080&vhei=2316" src="https://image.manyacan.com/202308131023150.jpg-wms#vwid=1080&vhei=2316"><figcaption>转战滁州</figcaption></figure><figure><img class="" alt="王总项目部" data-src="https://image.manyacan.com/202308131025215.jpg-wms#vwid=1920&vhei=1080" src="https://image.manyacan.com/202308131025215.jpg-wms#vwid=1920&vhei=1080"><figcaption>王总项目部</figcaption></figure><figure><img class="" alt="小趴菜河北崔总" data-src="https://image.manyacan.com/202308131025422.jpg-wms#vwid=1080&vhei=1920" src="https://image.manyacan.com/202308131025422.jpg-wms#vwid=1080&vhei=1920"><figcaption>小趴菜河北崔总</figcaption></figure></div><p>到了滁州，就是王总的天下了，自然把我们安排的妥妥当当。</p><p>应该是第二天晚上吧，吃饭的时候大家喝了不少白酒。回到酒店之后，K某人竟然说睡不着，还需要再使用啤酒来润润嗓，为了满足他的需求，我们又举行了二场。</p><p>结果一下就干到了凌晨三点半，那晚，大家都醉了。</p><p>毕业三年，疫情三年，太不容易了。大家第一次聚得这么齐。</p><p>五一当天，本来打算转战南京，然后C和W就从南京出发回济南。但是，我们竟然在高速上爆胎了。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131028341.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308131028341.jpg-wms#vwid=960&vhei=1280"></figure></p><p>奇奇怪怪的人生经历又增加了。幸亏是后胎，当时车辆并没有发生侧滑和失控，也算是不幸中的万幸了。</p><p>花💸钱💰️破灾吧。</p><p>最离谱的是，我的毕业论文盲审结果终于在5月1日当天返回：</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131038600.jpg-wms#vwid=820&vhei=272" src="https://image.manyacan.com/202308131038600.jpg-wms#vwid=820&vhei=272"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131038929.jpg-wms#vwid=1633&vhei=661" src="https://image.manyacan.com/202308131038929.jpg-wms#vwid=1633&vhei=661"></figure></div><p>可恶啊！我们整个学院大部分同学的盲审结果都在五一放假前就出来了，只有我们十个人左右的结果拖到了五一当天早上才出来，严重影响了我们放假的心情。💢💢💢</p><p>不过只要过了，干啥都好，嘿嘿嘿~</p><h2 id="toc_11">毕业</h2><p>毕业答辩那天，还是稍微有一点激动的~</p><p>答辩结束后，突然下起了大暴雨，冲刷后的天空，看起来格外透亮。</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131102322.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308131102322.jpg-wms#vwid=960&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131102653.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308131102653.jpg-wms#vwid=960&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131101390.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308131101390.jpg-wms#vwid=960&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131113502.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308131113502.jpg-wms#vwid=960&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131115856.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308131115856.jpg-wms#vwid=960&vhei=1280"></figure></div><p>那天晚上，X同学喝多了~</p><p>之后就是收拾东西准备拍屁股走人了，由于我需要无缝衔接直接去工大，所以就叫了一个货拉拉，直接把东西带到了工大。</p><p>千言万语，祝大家毕业🎓快乐🥰🥰🥰吧！</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131215322.webp-wm04#vwid=8000&vhei=1900" src="https://image.manyacan.com/202308131215322.webp-wm04#vwid=8000&vhei=1900"></figure></p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131215323.webp-wm04#vwid=11500&vhei=1900" src="https://image.manyacan.com/202308131215323.webp-wm04#vwid=11500&vhei=1900"></figure></p><p>三年时光，真到了要说再见的时候，内心其实还是挺释然的。</p><p>三年，真不容易哇~</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131115153.jpg-wms#vwid=1706&vhei=1280" src="https://image.manyacan.com/202308131115153.jpg-wms#vwid=1706&vhei=1280"></figure></p><h2 id="toc_12">新的生活</h2><p>在六月初的时候，我就搬到工大这边开始了自己的新生活。</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131113643.jpg-wms#vwid=1024&vhei=682" src="https://image.manyacan.com/202308131113643.jpg-wms#vwid=1024&vhei=682"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131115966.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308131115966.jpg-wms#vwid=960&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131113578.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308131113578.jpg-wms#vwid=960&vhei=1280"></figure></div><p>怎么说呢，虽然对学校不是很满意，也没有啥喜欢的。但是我自己是觉得导师比学校更重要的，所以来了也并不后悔。希望毕业的时候，我也并不后悔放弃河海😭😭😭。</p><p>七月底的时候，我终于拿到了自己的录取通知书。人生第一次上门自提录取通知书，长见识了~</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131302645.webp-wms#vwid=1706&vhei=1280" src="https://image.manyacan.com/202308131302645.webp-wms#vwid=1706&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131114783.jpg-wms#vwid=1280&vhei=2058" src="https://image.manyacan.com/202308131114783.jpg-wms#vwid=1280&vhei=2058"></figure></div><p>七月，在博导的资助下，还让我体验到了4080的快乐。瞬间感觉我的3060是不是要退休了。</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131114495.jpg-wms#vwid=990&vhei=610" src="https://image.manyacan.com/202308131114495.jpg-wms#vwid=990&vhei=610"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131114449.jpg-wms#vwid=1706&vhei=1280" src="https://image.manyacan.com/202308131114449.jpg-wms#vwid=1706&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131114174.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308131114174.jpg-wms#vwid=960&vhei=1280"></figure></div><p>经过我的实际对比，4080跑CNN要比3060快2.5~3.5倍，这个速度还是让我感到吃惊的。因此，最近这段时间我也开始逐渐慢慢开始在办公室办公。啥也不要问，问就是为了💦💦💦好好学习✊️✊️✊️！！！</p><p>不是你3060不够优秀，只是哥的眼光变高了！！！🤣🤣🤣</p><div class="photos large"><figure><img class="" alt="有4080之前" data-src="https://image.manyacan.com/202308131113423.jpg-wms#vwid=1706&vhei=1280" src="https://image.manyacan.com/202308131113423.jpg-wms#vwid=1706&vhei=1280"><figcaption>有4080之前</figcaption></figure><figure><img class="" alt="有了4080之后" data-src="https://image.manyacan.com/202308131233925.jpg-wms#vwid=4000&vhei=3000" src="https://image.manyacan.com/202308131233925.jpg-wms#vwid=4000&vhei=3000"><figcaption>有了4080之后</figcaption></figure></div><h2 id="toc_13">生病了</h2><p>应该是07月16号周日，晚上几个硕士同学聚餐。其实那天晚上的烧烤挺好吃的，晚上回去之后又因为什么原因然后加了个班，睡觉的时候有点晚，大概凌晨1点一刻。</p><p>第二天早上起来，嘴角上就有几个透明的水泡，当时自己感觉可能是上火了？然后也没有太在意。</p><p>结果到了晚上的时候发现不但没有好转，水泡还有蔓延的趋势。于是乎我就想着去药店买点药，那个医生可真是坑人哇！他也不懂，说应该是上火了，就给我了几盒去火的药。结果第二天早上醒来发现，更加严重了。那几天好像挺多事儿的，然后我就自己在网上查了查，发现应该是水痘-疱疹病毒感染，然后就在网上买了点药。</p><p>本以为对症下药就好了，我还是太轻视疾病了。没想到这个病这么难缠，周五的时候，水痘基本已经结痂，我想这还是到医院去看下医生，然后医生开了一大堆药。我当时还觉得有必要开这么多药吗？都感觉已经好转了。</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131115680.jpg-wms#vwid=1080&vhei=1920" src="https://image.manyacan.com/202308131115680.jpg-wms#vwid=1080&vhei=1920"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131115341.jpg-wms#vwid=960&vhei=1280" src="https://image.manyacan.com/202308131115341.jpg-wms#vwid=960&vhei=1280"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202308131114844.jpg-wms#vwid=1080&vhei=1920" src="https://image.manyacan.com/202308131114844.jpg-wms#vwid=1080&vhei=1920"></figure></div><p>没想到这个病竟然还有后遗症，一直到今天，我还在吃药。每天早上醒的时候，左脸还会特别痒。医生说这个是神经痛的后遗症。唉，生病太难受了。</p><p>上一年经历新冠的时候，奶奶刚刚去世，所以那几天家里很多事。我那几天一直处于反复感染的状态，也没有休息好，每天晚上都要守到凌晨。每天都是晚上睡觉的时候吃药，早上起来感觉好一点了，但是白天只要一出去，就感觉又发烧了。新冠对于我身体的免疫系统造成了很严重的损害。因为，今年以来我已经大病小病吃了四次💊药💊了。我本硕七年加起来都没有吃过这么多次💊药💊。</p><p>这次的生病，也算是我的身体给我的一个⚠︎警告🚨。以后一定要多多锻炼、不熬夜。不然的话，在这里定个目标吧！</p><ul><li>[ ] 每周至少跑步两次（每次5 km）；</li><li>[ ] 晚上十一点半之前睡觉！！！</li></ul><h2 id="toc_14">总结</h2><p>今年的生活，非常惊险刺激——预答辩、博士申请考核、论文盲审、毕业答辩等等等。进入了新的环境，目前来说，还是非常满意的。那么，接下来自己就好好努力吧！</p>
]]></content:encoded>
<slash:comments>24</slash:comments>
<comments>https://blog.manyacan.com/archives/2042/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2042/</wfw:commentRss>
</item>
<item>
<title>Hello World, GNN</title>
<link>https://blog.manyacan.com/archives/2047/</link>
<guid>https://blog.manyacan.com/archives/2047/</guid>
<pubDate>Tue, 16 Jan 2024 15:39:36 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[引本篇博客介绍一个入门图神经网络（Graph Neural Network, GNN）的例子。严格来说，使用到的技术为图卷积神经网络（Graph Convolution Neural Netwo...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<h2 id="toc_15">引</h2><p>本篇博客介绍一个入门图神经网络（Graph Neural Network, GNN）的例子。严格来说，使用到的技术为图卷积神经网络（Graph Convolution Neural Network, GCN），看名字也就知道它是在卷积神经网络（Convolution Neural Network, CCN）的基础上改进而来。这里先做一个剧透：</p><blockquote><p>GCN就是在CNN的过程中加上一个图结构——邻接矩阵（Adjacency Matrix）。</p></blockquote><p>如果你已经对传统CNN结构有非常熟悉的了解，那么你可以非常轻松地看懂本篇博客。如果您对CNN和PyTorch还不够熟悉，可以先来看看我的其他博客：</p><ul><li><a href="https://blog.manyacan.com/archives/2040/">「卷积神经网络」深入浅出</a></li><li><a href="https://blog.manyacan.com/archives/2038/">「Deep Learning」PyTorch初步认识</a></li></ul><p>关于图论（Graph Theory, GT）部分的知识，只会涉及到邻接矩阵，下文我会单独再进行讲解，如果你对GT感兴趣，可以参考我的这篇博客：</p><ul><li><a href="https://blog.manyacan.com/archives/2044/">图论入门——从基础概念到NetworkX</a></li></ul><h2 id="toc_16">案例介绍</h2><p>本案例来自<a href="https://book.douban.com/subject/35695496/">《PyTorch深度学习和图神经网络（卷1）》</a>，算是我自己的学习小总结，我在书本附带代码的基础上又进行了一定的优化。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202401160836726.png-wms#vwid=697&vhei=271" src="https://image.manyacan.com/202401160836726.png-wms#vwid=697&vhei=271"></figure></p><p>本案例的内容呢，主要是利用论文间的相互引用关系，设计一个GCN网络进行论文分类。具体的数据结构与内容会在下文详细介绍。</p><h2 id="toc_17">代码实战</h2><h3 id="toc_18">1. 引包</h3><pre><code class="lang-python">import hues
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from torch import nn
from pathlib import Path
from prettytable import PrettyTable
from torch.nn import functional as nn_fun
from scipy.sparse import coo_matrix, csr_matrix, diags, eye</code></pre><p>Python第一步，引包最重要。上面所用到包的主要作用大概是：</p><ol><li><strong><code>hues</code></strong>: <code>hues</code> 是一个Python库，用于在终端输出中添加颜色和样式。它可以用于美化控制台输出，使得调试和呈现数据更加直观和易于理解。</li><li><p><strong><code>torch</code></strong> 和 <strong><code>from torch import nn</code></strong>: <code>torch</code> 是PyTorch框架的核心，一个流行的深度学习库，广泛用于机器学习和人工智能领域。它提供了丰富的张量操作，与NumPy兼容但具有更强大的GPU加速支持。</p><ul><li><code>from torch import nn</code> 导入了PyTorch的神经网络模块。这个模块包含了构建深度学习模型所需的各种层、损失函数等组件。</li></ul></li><li><strong><code>numpy</code></strong>: <code>numpy</code> 是Python中用于科学计算的核心库。它提供了一个强大的N维数组对象、广泛的数学函数操作，以及用于线性代数、傅里叶变换和随机数生成的工具。</li><li><strong><code>pandas</code></strong>: <code>pandas</code> 是Python中用于数据处理和分析的库。它提供了DataFrame和Series这两种主要的数据结构，适用于处理时间序列和非时间序列数据，非常适合于数据清洗、分析和可视化。</li><li><strong><code>matplotlib.pyplot</code></strong>: <code>matplotlib.pyplot</code> 是一个绘图库，用于Python和其数值计算库NumPy。它提供了一种类似于MATLAB的绘图界面，用于生成各种静态、动画以及交云的图表。</li><li><strong><code>from pathlib import Path</code></strong>: <code>Path</code> 来自<code>pathlib</code>模块，它提供了面向对象的文件系统路径处理方法。使用<code>Path</code>可以以更直观和安全的方式操作文件系统路径，比传统的字符串路径操作更加灵活和易用。</li><li><strong><code>from prettytable import PrettyTable</code></strong>: <code>PrettyTable</code> 是一个简单的Python库，用于从数据中创建漂云的ASCII表格。这非常适合在命令行应用中格式化和呈现数据。</li><li><strong><code>from torch.nn import functional as nn_fun</code></strong>: <code>torch.nn.functional</code> 包含了神经网络中使用的各种函数，如激活函数、损失函数等，通常与<code>nn</code>模块中的类接口结合使用。</li><li><p><strong><code>scipy.sparse</code> 相关函数</strong>: <code>from scipy.sparse import coo_matrix, csr_matrix, diags, eye</code> 导入了SciPy库中的稀疏矩阵相关功能。</p><ul><li><code>coo_matrix</code>：一种稀疏矩阵表示方式，使用三个NumPy数组（行坐标、列坐标、数据值）存储非零元素。</li><li><code>csr_matrix</code>：另一种稀疏矩阵表示方式，使用行索引、列索引和数据值数组，适合高效的算术运算和矩阵向量积。</li><li><code>diags</code>：用于创建对角矩阵的函数。</li><li><code>eye</code>：创建一个单位矩阵（主对角线上为1，其余为0的方阵）。</li></ul></li></ol><h3 id="toc_19">2. 查看&定义计算设备</h3><p>基于PyTorch的深度学习可以在CPU或者GPU上运行，如果你已经成功安装对应版本的CUDA，俺么就可以使用GPU来加速运行：</p><pre><code class="lang-python">#输出运算资源请况
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
print(device)</code></pre><blockquote><p>输出<code>cuda</code>，说明本环境中已经成功安装GPU版本的PyTorch。</p></blockquote><h3 id="toc_20">3. 读取数据并进行数据预处理</h3><h4 id="toc_21">特征与标签矩阵</h4><p>定义文件存放文件夹路径：</p><pre><code class="lang-python">path = Path('..\..\pytorch-GNN-1st-main\pytorch-GNN-1st-main\data\第9章28\第9章28\cora')</code></pre><p>需要读取到的数据文件有两个：</p><ul><li><code>cora.content</code>: 这个文件中的数据矩阵大小为(2708, 1435)，其中每一行为一个样本——即一篇论文，第一列为论文编号，最后一列为该论文的分类，中间列为经过编码的文章关键字，具体结构如下图所示。</li></ul><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202401160901152.jpg-wms#vwid=926&vhei=477" src="https://image.manyacan.com/202401160901152.jpg-wms#vwid=926&vhei=477"></figure></p><pre><code class="lang-python">#读取论文内容数据，并将其转化为数组
paper_features_label = np.genfromtxt(path / 'cora.content', dtype=np.str_)
print(paper_features_label.shape)
paper_features_label</code></pre><p>对<code>paper_features_label</code>，首先要进行拆分，第一列论文ID为不连续的整数，需要进行重命名编号：</p><pre><code class="lang-python">#取出数据的第一列：论文的ID
papers = paper_features_label[:, 0].astype(np.int32)
#为论文重新编号，{31336: 0, 1061127: 1,……
paper_id = {k: v for v, k in enumerate(papers)}
paper_id</code></pre><p><code>paper_id</code>即为经过重编号的论文ID。</p><p>将中间部分的文字编码取出，作为特征矩阵：</p><pre><code class="lang-python">#将数据中间部分的字标签取出，转化成(稀疏)矩阵
features = csr_matrix(paper_features_label[:, 1:-1], dtype=np.float32)
print(np.shape(features))
# 将稀疏矩阵转化为稠密矩阵
features.todense()</code></pre><p>对最后一列的标签进行编码处理：</p><pre><code class="lang-python">#将最后一项的论文分类属性取出，并转化为分类索引
labels = paper_features_label[:, -1]
lbl2idx = {k: v for v, k in enumerate(sorted(np.unique(labels)))}
labels = [lbl2idx[e] for e in labels]
print(lbl2idx, labels[:5])</code></pre><h4 id="toc_22">关系矩阵</h4><p>另一个数据文件为<code>cora.cites</code>：</p><pre><code class="lang-python">#读取论文关系数据，并将其转化为数组
edges = np.genfromtxt(path / 'cora.cites', dtype=np.int32)
print(np.shape(edges))
edges</code></pre><p>这个文件中矩阵的大小为(5429, 2)，每一行代表一个引用关系。例如：第一行表示ID为35的论文引用了ID为1033的论文。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202401160915642.png-wms#vwid=1193&vhei=731" src="https://image.manyacan.com/202401160915642.png-wms#vwid=1193&vhei=731"></figure></p><p>因为上面在处理特征与标签矩阵的过程中，我们对论文ID进行了重排序。因此，在这里我们需要对此矩阵中的论文ID也进行重排序。</p><pre><code class="lang-python">#转化为新编号节点间的关系
edges = np.asarray([paper_id[e] for e in edges.flatten()], np.int32).reshape(edges.shape)
print(edges.shape)
edges</code></pre><p>根据边关系构建邻接矩阵：</p><pre><code class="lang-python"># 计算邻接矩阵(Adjacency matrix), 行列都为论文个数.
adj = coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),
                 shape=(len(labels), len(labels)), dtype=np.float32)

adj.todense()</code></pre><p>这里需要注意的是，上面所构建的邻接矩阵为有向图邻接矩阵，而在论文的引用关系中，我们并不需要有向连接。例如：论文A引用了论文B或者是论文B引用了论文A，只要其两者间存在引用就说明这两篇论文存在一定的相似性。</p><p>由此就产生了一个问题：如何将有向图的邻接矩阵转换为无向图的邻接矩阵？这里请看我下面总结的一张图：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202401161057825.png-wms#vwid=2879&vhei=1619" src="https://image.manyacan.com/202401161057825.png-wms#vwid=2879&vhei=1619"></figure></p><p>第一眼看上去好像很难，但是只要你自己画出来图结构，然后手推一遍就可以非常深刻地理解了。</p><p>理解了上图，就可以按照数学公式很方便地进行运算了：</p><pre><code class="lang-python"># 有向图邻接矩阵转化为无向图对称矩阵
adj_long = adj.multiply(adj.T &lt; adj)
adj = adj_long + adj_long.T</code></pre><p>至此，其实我们已经完成了所有的数据准备工作，得到了GCN模型输入的所有内容：</p><ul><li>一个无向图邻接矩阵<code>adj</code>；</li><li>一个数据特征矩阵<code>features</code>；</li><li>一个标签矩阵（向量）：<code>labels</code>.</li></ul><p>但是有一点需要注意，就是我们仍需要对输入特征矩阵和邻接矩阵进行归一化处理，原因主要包括以下几点：</p><ol><li><strong>防止梯度消失或爆炸</strong>：在深度学习模型中，特别是在使用多层网络时，未经归一化的数据可能导致梯度消失或爆炸。归一化可以帮助缓解这个问题，因为它保证了数据在各个维度上的尺度大致相同。</li><li><strong>保持特征尺度一致性</strong>：在GCN中，节点特征和结构特征（即通过邻接矩阵表示的）是同等重要的。归一化确保这些不同类型的数据在尺度上保持一致，避免了某一类型的数据在模型训练过程中占据主导地位。</li><li><strong>增强模型的稳定性和收敛速度</strong>：归一化处理有助于提高模型的数值稳定性，并可以加快模型的收敛速度。当数据在一个较小的范围内变化时，优化算法（如梯度下降）更容易找到最优解。</li><li><strong>邻接矩阵的特殊性</strong>：在GCN中，邻接矩阵用于传播节点特征，从而捕获图结构。如果不进行归一化，节点的特征可能会因为节点的度（即连接的边数）而被放大或缩小，这可能导致信息传播不均衡。通过归一化（例如使用度矩阵的逆平方根），可以保证每个节点的贡献被适当地标准化，从而使特征传播更加有效和平衡。</li></ol><p>构造一个对矩阵进行归一化的函数，并对特征矩阵和邻接矩阵进行归一化处理：</p><pre><code class="lang-python">def normalize(mx):  #定义函数，对矩阵数据进行归一化
    '''Row-normalize sparse matrix'''
    rowsum = np.array(mx.sum(1))  #每一篇论文的字数
    r_inv = (rowsum ** -1).flatten()  #取总字数的倒数
    r_inv[np.isinf(r_inv)] = 0.  #将Nan值设为0(防止某一行全为0, 即对应的rowsum为0, r_inv就为)
    r_mat_inv = diags(r_inv)  #将总字数的倒数做成对角矩阵
    mx = r_mat_inv.dot(mx)  #左乘一个矩阵，相当于每个元素除以总数
    return mx


#对 features矩阵进行归一化（每行的总和为1）
features = normalize(features)

# 对邻接矩阵对角线添加1，将其变为自循环图。同时再对其进行归一化
adj = normalize(adj + eye(adj.shape[0]))</code></pre><h3 id="toc_23">4. 数据集划分及转移</h3><p>首先要将Numpy格式的数据转化为Tensor格式：</p><pre><code class="lang-python"># Data as tensors
adj = torch.FloatTensor(adj.todense())  #节点间的关系
features = torch.FloatTensor(features.todense())  #节点自身的特征
labels = torch.LongTensor(labels)  #每个节点的分类标签</code></pre><p>然后要进行数据集的划分：</p><pre><code class="lang-python">#划分数据集
n_train = 200
n_val = 300
n_test = len(features) - n_train - n_val

np.random.seed(34)
idxs = np.random.permutation(len(features))  #将原有索引打乱顺序

#计算每个数据集的索引
idx_train = torch.LongTensor(idxs[:n_train])
idx_val = torch.LongTensor(idxs[n_train:n_train + n_val])
idx_test = torch.LongTensor(idxs[n_train + n_val:])</code></pre><p>然后将数据全部转移到GPU上：</p><pre><code class="lang-python">#分配运算资源，转到GPU上
adj = adj.to(device)
features = features.to(device)
labels = labels.to(device)
idx_train = idx_train.to(device)
idx_val = idx_val.to(device)
idx_test = idx_test.to(device)</code></pre><h3 id="toc_24">5. 单层图卷积类设计</h3><p>单层图卷积的运算逻辑如下图所示：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202401161243994.png-wms#vwid=1954&vhei=1586" src="https://image.manyacan.com/202401161243994.png-wms#vwid=1954&vhei=1586"></figure></p><p>其实就是输入特征矩阵在进行升维或者降维后再左乘一个邻接矩阵，这样就把节点间的关系融合到了网络结构中。</p><blockquote><p>GCN就是在CNN的基础上<strong>左乘一个邻接矩阵</strong>，而正是这个邻接矩阵中所存储的图结构的信息，使得标签节点间的<strong>特征进行传播</strong>。</p></blockquote><pre><code class="lang-python">class GraphConvolutionLayer(nn.Module):
    &quot;&quot;&quot;
    图卷积类——单层图卷积类
    &quot;&quot;&quot;

    def __init__(self, f_in: int, f_out: int, use_bias: bool = True, activation=None):
        &quot;&quot;&quot;
        类对象初始化函数
        :param f_in: 输入样本特征数量
        :param f_out: 输出样本特征数量
        :param use_bias: 是否使用偏置
        :param activation: 激活函数
        &quot;&quot;&quot;
        super().__init__()
        self.f_in = f_in
        self.f_out = f_out
        self.use_bias = use_bias

        # 权重与偏置参数的定义与初始化
        self.weight = nn.Parameter(torch.FloatTensor(f_in, f_out))
        self.bias = nn.Parameter(torch.FloatTensor(f_out)) if use_bias else None

        # 定义激活函数(默认为Mish激活函数)
        self.activation = (lambda x: x * (nn_fun.tanh(nn_fun.softplus(x)))) if activation else activation

        # 学习参数初始化
        self.initialize_weights()

    def initialize_weights(self):
        &quot;&quot;&quot;
        参数初始化
        &quot;&quot;&quot;
        # 初始化权重参数
        if self.activation:  # 如果使用激活函数
            nn.init.xavier_uniform_(self.weight)
        else:  # 如果不使用激活函数
            nn.init.kaiming_uniform_(self.weight, nonlinearity='leaky_relu')

        # 初始化偏置参数
        if self.use_bias:  # 偏置项初始化
            nn.init.zeros_(self.bias)

    def forward(self, f_mat, adj_mat) -&gt; torch.tensor:
        &quot;&quot;&quot;
        前向传播函数
        :param f_mat: 输入特征矩阵，形状：n×feature_in
        :param adj_mat: 样本关系邻接矩阵，形状：n×n, support
        :return: 计算过程参考P285图9-14
        &quot;&quot;&quot;
        support = torch.mm(f_mat,
                           self.weight)  # input: n×feature_in, self.weight: feature_in×feature_out, support: n×feature_out

        # GCN与CNN唯一不同的地方——每一层都需要与邻接矩阵相乘
        output = torch.mm(adj_mat, support)  # adj: n×n, support: n×feature_out, output: n×feature_out,

        if self.use_bias:  # 如果有偏置项，则将输出进行与偏置进行广播运算
            output.add_(self.bias)

        if self.activation:  # 如果存在激活函数，则将输出传入激活函数
            output = self.activation(output)
        return output</code></pre><h3 id="toc_25">5. 多层图卷积类设计</h3><pre><code class="lang-python">class GCN(nn.Module):
    &quot;&quot;&quot;
    图卷积类——多层图卷积类
    &quot;&quot;&quot;

    def __init__(self, f_in: int, n_classes: int, hidden: list, dropout_p: float = 0.5):
        &quot;&quot;&quot;
        类对象初始化函数
        :param f_in: 输入样本特征数量
        :param n_classes: 卷积结束后，最后一层分类的数量
        :param hidden: 中间隐藏层输出特征f_out数量
        :param dropout_p: dropout参数
        &quot;&quot;&quot;
        super().__init__()
        # 循环创建单层图神经网络层
        self.layers = nn.Sequential()
        for i, (f_in, f_out) in enumerate(zip([f_in] + hidden[:-1], hidden)):
            self.layers.add_module(f'GCN Layer-{i}', GraphConvolutionLayer(f_in, f_out))

        # Dropout层
        self.layers.add_module(f'Dropout Layer', nn.Dropout(dropout_p))
        # 最后输出层
        self.layers.add_module(f'Output Layer', GraphConvolutionLayer(hidden[-1], n_classes))

    def forward(self, f_mat, adj_mat):
        &quot;&quot;&quot;
        前向传播函数
        :param f_mat: 输入特征矩阵，形状：n×feature_in
        :param adj_mat: 样本关系邻接矩阵，形状：n×n, support
        :return: 计算过程参考P285图9-14
        &quot;&quot;&quot;
        for layer in self.layers:
            f_mat = layer(f_mat) if type(layer) == nn.Dropout else layer(f_mat, adj_mat)  # Dropout层只需要传入x

        return f_mat</code></pre><h3 id="toc_26">6. 创建模型并测试</h3><p>获取分类个数与节点个数：</p><pre><code class="lang-python">n_labels = labels.max().item() + 1  #分类个数 7
n_features = features.shape[1]  #节点个数 1433
print(n_labels, n_features)</code></pre><p>创建模型并测试其各层输入输出结构：</p><pre><code class="lang-python">model = GCN(n_features, n_labels, hidden=[16, 32, 16]).to(device)

# 测试图神经网络
demo_features, demo_adj = torch.ones_like(features).to(device), torch.ones_like(adj).to(device)

# 创建一个 PrettyTable 对象
table = PrettyTable()
table.field_names = ['Index', &quot;Layer Name&quot;, &quot;Input Shape&quot;, &quot;Output Shape&quot;]  #  设置表头

for i, layer in enumerate(model.layers):
    input_shape = demo_features.shape
    demo_features = layer(demo_features) if type(layer) == nn.Dropout else layer(demo_features, demo_adj)
    table.add_row([i, layer.__class__.__name__, input_shape, demo_features.shape])

# 打印表格
print(table)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202401161422723.png-wms#vwid=1570&vhei=501" src="https://image.manyacan.com/202401161422723.png-wms#vwid=1570&vhei=501"></figure></p><h3 id="toc_27">7. 创建训练与测试函数</h3><pre><code class="lang-python"># 导入Ranger优化器
from ranger import *

# 创建一个多层GCN网络并将其转移到GPU上
model = GCN(n_features, n_labels, hidden=[16, 32, 16]).to(device)

# 创建优化器
optimizer = Ranger(model.parameters())

# 计算准确度函数：返回本轮计算所有预测结果的平均准确度
get_acc = lambda output, y: (output.argmax(1) == y).type(torch.float32).mean().item()  # output.argmax(1)与y都是一个长度为2708的一维张量.


def train():
    &quot;&quot;&quot;
    训练函数
    :return: 返回损失与精确度
    &quot;&quot;&quot;
    model.train()  # 告诉模型：即将开始训练
    optimizer.zero_grad()  # 梯度归零
    output = model(features, adj)  # 训练并返回结果
    loss = nn_fun.cross_entropy(output[idx_train], labels[idx_train])  # 计算交叉熵损失函数
    acc = get_acc(output[idx_train], labels[idx_train])  # 计算精准度
    loss.backward()  # 损失反向传播
    optimizer.step()  # 优化器执行
    return loss.item(), acc  # 返回训练损失和精确度


def evaluate(idx):
    &quot;&quot;&quot;
    测试函数
    :param idx: 需要进行预测的数据行indices
    :return: 返回损失与精确度
    &quot;&quot;&quot;
    model.eval()  # 告诉模型：开启测试模型（不需要使用Dropout层）
    output = model(features, adj)
    loss = nn_fun.cross_entropy(output[idx], labels[idx]).item()  # 计算交叉熵损失
    return loss, get_acc(output[idx], labels[idx])</code></pre><h3 id="toc_28">8. 训练模型</h3><pre><code class="lang-python">#训练模型
epochs = 1000
print_steps = 50
train_loss, train_acc = [], []
val_loss, val_acc = [], []

for i in range(epochs):
    tl, ta = train()
    train_loss.append(tl), train_acc.append(ta)
    if (i + 1) % print_steps == 0 or i == 0:
        # tl, ta = evaluate(idx_train)
        vl, va = evaluate(idx_val)
        val_loss.append(vl), val_acc.append(va)

        hues.log(f'[{i + 1:4d}/{epochs}]: train_loss={tl:.4f}, train_acc={ta:.4f}' +
                 f', val_loss={vl:.4f}, val_acc={va:.4f}')
#输出最终结果
final_train, final_val, final_test = evaluate(idx_train), evaluate(idx_val), evaluate(idx_test)
hues.success(f'Train     : loss={final_train[0]:.4f}, accuracy={final_train[1]:.4f}')
hues.success(f'Test      : loss={final_test[0]:.4f}, accuracy={final_test[1]:.4f}')
hues.success(f'Validation: loss={final_val[0]:.4f}, accuracy={final_val[1]:.4f}')</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202401161525032.png-wms#vwid=1810&vhei=653" src="https://image.manyacan.com/202401161525032.png-wms#vwid=1810&vhei=653"></figure></p><h3 id="toc_29">9. Loss与Accuarcy可视化</h3><pre><code class="lang-python">#可视化训练过程
plt.rcParams.update({
    'font.size': 15,
    'font.family': ['Times New Roman', 'SimSun']
})

fig, axes = plt.subplots(1, 2, figsize=(15, 5))
ax = axes[0]
axes[0].plot(train_loss[::print_steps] + [train_loss[-1]], label='Train')
axes[0].plot(val_loss, label='Validation')
axes[1].plot(train_acc[::print_steps] + [train_acc[-1]], label='Train')
axes[1].plot(val_acc, label='Validation')

from matplotlib.ticker import FuncFormatter

plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda temp, _: '%1.0f' % (100 * temp) + '%'))

for ax, t in zip(axes, ['Loss', 'Accuracy']): ax.set_title(t, size=15), ax.set_xlabel('Epochs')

axes[0].set_ylabel('Value')
axes[1].set_ylabel('Accuracy(%)')

lines, texts = fig.axes[-1].get_legend_handles_labels()
fig.legend(lines, texts, ncol=2, loc='lower center', bbox_to_anchor=(0.5, -.1), markerscale=2)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202401161525539.png-wms#vwid=1254&vhei=522" src="https://image.manyacan.com/202401161525539.png-wms#vwid=1254&vhei=522"></figure></p><h3 id="toc_30">10. 观察模型预测结果</h3><pre><code class="lang-python">#输出模型预测结果
output = model(features, adj)

samples = 10
idx_sample = idx_test[torch.randperm(len(idx_test))[:samples]]

idx2lbl = {v: k for k, v in lbl2idx.items()}
df = pd.DataFrame({'Real': [idx2lbl[e] for e in labels[idx_sample].tolist()],
                   'Pred': [idx2lbl[e] for e in output[idx_sample].argmax(1).tolist()]})
df</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202401161525170.png-wms#vwid=1057&vhei=682" src="https://image.manyacan.com/202401161525170.png-wms#vwid=1057&vhei=682"></figure></p><p>全部完整代码与数据文件可以在我的<a href="https://github.com/Man-Yacan/GNNStudy/tree/main/Book/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%92%8C%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/Demo-04-PredictionOfTitanic">GitHub仓库</a>下载。</p>
]]></content:encoded>
<slash:comments>0</slash:comments>
<comments>https://blog.manyacan.com/archives/2047/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2047/</wfw:commentRss>
</item>
<item>
<title>Python程序设计——供水调度项目总结</title>
<link>https://blog.manyacan.com/archives/2046/</link>
<guid>https://blog.manyacan.com/archives/2046/</guid>
<pubDate>Sat, 16 Dec 2023 19:56:00 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[🔛 引八月初的时候，博导跟我介绍了这个项目，大概内容就是对某市供水管网中的泵站与清水池进行优化调度。第一次博导跟我探讨这个项目的时候，我还是有点忐忑，觉得万一自己干不好岂不是砸了老师的招牌。但是...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<h2 id="toc_31">🔛 引</h2><p>八月初的时候，博导跟我介绍了这个项目，大概内容就是对某市供水管网中的泵站与清水池进行优化调度。第一次博导跟我探讨这个项目的时候，我还是有点忐忑，觉得万一自己干不好岂不是砸了老师的招牌。但是我导说了句特别有安全感的话：没事，只管干吧，搞不出来有我给你兜着！安全感直接拉满，奥里给，干！还得是我导儿。</p><p>历时4个多月，十几次的每周PPT工作汇报，终于完成了模型的算法设计、实际运维逻辑匹配、数据库输入输出对接、线上部署等工作。在这个项目过程中，也经历过很多次的绝望、失落、喜悦，以及无数次的DEBUG，感觉自己还是学到了很多东西的。这篇博客就来记录下整个项目下来我自己的一些学习与心得体会。</p><p>在上次的组会过程中，我其实已经进行了一个大概的总结，所以说接下来就按照组会PPT中的内容进行一个记录吧~</p><p><figure><img class="" alt="组会汇报" data-src="https://image.manyacan.com/202312161608119.png-wms#vwid=2952&vhei=1524" src="https://image.manyacan.com/202312161608119.png-wms#vwid=2952&vhei=1524"><figcaption>组会汇报</figcaption></figure></p><h2 id="toc_32">⏱️ 考虑时间成本</h2><blockquote><h4 id="toc_33">Quote / 参考</h4><p>面对未知的事物，试错过程需要花费大量时间成本，凡事一定要提前准备，预备好抵抗未知错误的缓冲区。</p></blockquote><p>对于任何一件未知的事（这个未知是指没有别人做过类似的事可以给你参考），那么就一定要提前考虑到遇到未知错误所花费的时间成本。</p><p>在项目开始前，博导说预备时间是两个半月，然后我们就先按两个月的来，给最后留半个月的时间缓冲。我当时觉得时间还是很充裕的。</p><p>然而实际情况做下来，我们花费了将近4个多月，几乎是原来时间的两倍了。</p><p>首先是第一个问题：<strong>项目开始前一定要做充分的调研，大方向不能错，或者说尽量少错。</strong></p><p>在项目开始前，与甲方多次沟通交流，确定了的方案是“基于历史数据驱动的智能调度模型研究”。从八月到国庆节前，我们也是一直按照这个方向来做的。结果到了国庆节前发现，我们所走的路是存在致命问题的，不得已又改变路线，选择了“基于区间流量平衡与遗传算法的智能调度模型研究”，这也就意味着我们前期浪费了巨多时间做了无用功。</p><p>其实选择的这个新方案，我导在第一次跟我讲这个项目的时候就提到了这种方案。因为对于一个泵站来说，其水泵开关的组合非常适合使用遗传算法（Genetic Algorithm, GA）进行求解。只是我当时根本不知道遗传算法是个什么东西，所以没有GET到我导的意思。</p><p>现在看来，我导对大方向的把握真是有点东西，如果一开始就按照我导的思路做，也许我们能减少很多无用功了。</p><p>第二个感受比较深的过程是在做项目前后端数据库对接的时候。简单来说，我负责模型的构建，模型输入输出的数据需要从数据库中读取或写入，另外一个团队负责WEB前端的开发，前端显示的内容就是从数据库中读取的。</p><p><strong>这里，犯了一个很严重的逻辑问题。</strong>直接与数据库对接的是前端和模型，那么前端就应该在与模型商议数据库结构之前，先确定了用户的需求。但是实际上前端团队并不是这样做的，而是边与用户沟通加入新的需求边与模型端沟通确定写入数据格式。这就造成了一个问题，前端一边与模型一起对接数据库，一边与顾客商议需求，这就给我的模型带来了很大困扰，我对我的模型输出进行了多次很大结构上的调整，花费了很多时间。所以说，选择与靠谱的团队进行合作还是很重要的😑。</p><h2 id="toc_34">🤌 嘴上说，心里想, 不如手上做</h2><blockquote><h4 id="toc_35">Quote / 参考</h4><p>不知道什么行不行，那就先动手试试，不动手永远不知道结果。动手了还真可能一个个慢慢就解决了。</p></blockquote><p>上面也提到了，在国庆前后我们准备更换新的工作路线。我导跟我提到了GA，说GA非常适合我们当时所遇到的问题，但是当时的我对于GA一窍不通。</p><p><strong>对于未知的事物，人们的本能总是恐惧，所以总是想逃避。</strong></p><p>当时我的一听到“算法”两个字，似乎就感觉一座大山压在我的身上，要让我迅速学习一个算法并应用到实际项目，这对我来说太难了。所以，那天我还是想看看以前的路到底还有没有办法能够继续走得通。</p><p>一直到最后，发现老路实在是走不下去了，我才“逼上梁山”开始学习GA。但是当我真的开始学习GA，发现它其实并没有想象中的那么难。从初识到应用到自己的项目里，前后也就是三五天的时间。</p><p>通过这件事就说明两点：</p><ol><li>要对自己有信心，面对未知事物，肯定会遇到困难。但是要相信自己——只用功夫深，铁棒磨成针！！！</li><li>凡事要一点点来，不用心急，每天进步一点点——水滴石穿！！！</li></ol><h2 id="toc_36">🐛 先谋大略，后顾细微</h2><blockquote><h4 id="toc_37">Quote / 参考</h4><p>技术应用于实际工程，需要考虑太多太多太多的未知情况，前期尽量去考虑照顾到，大方向不要出错误，后期预留一定的时间慢慢调试实际运行中的小问题。</p></blockquote><p>如果一项技术的科学研究已经发展到了98%，那么能将其30%成功应用到实际就很不错了， 科学与技术之间还是有很多隔阂的。这个隔阂，其实指的就是将科学应用到实际过程中需要协调的未知情况，因为科学实验大部分是在较为理想的环境中进行的。</p><p>可能并没有什么好的办法能够消除这种隔阂的，只能说是在技术应用的过程中就尽量多的去考虑实际中可能遇到的情况。然后，还要在实际部署后，预留大量的时间去DEBUG。</p><h2 id="toc_38">💡 君子生非异也，善假于物也</h2><blockquote><h4 id="toc_39">Quote / 参考</h4><p>擅用ChatGPT！！！特别是数据库相关内容（猜测可以推广到Numpy、Pandas的数据分析），把问题描述清楚（可以采用分步提问的方式）。</p></blockquote><p>从我小学接触互联网以来，互联网第一次给我的震撼是CS Online（一款在线射击游戏），第二次就是今年的ChatGPT。</p><p>这个项目的全过程中，涉及到数据库的操作全部是ChatGPT帮助我完成的，对于数据库这种本身其结构性就很强的东西，ChatGPT的回答相当完美，几乎没有出现过任何错误。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312161845007.png-wms#vwid=2024&vhei=1679" src="https://image.manyacan.com/202312161845007.png-wms#vwid=2024&vhei=1679"></figure></p><p>ChatGPT另一个比较好的应用场景是基础知识的学习，最近在学习图论的过程中，我没有看过任何视频教程，全部都是跟着ChatGPT进行学习的。这让我的学习效率得到了极大得提高。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312162036449.png-wms#vwid=3828&vhei=1926" src="https://image.manyacan.com/202312162036449.png-wms#vwid=3828&vhei=1926"></figure></p><p>前几天毫不犹豫下单了ChatGPT 4.0，这个价格能够提供给我的帮助让我觉得非常实惠。</p><h2 id="toc_40">⌨️ Python程序设计指南（非正式版）</h2><blockquote><h4 id="toc_41">Quote / 参考</h4><p>项目程序设计一定要最起码有一套“自己的规范”。</p></blockquote><h3 id="toc_42">结构化设计</h3><p>这个项目核心文件将近3000行代码，算是我目前写过最大的项目了。在项目开发的过程中，越发觉得程序设计规范化的重要性。当你写10行代码时，没有什么需要注意的；但是当你写了1000行代码时，回过头来可能你自己都忘了刚开始写的是什么。这个时候就凸显了注释和结构的重要性。</p><p>这里所说的结构化其实并不一定要按照Python编程规范或者说某一种固定的格式来编写代码。我个人觉得是最起码你自己要有一套自己的规范（如果你是单打独斗的话）。</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202312161925717.png-wms#vwid=483&vhei=491" src="https://image.manyacan.com/202312161925717.png-wms#vwid=483&vhei=491"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202312161926001.png-wms#vwid=717&vhei=316" src="https://image.manyacan.com/202312161926001.png-wms#vwid=717&vhei=316"></figure></div><p>例如，我就喜欢对每个类设置一个<code>run()</code>函数来作为类对象的入口函数：</p><pre><code class="lang-python">if __name__ == '__main__':
    optimizer = Optimizer(
        log_level=logging.INFO  # logging.INFO, logging.DEBUG
    )
    optimizer.run()</code></pre><h3 id="toc_43">虚拟环境</h3><p>在大项目开发过程中，虚拟环境真的太重要了，主要体现在以下三点：</p><ol><li>有可能项目需要部署到其他电脑来测试，如果没有虚拟环境，那么就需要在新电脑重新配置一个与原电脑一样的环境，非常麻烦；</li><li>避免了其他项目环境对本项目的污染，也避免了本项目对系统环境的污染；</li><li>如果程序需要打包为EXE或者其他可执行文件，那么虚拟环境可以避免无用的包被打包进程序里，从而减小程序的体积。</li></ol><p>如何导出当前环境中的所有包及其版本号？</p><p>使用命令： <code>pip freeze &gt; .\requirements.txt</code>即可。会在根目录生成一个名为<code>requirements.txt</code>的文件。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312161937333.png-wms#vwid=815&vhei=761" src="https://image.manyacan.com/202312161937333.png-wms#vwid=815&vhei=761"></figure></p><p>将该文件复制到需要配置新环境的电脑中，使用命令：</p><pre><code class="lang-shell">pip install -r requirements.txt</code></pre><p>即可一键复制安装源环境中的所有包。</p><h3 id="toc_44">EXE程序的打包</h3><p><strong>PyInstaller</strong> 是最常用和最方便的打包工具，尤其是由于其对不同操作系统的广泛支持和对各种Python版本和库的兼容性。使用PyInstaller打包Python程序相对简单，社区支持也很强大。PyInstaller可以打包Python程序为独立的可执行文件，适用于Windows、macOS和Linux。它支持Python 2.7和Python 3.5及以上版本，能够打包大多数Python库，并且有很多选项来自定义打包过程，下面记录几个打包过程踩的坑。</p><h4 id="toc_45">打包程序</h4><pre><code class="lang-shell">(venv) PS D:\Code\Optimizer&gt; pyinstaller -w -i favicon.ico --add-data=&quot;data;data&quot; main.py</code></pre><p>参数解释如下：</p><ul><li><code>-w</code>：让程序以无命令行的形式运行；</li><li><code>-i favicon.ico</code>：将根文件夹中的<code>favicon.ico</code>作为程序的LOGO；</li><li><code>--add-data=&quot;data;data&quot;</code>将<code>data</code>文件夹打包为程序下的<code>data</code>文件夹。</li></ul><h4 id="toc_46">异常捕获</h4><p>Python程序在经过打包后，如果有异常就会直接闪退，非常不利于调试错误。这个时候我们可以使用：</p><pre><code class="lang-python">try:  # 尝试捕获异常
    ...
except KeyError as e:  # 成功捕获异常
    print(e)
else:  # 未发现异常
    ...
finally:  # 最终要执行的
    ...</code></pre><p>来捕获并处理异常。</p><h4 id="toc_47">路径处理</h4><p>Python程序如果需要涉及读写文件的操作，那么就必须使用下面的函数来兼容EXE运行时的路径问题：</p><pre><code class="lang-python">@staticmethod
def resource_path(*args):
    &quot;&quot;&quot;
    获取文件路径, 兼容EXE打包问题
    :param args: 任意多个参数, 文件路径. 例如访问 './data/Setting_CQ.json'文件, 需要输入两个参数'data', 'Setting_CQ.json'
    :return: 组合后的绝对路径
    &quot;&quot;&quot;
    if hasattr(sys, '_MEIPASS'):
        # 在PyInstaller打包后的可执行文件中
        return os.path.join(sys._MEIPASS, *args)
    else:
        # 在原始Python脚本中
        return os.path.join(os.path.abspath(&quot;.&quot;), *args)</code></pre><h2 id="toc_48">💨 结</h2><p>总体上来说，这个过程还是挺锻炼人的，我在这个过程中学习到了很多东西，也成长了很多，也算是自己的一笔财富吧。加油！（不过我还是希望后面甲方反馈的BUG能少一点~🙏）</p><p>🙏🙏🙏佛祖保佑🙏🙏🙏</p><pre><code class="lang-python">print(&quot;                            _ooOoo_  &quot;)
print(&quot;                           o8888888o  &quot;)
print(&quot;                           88  .  88  &quot;)
print(&quot;                           (| -_- |)  &quot;)
print(&quot;                            O\\ = /O  &quot;)
print(&quot;                        ____/`---'\\____  &quot;)
print(&quot;                      .   ' \\| |// `.  &quot;)
print(&quot;                       / \\||| : |||// \\  &quot;)
print(&quot;                     / _||||| -:- |||||- \\  &quot;)
print(&quot;                       | | \\\\\\ - /// | |  &quot;)
print(&quot;                     | \\_| ''\\---/'' | |  &quot;)
print(&quot;                      \\ .-\\__ `-` ___/-. /  &quot;)
print(&quot;                   ___`. .' /--.--\\ `. . __  &quot;)
print(&quot;                .&quot;&quot; '&lt; `.___\\_&lt;|&gt;_/___.' &gt;'&quot;&quot;.  &quot;)
print(&quot;               | | : `- \\`.;`\\ _ /`;.`/ - ` : | |  &quot;)
print(&quot;                 \\ \\ `-. \\_ __\\ /__ _/ .-` / /  &quot;)
print(&quot;         =======`-.____`-.___\\_____/___.-`____.-'=======  &quot;)
print(&quot;                            `=------='  &quot;)
print(&quot;  &quot;)
print(&quot;         .............................................  &quot;)
print(&quot;                  佛祖镇楼                  BUG消失  &quot;)
print(&quot;          佛曰:  &quot;)
print(&quot;                  写字楼里写字间，写字间里程序员；  &quot;)
print(&quot;                  程序人员写程序，又拿程序换酒钱。  &quot;)
print(&quot;                  酒醒只在网上坐，酒醉还来网下眠；  &quot;)
print(&quot;                  酒醉酒醒日复日，网上网下年复年。  &quot;)
print(&quot;                  但愿老死电脑间，不愿鞠躬老板前；  &quot;)
print(&quot;                  奔驰宝马贵者趣，公交自行程序员。  &quot;)
print(&quot;                  别人笑我忒疯癫，我笑自己命太贱；  &quot;)
print(&quot;                  不见满街漂亮妹，哪个归得程序员？&quot;)</code></pre>
]]></content:encoded>
<slash:comments>1</slash:comments>
<comments>https://blog.manyacan.com/archives/2046/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2046/</wfw:commentRss>
</item>
<item>
<title>图论入门——从基础概念到NetworkX</title>
<link>https://blog.manyacan.com/archives/2044/</link>
<guid>https://blog.manyacan.com/archives/2044/</guid>
<pubDate>Tue, 12 Dec 2023 12:42:00 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[介绍图（Graph）是一种表示对象之间关系的抽象数据结构。图由节点（Vertex）和边（Edge）组成，节点表示对象，边表示对象之间的关系。图可以用于建模各种实际问题，如社交网络、交通网络、电力...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<h2 id="toc_49">介绍</h2><p><strong>图</strong>（Graph）是一种表示对象之间关系的抽象数据结构。图由节点（Vertex）和边（Edge）组成，节点表示对象，边表示对象之间的关系。图可以用于建模各种实际问题，如社交网络、交通网络、电力网络等。</p><p><strong>NetworkX</strong>是一个用Python编写的库，专门用于创建、操作和研究复杂网络的结构、动态和功能。它提供了简单易用的接口来处理图论和网络结构。NetworkX适用于处理大型网络结构，并提供了许多内置的图算法，如路径寻找、图的构建和修改、节点属性操作等。</p><ul><li>NetworkX官方文档（网站）：<a href="https://networkx.org/">https://networkx.org/</a>；</li><li>使用pip安装：<code>pip install networkx</code>并回车。</li></ul><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312121302497.png-wms#vwid=1436&vhei=1071" src="https://image.manyacan.com/202312121302497.png-wms#vwid=1436&vhei=1071"></figure></p><h2 id="toc_50">基本概念</h2><h3 id="toc_51">无向图（Undirected Graph）</h3><pre><code class="lang-python">import networkx as nx

# 创建一个无向图
G = nx.Graph()

# 添加节点
G.add_node(1)
G.add_nodes_from([2, 3])

# 添加边
G.add_edge(1, 2)
G.add_edges_from([(2, 3), (1, 3)])

# 查看图的节点和边
print(&quot;图的节点: &quot;, G.nodes(), &quot;; 图的边: &quot;, G.edges(), '.')

# 可视化
nx.draw(G, node_size=500, with_labels=True)</code></pre><p><figure><img class="" alt="控制台输出结果 - 无向图" data-src="https://image.manyacan.com/202312111113454.png-wms#vwid=1242&vhei=835" src="https://image.manyacan.com/202312111113454.png-wms#vwid=1242&vhei=835"><figcaption>控制台输出结果 - 无向图</figcaption></figure></p><h3 id="toc_52">有向图（Directed Graph）</h3><p>有向图的创建方式很简单，只需要把上面无向图的对象：</p><pre><code class="lang-python"># 创建一个无向图
G = nx.Graph()</code></pre><p>换成：</p><pre><code class="lang-python"># 创建一个有向图
G = nx.DiGraph()</code></pre><p>即可。</p><p><figure><img class="" alt="控制台输出结果 - 有向图" data-src="https://image.manyacan.com/202312111120619.png-wms#vwid=1098&vhei=834" src="https://image.manyacan.com/202312111120619.png-wms#vwid=1098&vhei=834"><figcaption>控制台输出结果 - 有向图</figcaption></figure></p><h3 id="toc_53">有权图（Directed Graph）</h3><p>创建有权图时需要添加权重信息，且可视化的代码略有不同：</p><pre><code class="lang-python">import networkx as nx
import matplotlib.pyplot as plt

# 创建一个带权重的无向图
G = nx.Graph()

# 添加带权重的边
G.add_edges_from([
    (2, 3, {'diameter': 1.0,'length': 12.0}),
    (1, 3, {'diameter': 2.0,'length': 10.0}),
    (2, 1, {'diameter': 3.0,'length': 8.0})
])

# 提取权重信息
edge_weights = nx.get_edge_attributes(G, 'length')

# 可视化图
pos = nx.spring_layout(G)  # 选择布局算法，这里使用弹簧布局
nx.draw(G, pos, with_labels=True, font_weight='bold', node_size=700, node_color='skyblue', font_color='black')

# 绘制权重标签
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_weights)

# 显示图形
plt.show()

# 查看图的节点和边
print(&quot;图的节点: &quot;, G.nodes(), &quot;; 图的边: &quot;, G.edges(data=True), '.')</code></pre><p><figure><img class="" alt="控制台输出结果 - 有权图" data-src="https://image.manyacan.com/202312111230908.png-wms#vwid=1637&vhei=910" src="https://image.manyacan.com/202312111230908.png-wms#vwid=1637&vhei=910"><figcaption>控制台输出结果 - 有权图</figcaption></figure></p><h3 id="toc_54">邻接矩阵</h3><p><strong>邻接矩阵（Adjacency Matrix）：</strong> 邻接矩阵是一个二维矩阵，其中的行和列分别对应图中的节点。矩阵的元素表示节点之间是否存在边。对于无向图，邻接矩阵是对称的；对于有向图，邻接矩阵不一定对称。</p><pre><code class="lang-python"># 获取邻接矩阵(默认是稀疏矩阵格式)
adj_matrix = nx.adjacency_matrix(G)

# 将稀疏矩阵转换为密集矩阵(如果需要)
dense_adj_matrix = adj_matrix.todense()</code></pre><p>请注意，如果你的图是有向图，你可以使用 <code>nx.adjacency_matrix(G, directed=True)</code> 来获取有向图的邻接矩阵。如果你想要自定义矩阵的表示方式，你可以使用 <code>toarray()</code> 方法将稀疏矩阵转换为 NumPy 数组。</p><h3 id="toc_55">关联矩阵</h3><p>在 <code>networkx</code> 库中，<code>nx.incidence_matrix(G)</code> 用于生成图 <code>G</code> 的关联矩阵（Incidence Matrix）。关联矩阵和邻接矩阵不同，它是一种表示图中节点与边之间关系的矩阵。</p><p>对于一个包含 $ N $ 个节点和 $ M $ 条边的图，其关联矩阵是一个 $ N \times M $ 的矩阵，其中矩阵的行对应图中的节点，列对应图中的边。关联矩阵中的元素定义如下：</p><ul><li>如果边 $ e $ 与节点 $ v $ 相连，则矩阵中对应位置的值为 1（或者对于有向图，出边为 -1，入边为 1）；</li><li>如果边 $ e $ 与节点 $ v $ 不相连，则对应位置的值为 0。</li></ul><p>举个例子：</p><pre><code class="lang-python"># 创建一个图
G = nx.Graph()
G.add_edges_from([(0, 1), (0, 2), (1, 2)])

# 获取关联矩阵
inc_matrix = nx.incidence_matrix(G)

# 绘制节点和边
pos = nx.spring_layout(G)  # 生成节点的布局
nx.draw(G, pos, node_size=500, with_labels=True)

# 为每条边创建一个标签（例如，使用边的索引作为标签）
edge_labels = {edge: i for i, edge in enumerate(G.edges())}

# 将边的标签添加到图中
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=20)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192153217.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312192153217.png-wms#vwid=660&vhei=499"></figure></p><p>获取关联矩阵：</p><pre><code class="lang-python">inc_matrix.toarray()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192153388.png-wms#vwid=1409&vhei=307" src="https://image.manyacan.com/202312192153388.png-wms#vwid=1409&vhei=307"></figure></p><h3 id="toc_56">度、平均度、度分布、度矩阵以及常见复杂网络常见度分布</h3><p>下面的演示均以：</p><pre><code class="lang-python">G.add_edges_from([  # Fig. 7
    (0, 1), (0, 2), (0, 7),
    (1, 0), (1, 2), (1, 3), (1, 4), (1, 7),
    (2, 0), (2, 1), (2, 3),
    (3, 1), (3, 2), (3, 4), (3, 5), (3, 7),
    (4, 1), (4, 3), (4, 5), (4, 6), (4, 7),
    (5, 3), (5, 4), (5, 6),
    (6, 4), (6, 5),
    (7, 0), (7, 1), (7, 3), (7, 4)
])</code></pre><p><figure><img class="" alt="演示图结构" data-src="https://image.manyacan.com/202312111439373.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312111439373.png-wms#vwid=660&vhei=499"><figcaption>演示图结构</figcaption></figure></p><p>为示例。</p><h4 id="toc_57">度</h4><p><strong>度（Degree）的定义：</strong></p><ul><li>对于无向图 G，节点 i 的度 $ \text{degree}(i) $ 是与节点 i 相连的边的数量。</li><li>对于有向图 G，节点 i 的入度 $ \text{in-degree}(i) $ 是指向节点 i 的边的数量，出度 $ \text{out-degree}(i) $ 是从节点 i 出发的边的数量。</li></ul><p><code>NetworkX</code>求度：</p><pre><code class="lang-python"># 获取节点的度
degrees = dict(G.degree())

print(&quot;节点的度：&quot;, degrees)</code></pre><blockquote><p>节点的度： {0: 3, 1: 5, 2: 3, 7: 4, 3: 5, 4: 5, 5: 3, 6: 2}</p></blockquote><h4 id="toc_58">平均度</h4><p><strong>平均度（Average Degree）</strong>是图中所有节点的度的平均值。</p><ul><li>对于无向图 G，平均度 $ \langle k \rangle $ 可以通过所有节点的度之和除以节点数得到。</li><li>对于有向图 G，同样可以计算平均入度和平均出度。</li></ul><pre><code class="lang-python"># 计算平均度
average_degree = sum(dict(G.degree()).values()) / len(G)

print(&quot;平均度：&quot;, average_degree)</code></pre><blockquote><p>平均度： 3.75</p></blockquote><h4 id="toc_59">度分布</h4><p><strong>度分布（Degree Distribution）</strong>描述了图中节点的度的分布情况，即度为 k 的节点有多少个。度分布是图结构的一个重要特征，它可以帮助我们了解网络中节点的连接模式。</p><pre><code class="lang-python"># 获取度分布
degree_distribution = nx.degree_histogram(G)

# 绘制度分布直方图
plt.bar(range(len(degree_distribution)), degree_distribution, tick_label=range(len(degree_distribution)))
plt.xlabel(&quot;Degree&quot;)
plt.ylabel(&quot;Frequency&quot;)
plt.title(&quot;Degree Distribution&quot;)
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312111444905.png-wms#vwid=567&vhei=455" src="https://image.manyacan.com/202312111444905.png-wms#vwid=567&vhei=455"></figure></p><h4 id="toc_60">度矩阵</h4><p><strong>度矩阵（Degree Matrix）</strong>是一个表示图中节点度信息的对角矩阵。对于一个无向图，度矩阵的定义如下：</p><ol><li>对于无向图 G，其度矩阵 $ D $ 是一个 $ n \times n $ 的矩阵，其中 $ n $ 是图中的节点数。</li><li>$ D $ 的对角线元素 $ D_{ii} $ 表示节点 $ i $ 的度，即与节点 $ i $ 相连的边的数量。</li></ol><pre><code class="lang-python"># 获取度矩阵
np.diag(list(dict(G.degree()).values()))</code></pre><p><figure><img class="" alt="控制台输出结果 - 度矩阵" data-src="https://image.manyacan.com/202312111314737.png-wms#vwid=1808&vhei=773" src="https://image.manyacan.com/202312111314737.png-wms#vwid=1808&vhei=773"><figcaption>控制台输出结果 - 度矩阵</figcaption></figure></p><h4 id="toc_61">复杂网络常见度分布</h4><p>在复杂网络理论中，度分布描述了网络中各节点的连接数（即度）的分布情况。不同类型的网络具有不同的度分布特性。典型复杂网络的度分布有：泊松分布、幂律分布（Power-Law Distribution）、指数分布等。</p><h5 id="toc_62">泊松分布</h5><p>大多数节点的度数集中在较小的数值范围内，这是典型的泊松分布特征，符合Erdős-Rényi随机图模型的特点。</p><pre><code class="lang-python">import networkx as nx
import matplotlib.pyplot as plt

# 参数设置
n = 500  # 节点数
p = 0.05  # 每对节点间存在边的概率

# 使用 Erdős-Rényi 模型创建随机图
G = nx.erdos_renyi_graph(n, p)

# 准备绘制网络结构图和度分布统计图
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# 在左边绘制网络图
nx.draw(G, ax=ax1, node_size=30, with_labels=False)
ax1.set_title(&quot;Erdős-Rényi Network (n={}, p={})&quot;.format(n, p))

# 在右边绘制度分布统计图
degrees = [G.degree(n) for n in G.nodes()]
ax2.hist(degrees, bins=range(min(degrees), max(degrees) + 1), density=True)
ax2.set_title(&quot;Degree Distribution&quot;)
ax2.set_xlabel(&quot;Degree&quot;)
ax2.set_ylabel(&quot;Frequency&quot;)

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312132036949.png-wms#vwid=1259&vhei=548" src="https://image.manyacan.com/202312132036949.png-wms#vwid=1259&vhei=548"></figure></p><h5 id="toc_63">幂律分布</h5><p>Barabási-Albert 模型生成的网络展现了显著的幂律分布特征，即大多数节点拥有较少的连接，而少数节点（枢纽节点）拥有非常多的连接。</p><pre><code class="lang-python">m = 5
n = 200  # 节点数
G = nx.barabasi_albert_graph(n, m)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312132041942.png-wms#vwid=1259&vhei=547" src="https://image.manyacan.com/202312132041942.png-wms#vwid=1259&vhei=547"></figure></p><h5 id="toc_64">指数分布</h5><p>大多数节点具有较低的度数，而只有少数节点具有较高的度数。这反映了指数分布的特点，即概率随着度数的增加而迅速减少。由于指数分布的特性，大多数节点集中在较低的度数区间，而高度数的节点数量迅速减少。</p><pre><code class="lang-python">import numpy as np
import networkx as nx
import matplotlib.pyplot as plt

# 参数设置
m = 5
n = 1000  # 节点数

# 由于NetworkX没有直接生成指数分布网络的函数，我们可以手动创建一个具有指数分布度的网络
# 创建一个空的图
G = nx.Graph()

# 添加节点
G.add_nodes_from(range(n))

# 生成一个符合指数分布的度序列
degree_sequence = np.random.exponential(scale=m, size=n).astype(int)

# 为了确保总度数为偶数（每条边两个端点），如果是奇数则调整
if sum(degree_sequence) % 2 != 0:
    degree_sequence[0] += 1

# 生成具有指定度序列的随机图（可能会有多重边和自环）
G = nx.configuration_model(degree_sequence)

# 转换为简单图（无多重边和自环）
G = nx.Graph(G)
G.remove_edges_from(nx.selfloop_edges(G))

# 准备绘制网络结构图和度分布统计图
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# 在左边绘制网络图
nx.draw(G, ax=ax1, node_size=30, with_labels=False)
ax1.set_title(&quot;Exponential Distribution Network (n={}, scale={})&quot;.format(n, m))

# 在右边绘制度分布统计图
degrees = [d for n, d in G.degree()]
ax2.hist(degrees, bins=range(min(degrees), max(degrees) + 1), density=True)
ax2.set_title(&quot;Degree Distribution&quot;)
ax2.set_xlabel(&quot;Degree&quot;)
ax2.set_ylabel(&quot;Frequency&quot;)
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312132048458.png-wms#vwid=1259&vhei=547" src="https://image.manyacan.com/202312132048458.png-wms#vwid=1259&vhei=547"></figure></p><blockquote><h4 id="toc_65">Quote / 参考</h4><p>幂律分布与指数分布看起来没有什么差别啊？</p><p>幂律分布：</p><ul><li><strong>长尾特性</strong>：幂律分布的一个显著特点是它的长尾特性。这意味着即使是非常大的值也有可能出现，尽管其频率较低。</li><li><strong>对数坐标下的直线</strong>：在对数-对数坐标图中，幂律分布呈现为一条直线。</li><li><strong>现实世界的例子</strong>：社交网络中的连接分布、互联网链接的分布、城市的人口分布等。</li></ul><p>指数分布：</p><ul><li><strong>迅速衰减</strong>：指数分布的特点是随着值的增加，其概率迅速减少。这意味着大值出现的可能性比幂律分布要小得多。</li><li><strong>半对数坐标下的直线</strong>：在半对数坐标图中（即纵坐标为对数坐标），指数分布表现为一条直线。</li><li><strong>现实世界的例子</strong>：无线电活动的持续时间、顾客在商店的停留时间等。</li></ul></blockquote><h4 id="toc_66">平均近邻度</h4><p>平均近邻度（Average Nearest Neighbor Degree, Average Neighbor Degree）是指网络中一个节点的邻居节点的平均度数。这个指标可以用来判断网络中的节点是否倾向于与相似或不同度数的其他节点相连。</p><p>平均近邻度的计算方法是：</p><ul><li>对于网络中的每个节点，计算其所有邻居节点的度数。</li><li>对这些度数求平均值。</li><li>重复此过程，计算所有节点的平均近邻度。</li></ul><p>公式为：</p><p>$$
k_{nn,i} = \frac{1}{k_i} \sum_{j \in \mathcal{N}(i)} k_j
$$</p><p>其中，$ \mathcal{N}(i) $ 是节点 $ i $ 的邻居集合，$ k_i $ 是节点 $ i $ 的度数，$ k_j $ 是 $ i $ 的邻居节点 $ j $ 的度数。</p><h4 id="toc_67">相关性(匹配)系数</h4><p>相关性(匹配)系数（Assortativity Coefficient, Degree Correlation Coefficient）衡量的是网络中高度数的节点倾向于与其他高度数的节点相连（正相关），还是与低度数的节点相连（负相关）。</p><p>相关性系数的计算方法是：</p><ul><li>计算网络中每对连接节点的度数乘积。</li><li>对这些乘积求平均值。</li><li>计算度数的平均值的平方和度数平方的平均值。</li><li>将这些值代入皮尔逊相关系数的公式中。</li></ul><p>公式为：</p><p>$$
r = \frac{M^{-1} \sum_{i,j} A_{ij} k_i k_j - [M^{-1} \sum_{i} k_i]^2}{M^{-1} \sum_{i} k_i^2 - [M^{-1} \sum_{i} k_i]^2}
$$</p><p>其中，$ A_{ij} $ 是邻接矩阵中的元素，$ k_i $ 和 $ k_j $ 是节点的度数，$ M $ 是边的总数。</p><p>下面举个例子对比分析下平均近邻度与相关性(匹配)系数：</p><p>创建两个网络结构：</p><pre><code class="lang-python"># 创建两个不同的网络结构
# 网络1：经典的Erdős-Rényi随机图
G1 = nx.erdos_renyi_graph(n=100, p=0.05)
# 网络2：Barabási-Albert无标度网络
G2 = nx.barabasi_albert_graph(n=100, m=2)</code></pre><p>计算两个网络的相关性（匹配）系数：</p><pre><code class="lang-python">G1_r = nx.degree_pearson_correlation_coefficient(G1)
G2_r = nx.degree_pearson_correlation_coefficient(G2)</code></pre><p>计算两个网络的平均近邻度：</p><pre><code class="lang-python">average_neighbor_degree_G1 = nx.average_neighbor_degree(G1)
average_neighbor_degree_G2 = nx.average_neighbor_degree(G2)

# 计算两个网络的平均近邻度的平均值
G1_and =sum(average_neighbor_degree_G1.values()) / len(average_neighbor_degree_G1)
G2_and = sum(average_neighbor_degree_G2.values()) / len(average_neighbor_degree_G2)</code></pre><p>绘图可视化观察：</p><pre><code class="lang-python"># 在左边绘制网络图
nx.draw(G1, ax=ax1, node_size=50, with_labels=False)
nx.draw(G2, ax=ax2, node_size=50, with_labels=False)

ax1.set_title(f&quot;Graph A, r={round(G1_r, 3)}, and={round(G1_and, 3)}&quot;)
ax2.set_title(f&quot;Graph B, r={round(G2_r, 3)}, and={round(G2_and, 3)}&quot;)
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312191226588.png-wml#vwid=1259&vhei=513" src="https://image.manyacan.com/202312191226588.png-wml#vwid=1259&vhei=513"></figure></p><ul><li><strong>相关性（匹配）系数</strong>：两个网络都显示出负相关性，但Barabási-Albert无标度网络（Graph B）的负相关性更强。这表明在无标度网络中，网络中的枢纽（高度数的节点）更可能与度数较低的节点相连，这是典型的无标度网络特性。</li><li><strong>平均近邻度</strong>：Barabási-Albert无标度网络的平均近邻度高于Erdős-Rényi随机图。这反映了无标度网络中节点连接的非均匀性，其中一些节点（即枢纽）与大量其他节点相连，从而提高了平均近邻度。</li></ul><p>总的来说，这两个网络展现出不同的结构特征，无标度网络的节点连通性更加集中和不均匀，而随机图则表现出更均匀的连接模式。这些特性在网络的稳定性和动态行为上有重要影响，例如在信息传播或疾病传播的研究中。</p><h3 id="toc_68">拉普拉斯矩阵</h3><p>拉普拉斯矩阵（Laplacian Matrix）有多种定义方式，其中最常见的计算方法是使用度矩阵减去邻接矩阵。假设无向图 G 有 n 个节点，其邻接矩阵为 A，度矩阵为 D。标准拉普拉斯矩阵 L 的计算如下：</p><ol><li>计算度矩阵 D 的对角线元素，即每个节点的度：$ D_{ii} = \sum_{j} A_{ij} $；</li><li>计算拉普拉斯矩阵 L：$ L = D - A $。</li></ol><pre><code class="lang-python"># 获取邻接矩阵和度矩阵
adj_matrix = nx.adjacency_matrix(G).toarray()
degree_matrix = np.diag(list(dict(G.degree()).values()))

# 计算标准拉普拉斯矩阵
laplacian_matrix = degree_matrix - adj_matrix</code></pre><blockquote><p>其他几种邻接矩阵：</p><ul><li><code>nx.laplacian_matrix(G)</code>：返回G的拉普拉斯矩阵；</li><li><code>nx.directed_laplacian_matrix(G)</code>：返回有向图的拉普拉斯矩阵；</li><li><code>nx.normalized_laplacian_matrix(G)</code>：返回G的标准化拉普拉斯矩阵。</li></ul></blockquote><h3 id="toc_69">路径和距离</h3><p>在图论中，路径和距离是描述图中节点之间连接关系和位置关系的重要概念。</p><ul><li>路径（Path）：在图中，路径是指图中的一系列节点，其中任意相邻两个节点之间都有边相连。路径的长度是指路径上边的数量。如果路径中的所有节点都是不同的，则路径是简单路径。</li><li>距离（Distance）：在图中，两个节点之间的距离是指<strong>连接这两个节点的最短路径的长度</strong>。如果两个节点之间没有路径相连，则它们之间的距离通常被定义为<strong>无穷大</strong>。</li></ul><h4 id="toc_70">获取所有节点间的最短路径和距离</h4><p>获取图中的所有最短路径和距离：</p><pre><code class="lang-python"># 获取所有节点对之间的最短路径和距离
all_shortest_paths = dict(nx.all_pairs_shortest_path(G))
all_shortest_distances = dict(nx.all_pairs_shortest_path_length(G))

# 打印最短路径和距离
all_info = []
for source in all_shortest_paths:
    for target in all_shortest_paths[source]:
        paths = all_shortest_paths[source][target]
        distance = all_shortest_distances[source][target]
        print(f&quot;最短路径从节点 {source} 到节点 {target}: {paths}, 距离: {distance}&quot;)</code></pre><h4 id="toc_71">节点间最短路径和距离</h4><p>获取节点间最短路径和距离：</p><pre><code class="lang-python">i, j = 1, 3
print(nx.shortest_path(G, i, j), nx.shortest_path_length(G, i, j))</code></pre><h4 id="toc_72">获取节点间的所有路径</h4><pre><code class="lang-python"># 寻找所有简单路径
paths = list(nx.all_simple_paths(G, 6, 0))

print(&quot;所有简单路径:&quot;)
for path in paths:
    print(path)

# 独立路径的数量
print(&quot;独立路径的数量:&quot;, len(paths))</code></pre><p>这个代码计算了从节点 6 到节点 0 的所有简单路径。请注意，这些路径可能在某些较复杂的图结构中共享边。如果你的网络足够大或复杂，计算所有独立路径的数量可能会变得非常困难，甚至不可行，因为可能的路径数量随着网络的大小和复杂性指数级增长。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312190940766.png-wms#vwid=921&vhei=635" src="https://image.manyacan.com/202312190940766.png-wms#vwid=921&vhei=635"></figure></p><h4 id="toc_73">离心率</h4><p>离心率（Eccentricity）用于描述一个节点到图中所有其他节点的最短路径中最长的那一个。对于图中的节点 <code>v</code>，其离心率定义为从 <code>v</code> 到图中所有其他节点的最短路径的最大长度。公式表示为：</p><p>$$
\text{Eccentricity}(v) = \max_{u \in G} d(v, u)
$$</p><p>其中，<code>d(v, u)</code> 是节点 <code>v</code> 和 <code>u</code> 之间的最短路径长度。</p><ul><li>如果不指定节点 <code>v</code>，<code>nx.eccentricity(G)</code> 返回一个字典，包含图 <code>G</code> 中每个节点的离心率。</li><li>如果指定节点 <code>v</code>，<code>nx.eccentricity(G, v)</code> 返回节点 <code>v</code> 的离心率。</li></ul><blockquote><ul><li>离心率仅适用于连通图。在不连通的图中，某些节点间可能不存在路径，因此无法计算离心率。</li><li>在有向图中，应考虑路径的方向性，这可能影响离心率的计算结果。</li></ul></blockquote><h4 id="toc_74">网络直径</h4><p>网络直径是图论中的一个重要概念，它指的是网络中所有节点对的最短路径中最长的那一个。</p><p>对于连通图：</p><pre><code class="lang-python"># 计算直径
diameter = nx.diameter(G)
print(&quot;网络的直径是:&quot;, diameter)</code></pre><p>如果图不连通（即存在不可达的节点对），这个函数将会抛出错误。在处理不连通图时，你可能需要先找出图中的连通分量，然后分别计算每个连通分量的直径。</p><pre><code class="lang-python">G = nx.Graph()

G.add_edges_from([
    (0, 1), (0, 2), (0, 7),
    (1, 2), (1, 3), (1, 4), (1, 7),
    (2, 3),
    (3, 4), (3, 5), (3, 7),
    (4, 5), (4, 6), (4, 7),
    (5, 6),
    (8,9),(9,10),(10,8)
])

nx.draw(G, node_size=500, with_labels=True)

# 找出所有连通分量
connected_components = nx.connected_components(G)

# 遍历每个连通分量，并计算其直径
for i, component in enumerate(connected_components):
    subgraph = G.subgraph(component)
    diameter = nx.diameter(subgraph)
    print(f&quot;连通分量 {i+1} 的直径是: {diameter}&quot;)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312190928907.png-wms#vwid=1087&vhei=908" src="https://image.manyacan.com/202312190928907.png-wms#vwid=1087&vhei=908"></figure></p><p>离心率（Eccentricity）和图的直径（Diameter）是图论中两个密切相关的概念，它们都与图中节点间距离的概念有关。</p><ol><li><strong>离心率（Eccentricity）</strong>：公式表示为：$ \text{eccentricity}(v) = \max_{u \in G} d(v, u) $，其中 $ d(v, u) $ 是节点 $ v $ 到节点 $ u $ 的最短路径长度。</li><li><strong>图的直径（Diameter）</strong>：$ \text{diameter}(G) = \max_{v \in G} \text{eccentricity}(v) $。</li></ol><p>图的直径实际上是图中所有节点离心率的最大值。换句话说，直径是图中具有最大离心率的节点的离心率。一个节点的离心率告诉我们从该节点到达图中任何其他节点所需的最长距离。而图的直径则告诉我们在整个图中，任意两个节点之间的最长最短路径长度。</p><p>在一个连通图中，最远的节点对的最短路径长度等于该图的直径。</p><p>因此，离心率和直径都是衡量图中节点间距离的重要指标，但离心率着重于单个节点与其他所有节点的最远距离，而直径关注的是整个图中任意两个节点间的最远距离。</p><h3 id="toc_75">效率、平均局部效率、全局效率</h3><ol><li><p><strong>节点对之间的效率（Efficiency between Node Pairs）</strong>:</p><ul><li><strong>定义</strong>：节点对之间的效率是衡量这两个节点之间路径效率的指标。它是节点间最短路径的倒数。</li><li><strong>公式</strong>：$E_{ij} = \frac{1}{d(i, j)}$，其中，$ E_{ij} $ 是节点 $ i $ 和节点 $ j $ 之间的效率，$ d(i, j) $ 是它们之间的最短路径长度。</li><li>NetworkX代码：<code>nx.efficiency(G, 3, 7)</code>。</li></ul></li><li><p><strong>平均局部效率（Average Local Efficiency）</strong>:</p><ul><li><strong>定义</strong>：平均局部效率是网络中每个节点的局部效率的平均值。局部效率是一个节点的邻居间效率的平均值。</li><li><strong>公式</strong>：$E_{local}(i) = \frac{1}{N_i} \sum_{j, h \in G_i, j \neq h} \frac{1}{d(j, h)}$，其中，$ G_i $ 是节点 $ i $ 的邻居子图，$ N_i $ 是子图中节点的数量，$ d(j, h) $ 是子图中节点 $ j $ 和 $ h $ 之间的最短路径长度。</li><li>NetworkX代码：<code>nx.local_efficiency(G)</code>。</li></ul></li><li><p><strong>全局效率（Global Efficiency）</strong>:</p><ul><li><strong>定义</strong>：全局效率是网络中所有节点对效率的平均值。它反映了网络整体的交换或通信效率。</li><li><strong>公式</strong>：$E_{global} = \frac{1}{N(N-1)} \sum_{i \neq j \in G} \frac{1}{d(i, j)}$，其中，$ N $ 是图中的节点总数。</li><li>NetworkX代码：<code>nx.global_efficiency(G)</code>。</li></ul></li></ol><h3 id="toc_76">集聚系数、平均集聚系数与全局集聚系数</h3><p>演示实例：</p><pre><code class="lang-python">G = nx.Graph()
G.add_edges_from([(1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5)])
nx.draw(G, node_size=500, with_labels=True)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312111553020.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312111553020.png-wms#vwid=660&vhei=499"></figure></p><p>在图论中，<strong>集聚系数</strong>（Clustering Coefficient）是用于度量节点周围邻居之间连接紧密程度的指标。它可以帮助我们了解图中的局部连接性。有三种主要的集聚系数：节点的集聚系数、平均集聚系数和全局集聚系数。</p><p>节点的集聚系数是一个节点邻居之间实际存在的边数与可能存在的最大边数之比。对于一个无向图中的节点 $i$，其集聚系数 $C_i$ 的计算方式如下：</p><p>$$
C_i = \frac{2 \times \text{实际存在的边数}}{\text{邻居节点数} \times (\text{邻居节点数} - 1)}
$$</p><p>这个值在 [0, 1] 范围内，表示节点的邻居之间连接紧密的程度。</p><pre><code class="lang-python"># 计算节点的集聚系数
node_clustering = nx.clustering(G)
print(&quot;节点的集聚系数:&quot;, node_clustering)</code></pre><blockquote><p>节点的集聚系数: {1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0}</p></blockquote><p>以节点2为例，节点2的邻居节点是1、3、4、5。节点1、3、4、5可能存在的最大边数组合为$C_4^2 = \frac{4 \times 3}{2 \times 1} = 6$.</p><p>$$
C_n^k = \frac{n!}{k!(n-k)!}
$$</p><p>节点1、3、4、5实际存在的连接情况是：</p><pre><code class="lang-markdown">1: [1, 3], [1, 4], [1, 5]
3: [3, 4], [3, 5]
4: [4, 5]</code></pre><p>共有6种。因此，节点2的聚集系数为1.</p><p><strong>平均集聚系数</strong>是图中所有节点的集聚系数的平均值。对于一个无向图 $G$，其平均集聚系数 $C$ 的计算方式如下：</p><p>$$
C = \frac{1}{n} \sum_{i=1}^{n} C_i
$$</p><p>其中，$n$ 是图中的节点数。</p><pre><code class="lang-python"># 计算平均集聚系数
average_clustering = nx.average_clustering(G)
print(&quot;平均集聚系数:&quot;, average_clustering)</code></pre><p><strong>全局集聚系数</strong>是图中所有闭合三角形的数量与所有可能的闭合三角形的数量的比值。闭合三角形是由三个节点和它们之间的边组成的子图。对于一个无向图 $G$，其全局集聚系数 $C_{\text{global}}$ 的计算方式如下：</p><p>$$
C_{\text{global}} = \frac{\text{3×闭合三元组的数量}}{\text{连接三元组的数量}}
$$</p><blockquote><p>连接三元组（Open Triplet）是图论中的一个概念，它指的是在图中任选三个节点，其中至少有两个节点是相互连接的。这种三元组被称为“开放的”，因为它们不一定构成一个闭合的三角形。连接三元组是用来计算图的集聚系数的一个重要概念。</p><p>在具体的定义中，连接三元组通常包含以下两种情况：</p><ol><li><strong>闭合三元组（Closed Triplet）</strong>：这是图中的三个节点，它们之间的每一对节点都相互连接。换句话说，这三个节点形成了一个闭合的三角形。</li><li><strong>非闭合三元组</strong>：这也是图中的三个节点，但它们之间不是每一对节点都相互连接。这意味着虽然其中两个节点之间有边相连，但至少有一对节点之间没有直接的连线，因此不形成闭合的三角形。</li></ol><p>在计算图的全局集聚系数时，会考虑图中所有可能的连接三元组。全局集聚系数是闭合三元组数量与连接三元组总数量的比例。这个比例说明了在所有可能形成三角形的节点组合中，有多少实际形成了闭合的三角形。</p><p>例如，在社交网络分析中，闭合三元组可能表示一种更强的社会关系，因为如果A认识B，B认识C，且A也认识C，这可能意味着这三个人之间有更紧密的社交联系。而非闭合的三元组则可能表示潜在的、未完全形成的社交联系。</p></blockquote><p><strong>平均集聚系数关注的是每个节点的局部连接性，而全局集聚系数关注的是整个图中的全局连接性。</strong></p><pre><code class="lang-python"># 计算全局集聚系数
global_clustering = nx.transitivity(G)
print(&quot;全局集聚系数:&quot;, global_clustering)</code></pre><blockquote><p>全局集聚系数: 1.0</p></blockquote><p>上面的示例图是一个完全图（任意两个顶点都是相连的），在完全图中，每一组三个节点都会形成一个闭合三角形，所以闭合三元组的数量等于连接三元组的数量。因此，全局集聚系数是 1.0。</p><p>实际存在的闭合三角形的数量（闭合三元组的数量）：</p><pre><code class="lang-python">from itertools import combinations

# 获取图中所有可能的闭合三角形数量
all_triangles_count = 0

for node in G.nodes():  # 遍历所有节点
    neighbors = set(G.neighbors(node))  # 获取该节点的所有邻居节点
    for pair in combinations(neighbors, 2):  # 获取所有邻居节点的两两组合
        if G.has_edge(pair[0], pair[1]):  # 检查这个两两组合之间是否有边(因为它俩都是node的邻居节点，因此它俩肯定与node相连)，如果它俩相连，那么就说明node与pair[0]、pair[1]构成了三角形.
            all_triangles_count += 1</code></pre><p>上面的代码等同于：</p><pre><code class="lang-python"># 获取图中实际存在的闭合三角形数量(也需要除以3)
actual_triangles_count = sum(nx.triangles(G).values()) </code></pre><blockquote><p>需要注意的是：<code>all_triangles_count</code>需要除以3得到的才是闭合三元组的数量，因为闭合三元组中的三个顶点会在不同的组合中进行重复计算。</p></blockquote><p>连接三元组的数量：</p><pre><code class="lang-python">open_triplets_count = 0

for node in G.nodes():
    neighbors_count = len(list(G.neighbors(node)))
    open_triplets_count += (neighbors_count * (neighbors_count - 1)) // 2

# open_triplets_count 现在就是图中连接三元组的总数量</code></pre><blockquote><p>从 $n$ 个数中随机挑选出 2 个的组合数可以用组合数学中的公式来计算，这个公式是 $ C(n, 2) $ 或者 $ \binom{n}{2} $，可以表示为：</p><p>$$
C(n, 2) = \frac{n!}{2!(n-2)!} = \frac{n \times (n-1)}{2}
$$</p></blockquote><h3 id="toc_77">图的连通性</h3><p><strong>连通性</strong>描述的是图中节点之间是否存在路径相连的性质。一个图是连通的，意味着从图中的任意一个节点到另一个节点都存在路径。</p><h4 id="toc_78">图结构连通性的简单判断</h4><pre><code class="lang-python">G = nx.Graph()
G.add_nodes_from([i for i in range(1, 8)])
G.add_edges_from([(1, 2), (1, 3), (2, 3), (4, 7), (5, 6), (5, 7), (6, 7)])
nx.draw(G, node_size=500, with_labels=True)

# 查看图的连通性
nx.is_connected(G)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312111540677.png-wms#vwid=1035&vhei=829" src="https://image.manyacan.com/202312111540677.png-wms#vwid=1035&vhei=829"></figure></p><p>什么叫做图的连通性？在无向图中，如果对于每一对不同的顶点 $u$ 和 $v$，都存在至少一条由边连接的路径从 $u$ 到 $v$，则该图是连通的。请注意这个概念并不等同于完全图的概念，完全图的概念是每一对不同的顶点 $u$ 和 $v$都直接相连，而连通图的每一对不同的顶点 $u$ 都可以达到 $v$，两者可以不直接相连。</p><h4 id="toc_79">Fiedler值与图连通性的关系</h4><p>通过创建两个图来展示不同的连通性：</p><pre><code class="lang-python"># 创建具有较强连通性的图（低Fiedler值）
G_strong = nx.Graph()
G_strong.add_edges_from([(1, 2), (2, 3), (3, 4), (4, 1), (1, 3), (2, 4)])

# 创建具有较弱连通性的图（高Fiedler值）
G_weak = nx.Graph()
G_weak.add_edges_from([(1, 2), (2, 3), (3, 4)])

# 绘制这两个图
plt.figure(figsize=(12, 6))

# 绘制具有较强连通性的图
plt.subplot(1, 2, 1)
nx.draw(G_strong, with_labels=True, node_color='lightblue', node_size=700)
plt.title(&quot;Strongly Connected Graph&quot;)

# 绘制具有较弱连通性的图
plt.subplot(1, 2, 2)
nx.draw(G_weak, with_labels=True, node_color='lightgreen', node_size=700)
plt.title(&quot;Weakly Connected Graph&quot;)

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312121055137.png-wms#vwid=950&vhei=504" src="https://image.manyacan.com/202312121055137.png-wms#vwid=950&vhei=504"></figure></p><p>可以看出，左边的图具有更高的连通性，其应该具有更高的高Fiedler值，表明要将图分割成孤立的子图，需要切断更多的边。这通常表示图在整体上更加紧密连接，没有明显的弱连接点。右边的图具有更低的连通性，表明图可以通过切断较少的边来分割成不同的部分。这通常发生在图中存在一个或多个"瓶颈"区域，这些区域的边相对较少，是连接大的图区域的桥梁。</p><div class="photos large"><figure><img class="" alt="G_strong" data-src="https://image.manyacan.com/202312121045147.png-wms#vwid=547&vhei=435" src="https://image.manyacan.com/202312121045147.png-wms#vwid=547&vhei=435"><figcaption>G_strong</figcaption></figure><figure><img class="" alt="G_weak" data-src="https://image.manyacan.com/202312121047067.png-wms#vwid=547&vhei=435" src="https://image.manyacan.com/202312121047067.png-wms#vwid=547&vhei=435"><figcaption>G_weak</figcaption></figure></div><p>通过对两个图结构的拉普拉斯矩阵进行特征值分解发现，左边图结构的Fiedler值为4.0，而右边的为0.586左右。因此，说明左边图结构的连通性更强。</p><blockquote><h6 id="toc_80">Thinking/ 思考</h6><p>两点自己的思考：</p><ol><li>对于一个管网系统来说，Fiedler似乎可以反应该管网的冗余性，Fiedler值越大说明该管网中网状结构越多。</li><li>如果对一个管网进行切分，是否可以设计一种算法，来使得切出来的这个分区的Fiedler值最小，这样就保证了“切最少的管道”就可以得到了这个分区。</li></ol></blockquote><h4 id="toc_81">遍历所有连通分量</h4><p>请查看上面“网络直径”一节中，如何遍历图中所有连通分量并获取其网络直径。</p><h4 id="toc_82">节点对之间的连通性</h4><p>在图论中，节点连通性是指在不破坏图的连通性的情况下，可以从图中移除的最小节点数，以便特定的两个节点不再连通。换句话说，<strong>它是指在保持图的连通性的前提下，需要移除的节点数，才能使得这两个节点不再通过任何路径相连。</strong></p><p>获取所有节点对之间的连通性：</p><pre><code class="lang-python">from networkx.algorithms import approximation as approx

# 计算所有节点对之间的节点连通性：独立路径数量
print(approx.all_pairs_node_connectivity(G))</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312190957471.png-wms#vwid=1369&vhei=643" src="https://image.manyacan.com/202312190957471.png-wms#vwid=1369&vhei=643"></figure></p><p>获取单个节点对之间的连通性：</p><pre><code class="lang-python">approx.local_node_connectivity(G, 6, 0)</code></pre><blockquote><p>上面的代码返回结果是2，就代表图中节点6与节点0之间的连通性是2。也就说明，如果要破坏节点2与节点6之间的连通性，最少要移除两条边才可以。</p></blockquote><h4 id="toc_83">全局连通性</h4><p>全局连通性是指整个图的最小节点连通性，也就是在保持图连通的情况下，需要从图中移除的最少节点数，使得图变得不连通。</p><pre><code class="lang-python">approx.node_connectivity(G)</code></pre><p>函数将返回图 $G$ 的节点连通性，即使图变得不连通所需移除的最少节点数。这个值为整个图的一个全局度量，而不是针对特定节点对的。</p><blockquote><p>一个特殊的图结构——柏拉图式的八面体图：</p><pre><code class="lang-python">G2 = nx.octahedral_graph() # 柏拉图式的八面体图
nx.draw(G2, node_size=500, with_labels=True)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312191006678.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312191006678.png-wms#vwid=660&vhei=499"></figure></p><pre><code class="lang-python">print(approx.all_pairs_node_connectivity(G2))
print(approx.node_connectivity(G2))</code></pre><p>这个图结构所有节点间的连通性都是4。因此，其全局连通性也是4。</p></blockquote><h4 id="toc_84">NetworkX中关于连通分量的一些其他操作</h4><p>获取连通组件（子图）的数量：</p><pre><code class="lang-python">print(nx.number_connected_components(G))</code></pre><p>对所有联通分量按照节点数的多少排序，获取最大连通子图并绘图：</p><pre><code class="lang-python">Gcc = sorted(nx.connected_components(G), key=len, reverse=True)

# 获取最大连通子图
largest_cc = G.subgraph(Gcc[0])
nx.draw(largest_cc, node_size=500, with_labels=True)</code></pre><p>复制连通分量，并进行修改：</p><pre><code class="lang-python"># largest_cc.add_edge(3,6) # 连通子图不支持修改：NetworkXError: Frozen graph can't be modified
# 可以复制，在复制的图上修改
LCC = largest_cc.copy()
LCC.add_edge(3,6)
nx.draw(LCC, node_size=500, with_labels=True)</code></pre><h3 id="toc_85">链接密度</h3><p>Link Density（链接密度）通常是用于网络分析中的一个概念，特别是在图论和社交网络分析中。它描述了网络中链接（或边）的数量与网络中可能存在的最大链接数量之间的比例。换句话说，它衡量了网络的饱和度或连接紧密程度。</p><p>$$
\text{Link Density} = \frac{2E}{N(N-1)}
$$</p><p>其中：</p><ul><li>$ E $ 是图中实际存在的边的数量。</li><li>$ N $ 是图中节点的数量。</li></ul><p>对于一个有向图，由于边的方向性，计算公式略有不同：</p><p>$$
\text{Link Density} = \frac{E}{N(N-1)}
$$</p><p>在这个公式中：</p><ul><li>$ E $ 仍然代表边的数量。</li><li>$ N $ 代表节点的数量。</li><li>因子“2”在无向图中用于考虑每条边连接两个不同的节点，而在有向图中则不需要。</li></ul><p><strong>解释：</strong></p><ul><li>当Link Density接近1时，表示网络中的节点之间几乎全部相互连接，这是一个高度紧密的网络。</li><li>当Link Density接近0时，表示网络中的节点之间很少连接，这是一个稀疏网络。</li></ul><p><strong>举例：</strong></p><pre><code class="lang-python">import networkx as nx
import matplotlib.pyplot as plt

# 创建一个完全连接的网络（Link Density = 1）
G1 = nx.complete_graph(5)

# 创建一个稀疏连接的网络（较小的Link Density）
G2 = nx.Graph()
G2.add_edges_from([(0, 1), (1, 2), (3, 4)])  # 只添加几条边

# 绘制这两个网络
plt.figure(figsize=(12, 6))

# 绘制完全连接的网络
plt.subplot(121)
nx.draw(G1, with_labels=True, node_color='lightblue', node_size=800)
plt.title(&quot;Link Density = 1&quot;)

# 绘制稀疏连接的网络
plt.subplot(122)
nx.draw(G2, with_labels=True, node_color='lightgreen', node_size=800)
plt.title(&quot;Link Density &lt; 1&quot;)

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312141702657.png-wms#vwid=950&vhei=504" src="https://image.manyacan.com/202312141702657.png-wms#vwid=950&vhei=504"></figure></p><p>在NetworkX中获取图结构的连接密度：</p><pre><code class="lang-python">print(nx.density(G1), nx.density(G2))</code></pre><p>其实可以发现，对于一个图，如果<code>Link Density=1</code>，那么其就是一个完全图。</p><h3 id="toc_86">网格系数</h3><p>网格系数（Meshedness Coefficient）是图论中用于特别衡量平面图的一个指标。它测量图中有界面的数量与具有相同顶点数量的其他平面图可能拥有的面的数量之间的比例。这个系数有助于理解图中的网格程度或互连程度。</p><ul><li>网格系数为0表示树状结构，没有循环，代表最小的连通性。</li><li>系数为1代表最大平面图，表示高度互连的结构，具有最大数量的面。</li></ul><p>在平面图中计算网格系数涉及计算有界面的数量（f）并将其与具有相同顶点数的图的最大可能面数进行比较。网格系数（M）的计算公式为：</p><p>$$
M = \frac{f - 1}{2v - 5}
$$</p><p>其中：</p><ul><li>$ f $ 是图中有界面的数量；</li><li>$ v $ 是图中顶点的数量。</li></ul><blockquote><h5 id="toc_87">Tips / 提示</h5><p>什么叫做有界面的数量？在图论和网络分析中，"有界面的数量"（或简称为"面"）是指平面图中被边界包围的区域的数量。</p></blockquote><p>编写一个计算网格系数的函数：</p><pre><code class="lang-python"># 在NetworkX中计算网格系数
def calculate_meshedness(G):
    &quot;&quot;&quot;计算网格系数&quot;&quot;&quot;
    # 计算有界面的数量：边的数量 - 顶点的数量 + 1
    f = G.number_of_edges() - G.number_of_nodes() + 1
    # 计算网格系数
    v = G.number_of_nodes()
    if v &gt; 2:
        M = (f - 1) / (2 * v - 5)
    else:
        M = 0  # 对于少于3个顶点的图，网格系数无意义
    return M</code></pre><h3 id="toc_88">代数连通性</h3><p><strong>代数连通性（Algebraic Connectivity）</strong>是图的拉普拉斯矩阵的第二小的特征值。</p><p>在 <code>NetworkX</code> 中，可以使用 <code>nx.algebraic_connectivity(G)</code> 函数来计算图 $G$ 的代数连通性。这个函数内部会完成上述的计算步骤，并返回代数连通性的值。</p><p>代数连通性通常也被称为Fiedler值。有关其更详细的解释，请看下面“特征值分解的意义”章节。</p><h3 id="toc_89">点中心性</h3><p><strong>点中心性（degree centrality）</strong>是最基本的中心性度量之一，它反映了节点的连接数相对于网络中可能的连接数的比例。在无向图中，点中心性简单地等于某个节点的邻接节点数（或者说是边数）除以可能的最大邻接节点数（即网络中节点总数减去1）。</p><h4 id="toc_90">度中心性</h4><p>对于网络中的节点 $ v $，其<strong>度中心性（Degree Centrality）</strong> $ C_D(v) $ 可以通过以下公式计算：</p><p>$$
C_D(v) = \frac{\text{节点 } v \text{ 的度数}}{N - 1}
$$</p><p>其中，$ N $ 是网络中节点的总数。</p><p>在 <code>NetworkX</code> 中，可以使用 <code>degree_centrality(G)</code> 函数来计算所有节点的点中心性。这个函数返回一个字典，其中键是节点，值是对应节点的点中心性。</p><h4 id="toc_91">其他几种中心性</h4><ol><li><p><strong>特征向量中心性（Eigenvector Centrality）</strong>:</p><ul><li><strong>定义</strong>：特征向量中心性考虑了一个节点的邻居的重要性。一个节点的特征向量中心性高，如果它连接到许多其他具有高中心性的节点。</li><li><strong>公式</strong>：$ C_E(v) = \frac{1}{\lambda} \sum_{t \in M(v)} C_E(t) $<br>  其中，$ C_E(v) $ 是节点 $ v $ 的特征向量中心性，$ M(v) $ 是与 $ v $ 直接相连的节点集合，$ \lambda $ 是特征值。</li></ul></li><li><p><strong>接近度中心性（Closeness Centrality）</strong>:</p><ul><li><strong>定义</strong>：接近度中心性基于节点到网络中所有其他节点的平均最短路径长度。距离越短，接近度中心性越高。</li><li><strong>公式</strong>：$ C_C(v) = \frac{N-1}{\sum_{t \neq v} d(v, t)} $，其中$ C_C(v) $ 是节点 $ v $ 的接近度中心性，$ d(v, t) $ 是节点 $ v $ 到 $ t $ 的最短路径长度。</li></ul></li><li><p><strong>介数中心性（Betweenness Centrality）</strong>:</p><ul><li><strong>定义</strong>：介数中心性是基于节点在网络中所有最短路径中出现的频率。一个节点的介数中心性高，如果更多的最短路径通过它。</li><li><strong>公式</strong>：$ C_B(v) = \sum_{s \neq v \neq t} \frac{\sigma_{st}(v)}{\sigma_{st}} $，其中，$ C_B(v) $ 是节点 $ v $ 的介数中心性，$ \sigma_{st} $ 是节点 $ s $ 到 $ t $ 的所有最短路径的数量，$ \sigma_{st}(v) $ 是经过节点 $ v $ 的那些路径的数量。</li></ul></li><li><p><strong>PageRank中心性（PageRank Centrality）</strong>:</p><ul><li><strong>定义</strong>：PageRank是衡量网页重要性的算法，但也可用于网络中。一个节点的PageRank高，如果有许多其他高PageRank的节点指向它。</li><li><strong>公式</strong>：$ PR(v) = \frac{1-d}{N} + d \sum_{t \in M(v)} \frac{PR(t)}{L(t)} $，其中，$ PR(v) $ 是节点 $ v $ 的PageRank值，$ M(v) $ 是指向 $ v $ 的节点集合，$ L(t) $ 是节点 $ t $ 的出度，$ d $ 是阻尼系数（通常设为0.85）。</li></ul></li></ol><p>如何在NetworkX中获得：</p><pre><code class="lang-python"># 度中心性（Degree Centrality）
nx.degree_centrality(G)

# 特征向量中心性（Eigenvector Centrality）
nx.eigenvector_centrality(G)

# 接近度中心性（Closeness Centrality）
nx.closeness_centrality(G)

# 介数中心性（Betweenness Centrality）
nx.betweenness_centrality(G)

# PageRank中心性（PageRank Centrality）
nx.pagerank(G)</code></pre><h3 id="toc_92">中心点优势</h3><p><strong>Central-point dominance（中心点优势）</strong>是网络分析中的一个度量，用来量化网络中最中心节点的控制力相对于网络中其他节点的控制力。它是由Linton Freeman在1977年提出的。这个度量是基于中心性的概念，特别是点中心性（point centrality）。</p><p>在某个网络中，中心点优势是由网络中点中心性最高的节点（即最中心的节点）的点中心性值，减去网络中所有节点的点中心性平均值，再除以最大可能的差值来计算的。</p><p>计算步骤如下：</p><ol><li>计算网络中每个节点的点中心性（可以是接近中心性、介数中心性或特征向量中心性等）。</li><li>找到具有最高点中心性的节点。</li><li>计算该节点的点中心性与所有节点的点中心性平均值的差值。</li><li>除以最大可能的差值，这通常是最中心节点的点中心性减去最小可能的点中心性（通常是1/n，其中n是节点总数）。</li></ol><p>公式表示为：</p><p>$$
CPD = \frac{C_{max} - \overline{C}}{Max(C_{max} - C_i)}
$$</p><p>其中：</p><ul><li>$ CPD $ 是中心点优势。</li><li>$ C_{max} $ 是最高点中心性。</li><li>$ \overline{C} $ 是所有节点点中心性的平均值。</li><li>$ Max(C_{max} - C_i) $ 是最高点中心性与任意节点中心性之差的最大可能值。</li></ul><p>在 <code>NetworkX</code> 中没有直接计算中心点优势的函数，但可以使用已有的中心性计算函数和一些额外的计算步骤来求解。</p><p>中心点优势的具体含义包括：</p><ol><li><strong>网络权力集中度</strong>：CPD较高意味着网络中有一个或几个节点拥有远高于其他节点的中心性，表明网络中的权力或影响力可能非常集中。</li><li><strong>脆弱性和稳健性</strong>：当一个网络的CPD很高时，网络可能对最中心节点的移除或故障非常敏感。这可能会影响网络的整体功能和稳定性。</li><li><strong>信息流动和效率</strong>：一个中心点优势很高的网络可能会有更有效的信息流动，因为中心节点可以作为信息流动的枢纽。然而，这也可能导致信息过度集中，使得网络对于中心节点的依赖度增加。</li></ol><blockquote><h6 id="toc_93">Thinking/ 思考</h6><p>在给水管网的图结构中，中心点优势（Central Point Dominance, CPD）可以有以下几种现实意义：</p><ol><li><strong>关键节点的识别</strong>：高中心点优势意味着给水管网中存在一个或几个关键节点，这些节点对整个网络的运作至关重要。例如，这可能是主要的水源地、水处理中心或主要的分配点。</li><li><strong>网络脆弱性分析</strong>：如果给水管网的中心点优势很高，这可能表明网络对单个节点或几个节点的依赖性很大。这样的网络可能对于这些关键节点的故障或损坏特别敏感，从而影响整个网络的供水能力。</li><li><strong>优化和升级规划</strong>：通过分析中心点优势，可以识别那些对整个给水管网至关重要的节点，从而有助于优先考虑这些节点的维护、升级或加固，以提高网络的整体效率和可靠性。</li><li><strong>应急响应和风险管理</strong>：在应对突发情况（如管道破裂、污染事件等）时，了解中心点优势可以帮助决策者优先处理那些对整个网络影响最大的节点，从而更有效地减轻整体影响。</li><li><strong>提高供水效率</strong>：通过优化中心节点的运作，可以提高整个给水系统的供水效率和效果，确保水资源的合理分配和使用。</li></ol><p>因此，在给水管网的管理和优化中，理解和分析中心点优势是非常重要的，它有助于指导网络设计、运维、危机管理和改进策略。</p><p>实际数据分析表明，CPD与管网节点数呈现略微正相关关系，这表明节点数越多的管网中，网络对单个节点或几个节点的依赖性越大。这是为什么呢？不科学啊？不应该是越大的管网抵抗风险的能力越强吗？</p></blockquote><h3 id="toc_94">关键比例</h3><p><strong>"Critical Fraction"（关键比例）</strong>是网络科学中的一个概念，通常用于描述网络在遭受随机故障或有意攻击时维持功能的能力。具体来说，它指的是导致网络失去大规模连通性或功能的最小比例的节点或边的移除。这个概念在理解和评估网络的鲁棒性和脆弱性方面非常重要。</p><p>举个🌰，创建两个随机图结构：</p><pre><code class="lang-python">import networkx as nx

# 创建两个网络
G_A = nx.erdos_renyi_graph(100, 0.05)  # 网络A
G_B = nx.watts_strogatz_graph(100, 4, 0.1)  # 网络B

# 准备绘制网络结构图和度分布统计图
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# 在左边绘制网络图
nx.draw(G_A, ax=ax1, node_size=50, with_labels=False)
nx.draw(G_B, ax=ax2, node_size=50, with_labels=False)

ax1.set_title(&quot;Graph A&quot;)
ax2.set_title(&quot;Graph B&quot;)
plt.show()</code></pre><p><figure><img class="" alt="两个随机图结构" data-src="https://image.manyacan.com/202312151430240.png-wms#vwid=1259&vhei=504" src="https://image.manyacan.com/202312151430240.png-wms#vwid=1259&vhei=504"><figcaption>两个随机图结构</figcaption></figure></p><p>定义一个计算关键比例的函数：</p><pre><code class="lang-python">import random


def calculate_critical_fraction(G: nx.Graph, iter_num: int = 100) -&gt; float:
    &quot;&quot;&quot;
    图结构关键比例计算函数
    :param G: 图结构对象, nx.Graph格式
    :param iter_num: 随机循环数量, 通过多次重复移除节点的实验, 并计算每次实验的关键比例, 然后取这些实验的平均值.
    :return: 多次计算关键比例的平均值,范围[0, 1]
    &quot;&quot;&quot;
    ratio = []

    for _ in range(iter_num):
        # 复制原始网络
        G_temp = G.copy()
        # 计算原始网络中最大连通分量的节点数
        original_size = max(len(c) for c in nx.connected_components(G_temp))
        for i in range(len(G_temp)):
            # 随机选择并移除一个节点
            node_to_remove = random.choice(list(G_temp.nodes()))
            G_temp.remove_node(node_to_remove)

            # 计算移除节点后网络中最大连通分量的节点数
            largest_cc_size = max(len(c) for c in nx.connected_components(G_temp))
            if largest_cc_size &lt;= original_size / 2:  # 如果移除节点后, 网络中最大连通分量的节点数小于原始网络中的1/2
                ratio.append(i)
                break

    # 返回平均关键比例
    return sum(ratio) / len(ratio) / len(G)</code></pre><p>对比两个图结构的关键比例：</p><pre><code class="lang-python">critical_fraction_A = calculate_critical_fraction(G_A.copy())
critical_fraction_B = calculate_critical_fraction(G_B.copy())

print(&quot;Critical Fraction of Network A:&quot;, critical_fraction_A)
print(&quot;Critical Fraction of Network B:&quot;, critical_fraction_B)</code></pre><blockquote><p>Critical Fraction of Network A: 0.45640000000000003<br>Critical Fraction of Network B: 0.3701</p></blockquote><p>比较两个网络的平均关键比例，发现$CF_A&gt;CF_B$，说明网络B在面临随机故障时更加脆弱。</p><blockquote><h6 id="toc_95">Thinking/ 思考</h6><p>感觉“关键比例”这个概念不适合用于对比两个给水管网在面临随机故障时的脆弱性。因为给水管网中节点的重要性并是仅仅是看哪个节点的度比较大（给水管网中节点的度都在1~4之间）。关键比例仅仅对比两个管网在随机减少节点后，具有最大连通分量的节点数量，这对于给水管网来说并不合理。</p></blockquote><h3 id="toc_96">K核值</h3><p>节点的 k-核（k-core）是一个网络分析中的概念，用于识别网络中的一个最大子图，在这个子图中，每个节点至少与 k 个其他节点相连。计算一个网络中所有节点的 k-核值的过程涉及到逐步移除度数小于 k 的节点，直到所有剩余的节点度数都大于或等于 k。</p><p>举个例子就明白了，创建一个图结构：</p><pre><code class="lang-python"># 创建图
G = nx.Graph()
G.add_node('W')
G.add_edges_from([('A', 'B'), ('A', 'C'), ('A', 'D'),
                 ('B', 'C'), ('C', 'D'), ('E', 'F'), ('B', 'D'), ('B', 'G'), ('G', 'C')])

nx.draw(G, node_size=500, with_labels=True)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192056948.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312192056948.png-wms#vwid=660&vhei=499"></figure></p><p>分别获取并绘制上面图结构中K核值为1、2、3的节点：</p><pre><code class="lang-python">import matplotlib.pyplot as plt
plt.rcParams.update({
'font.size': 20,
'font.family': ['Times New Roman', 'SimSun']
})

# 准备绘制网络结构图和度分布统计图
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 6))

k_1 = nx.k_core(G, k=1)
k_2 = nx.k_core(G, k=2)
k_3 = nx.k_core(G, k=3)

# 在左边绘制网络图
nx.draw(k_1, ax=ax1, node_size=500, with_labels=True, node_color='r')
nx.draw(k_2, ax=ax2, node_size=500, with_labels=True, node_color='g')
nx.draw(k_3, ax=ax3, node_size=500, with_labels=True, node_color='b')

ax1.set_title('K=1')
ax2.set_title('K=2')
ax3.set_title('K=3')
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192057774.png-wms#vwid=1260&vhei=513" src="https://image.manyacan.com/202312192057774.png-wms#vwid=1260&vhei=513"></figure></p><p>这个时候就很容易明白K核值的定义了：<code>nx.k_core(G, k=1)</code>返回的是图结构中度≥1的节点；<code>nx.k_core(G, k=2)</code>返回的是图结构中度≥2的节点；<code>nx.k_core(G, k=3)</code>返回的是图结构中度≥3的节点。</p><p>打印单个节点的K核值：</p><pre><code class="lang-python">for node, k_core in k_core_values.items():
    print(&quot;节点&quot;, node, &quot;的K核值是&quot;, k_core)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192100548.png-wms#vwid=1433&vhei=511" src="https://image.manyacan.com/202312192100548.png-wms#vwid=1433&vhei=511"></figure></p><p>我们会发现打印结果与上面的分析结论是一样的。</p><h3 id="toc_97">度同配性</h3><p>如果网络中度数相似的节点倾向于相互连接，即高度数的节点倾向于与其他高度数的节点相连，低度数的节点倾向于与其他低度数的节点相连，这种现象称为度同配（Assortative Mixing）。</p><p><strong>度同配性（Degree Assortativity）</strong>度同配性系数是一个介于 -1 和 1 之间的数值，用来量化度同配性的程度。系数接近 1 表示强同配性，即网络中类似度数的节点倾向于相互连接。系数接近 -1 表示强异配性，即网络中不同度数的节点倾向于相互连接。</p><p>在 <code>networkx</code> 中，可以使用 <code>nx.degree_assortativity_coefficient(G)</code> 来计算图 <code>G</code> 的度同配性系数。这个函数会考虑图中每个节点的度数，并计算整个网络的度同配性。</p><p>度同配性系数的计算涉及到评估网络中节点的度数（即每个节点的连接数）之间的相关性。具体计算方法基于皮尔逊相关系数，但是针对的是节点的度数而不是节点的特征或标签。</p><p>计算步骤：</p><ol><li><p><strong>准备数据</strong>：</p><ul><li>对于每条边，考虑其两个端点的度数。例如，如果一条边连接度为2的节点和度为3的节点，则这条边对应于（2,3）和（3,2）两组度数对。</li></ul></li><li><p><strong>计算平均度数和方差</strong>：</p><ul><li>计算网络中所有节点度数的平均值和方差。</li></ul></li><li><p><strong>计算协方差</strong>：</p><ul><li>对于所有边的度数对，计算它们的协方差。协方差测量两个变量（在这里是度数）之间的总体偏差。</li></ul></li><li><p><strong>应用皮尔逊相关系数公式</strong>：</p><ul><li>使用下面的公式计算度同配性系数：$r = \frac{\sum_{xy} xy(e_{xy} - a_x a_y)}{\sigma_a \sigma_b}$。其中，$ e_{xy} $ 是连接度数为 $ x $ 和 $ y $ 的节点的边的比例，$ a_x $ 是度数为 $ x $ 的节点的比例，$ \sigma_a $ 和 $ \sigma_b $ 是度分布的标准差。</li></ul></li></ol><h3 id="toc_98">桥连接</h3><p>（这个🌉名词实在是不知道怎么翻译……）</p><p>在图论中，桥是指图中的一条边，移除它会导致图的连通性分量增加。换句话说，桥是连接图中两个部分的唯一边，移除它会使这两部分变得不连通。举个例子：</p><pre><code class="lang-python">G_strong = nx.Graph()
G_strong.add_edges_from([
    (0, 1), (0, 2), (0, 7),
    (1, 2), (1, 3), (1, 7),
    (2, 3),
    (3, 5), (3, 7),
    (4, 5),(4, 6),
    (5, 6)
])

G_weak = G_strong.copy()
G_weak.remove_edge(3, 5)

# 绘制这两个图
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
nx.draw(G_strong, with_labels=True, node_color='lightblue', node_size=700)
plt.title(f&quot;Graph with a bridge{list(nx.bridges(G_strong))[0]}&quot;)

plt.subplot(1, 2, 2)
nx.draw(G_weak, with_labels=True, node_color='lightgreen', node_size=700)
plt.title(&quot;Graph with no bridges&quot;)

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201951209.png-wms#vwid=950&vhei=513" src="https://image.manyacan.com/202312201951209.png-wms#vwid=950&vhei=513"></figure></p><p>上面的左图中，边 (3, 5)就是一个Bridge，因为当切断这条边时，该图就会变成两个连通分量。</p><p><strong>桥连接分析网络的结构稳定性和脆弱性时非常有用，特别是在识别网络中的关键连接或潜在的脆弱点方面。</strong></p><p>在<code>NetworkX</code> 库中：</p><ul><li><code>nx.has_bridges(G)</code>：返回一个Bool值，返回 <code>True</code>，则表示图 <code>G</code> 中至少有一条边是桥；如果返回 <code>False</code>，则表示图中没有桥。</li><li><code>nx.bridges(G)</code>：返回一个可迭代对象，包含了网络中的所有桥。</li></ul><p>补充个知识点，还有个东西叫做“本地桥”，在<code>NetworkX</code> 库中使用<code>nx.local_bridges(G)</code>即可获取。</p><p>还是举个例子来说明吧：</p><pre><code class="lang-python">import networkx as nx

# 创建一个图
G = nx.Graph()
G.add_edges_from([
    ('A', 'B'),
    ('B', 'C'),
    ('C', 'D'),
    ('D', 'A'),
])

# 找出所有桥
print(&quot;图中的桥:&quot;)
for bridge in nx.bridges(G):
    print(bridge)

# 找出所有本地桥
print(&quot;\n图中的本地桥:&quot;)
for local_bridge in nx.local_bridges(G, with_span=True):
    print(local_bridge)

nx.draw(G, with_labels=True, node_color='lightblue', node_size=700)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312202020022.png-wms#vwid=1355&vhei=1190" src="https://image.manyacan.com/202312202020022.png-wms#vwid=1355&vhei=1190"></figure></p><p>在上面的图结构中，没有桥，因为断开任何一条边也不能让图变成两个连通分量。所谓“本地桥”是指，桥两端的节点在桥断开后，没有共同的节点相连。</p><p>将上面的图结构中，添加一个点E，使其与点A、点D相连，那么桥 (A, D ) 就不是本地桥了：</p><pre><code class="lang-python">G.add_edges_from([
    ('E', 'A'),
    ('E', 'D')
])

# 找出所有桥
print(&quot;图中的桥:&quot;)
for bridge in nx.bridges(G):
    print(bridge)

# 找出所有本地桥
print(&quot;\n图中的本地桥:&quot;)
for local_bridge in nx.local_bridges(G, with_span=True):
    print(local_bridge)

nx.draw(G, with_labels=True, node_color='lightblue', node_size=700)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312202027034.png-wms#vwid=1359&vhei=1131" src="https://image.manyacan.com/202312202027034.png-wms#vwid=1359&vhei=1131"></figure></p><h2 id="toc_99">图的特征值分解</h2><p>下面的讲解以<a href="https://www.researchgate.net/publication/329350163_Introduction_to_Graph_Signal_Processing">Introduction to Graph Signal Processing</a>中P19页的Fig. 10（图1，连通图）、P14页的Fig. 7（图2，非连通图）为例。</p><pre><code class="lang-python">G_strong = nx.Graph()
G_strong.add_edges_from([
    (0, 1), (0, 2), (0, 7),
    (1, 2), (1, 3), (1, 4), (1, 7),
    (2, 3),
    (3, 4), (3, 5), (3, 7),
    (4, 5), (4, 6), (4, 7),
    (5, 6)
])

G_weak = nx.Graph()
G_weak.add_edges_from([
    (0, 1), (0, 2),
    (1, 2),
    (3, 4), (3, 5), (3, 7),
    (4, 5), (4, 6), (4, 7),
    (5, 6)
])

# 绘制这两个图
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
nx.draw(G_strong, with_labels=True, node_color='lightblue', node_size=700)
plt.title(&quot;Strongly Connected Graph&quot;)

plt.subplot(1, 2, 2)
nx.draw(G_weak, with_labels=True, node_color='lightgreen', node_size=700)
plt.title(&quot;Weakly Connected Graph&quot;)

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312121500027.png-wms#vwid=950&vhei=504" src="https://image.manyacan.com/202312121500027.png-wms#vwid=950&vhei=504"></figure></p><h3 id="toc_100">特征值分解的意义</h3><p>邻接矩阵更倾向于揭示图的整体连通性，而拉普拉斯矩阵的特征值和特征向量则更多地用于研究图的局部结构特征，如社区结构或者图的连通分量。</p><p><strong>为什么拉普拉斯矩阵的第一个特征值总是0？</strong></p><p>拉普拉斯矩阵的第一个特征值总是0，其对应的特征向量是一个所有元素都相同的向量。这代表图中所有节点的均匀分布。</p><p>拉普拉斯矩阵 $ L $ 的第一个特征值总是 0 的原因与拉普拉斯矩阵的定义和图的性质有关。拉普拉斯矩阵 $ L $ 定义为度矩阵 $ D $ 减去邻接矩阵 $ A $，即 $ L = D - A $。</p><p>这里是为什么其第一个特征值总是 0：</p><ol><li><strong>和为零的行（列）</strong>：在拉普拉斯矩阵中，每一行的和（以及每一列的和，因为 $ L $ 是对称的）都是 0。这是因为每一行的非对角元素（即 $-A$ 的部分）与对角线上的元素（即 $ D $ 的部分，它是节点的度数）相加抵消。换句话说，对于每个节点 $ i $，它的度数 $ D_{ii} $ 等于与它相连的边的数量，而 $ -A $ 中的元素表示与节点 $ i $ 相连的邻居节点，因此当你在一行中把这些值加起来时，结果是 0。</li><li><strong>恒等特征向量</strong>：由于每行的和为零，这意味着全 1 向量（所有元素都是 1 的向量）是拉普拉斯矩阵的一个特征向量，因为 $ L \times \textbf{1} = \textbf{0} $（其中 $\textbf{1}$ 是全1向量，$\textbf{0}$ 是零向量）。这意味着乘以全 1 向量后，每行的元素相加都得到 0，这与零向量相匹配。</li><li><strong>特征值 0 的意义</strong>：特征值 0 对应的特征向量表示图中所有节点的均匀分布，它反映了图的连通性。对于连通图，特征值 0 是唯一的，它的代数重数（特征值的重复次数）等于图的连通分量的数量。因此，对于连通图，特征值 0 的代数重数是 1。如果图不是完全连通的，特征值 0 的代数重数将等于图的连通分量数量。</li></ol><p>简而言之，拉普拉斯矩阵的每一行和每一列的和为零这个属性保证了第一个特征值必定是0。这与图的基本性质密切相关，特别是与图的连通性有关。</p><p><strong>其他特征值的意义：</strong></p><ol><li><p><strong>第二个特征值（Fiedler值）和特征向量：</strong></p><ul><li>第二个最小的特征值通常被称为Fiedler值，它在图的谱聚类和社区检测中非常重要。Fiedler值的大小可以表示图的连通性：Fiedler值越小，图的连通性越弱。</li><li>对应的Fiedler向量可以用来识别图中的社区或集群。通过分析Fiedler向量的组件，可以将图划分为不同的部分，其中每个部分相对内部紧密连接，而与其他部分的连接较少。</li></ul></li><li><p><strong>其他特征值和特征向量</strong>：</p><ul><li>更高的特征值和对应的特征向量可以揭示图的更复杂的结构特征，如多层次的社区结构。</li><li>在某些情况下，这些特征向量也用于嵌入技术，将图的节点映射到低维空间，以便于可视化和进一步分析。</li></ul></li></ol><h3 id="toc_101">特征值分解</h3><p>下面对上面的示例图进行拉普拉斯矩阵的特征值分解。</p><h4 id="toc_102">拉普拉斯矩阵</h4><p>首先，获取图结构的拉普拉斯矩阵：</p><pre><code class="lang-python"># 获取拉普拉斯矩阵
L = nx.laplacian_matrix(G).toarray()
L</code></pre><p>$$
\begin{bmatrix}
3 &amp; -1 &amp; -1 &amp; -1 &amp;  0 &amp;  0 &amp;  0 &amp;  0 \\
-1 &amp;  5 &amp; -1 &amp; -1 &amp; -1 &amp; -1 &amp;  0 &amp;  0 \\
-1 &amp; -1 &amp;  3 &amp;  0 &amp; -1 &amp;  0 &amp;  0 &amp;  0 \\
-1 &amp; -1 &amp;  0 &amp;  4 &amp; -1 &amp; -1 &amp;  0 &amp;  0 \\
0 &amp; -1 &amp; -1 &amp; -1 &amp;  5 &amp; -1 &amp; -1 &amp;  0 \\
0 &amp; -1 &amp;  0 &amp; -1 &amp; -1 &amp;  5 &amp; -1 &amp; -1 \\
0 &amp;  0 &amp;  0 &amp;  0 &amp; -1 &amp; -1 &amp;  3 &amp; -1 \\
0 &amp;  0 &amp;  0 &amp;  0 &amp;  0 &amp; -1 &amp; -1 &amp;  2 \\
\end{bmatrix}
VS
\begin{bmatrix}
2 &amp; -1 &amp; -1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
-1 &amp; 2 &amp; -1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
-1 &amp; -1 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 3 &amp; -1 &amp; -1 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; -1 &amp; 4 &amp; -1 &amp; -1 &amp; -1 \\
0 &amp; 0 &amp; 0 &amp; -1 &amp; -1 &amp; 3 &amp; 0 &amp; -1 \\
0 &amp; 0 &amp; 0 &amp; -1 &amp; -1 &amp; 0 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; -1 &amp; -1 &amp; 0 &amp; 2 \\
\end{bmatrix}
$$</p><p>需要注意的是，返回的拉普拉斯矩阵的行列顺序并不与图中的顺序相同，矩阵中的行列数据是按照节点的添加顺序来的。如何查看节点的顺序：</p><pre><code class="lang-python">list(G.nodes())
# [0, 1, 2, 7, 3, 4, 5, 6]</code></pre><p>对于图1来说，因为节点7添加的早，所以排在节点3之前。也就是说，拉普拉斯矩阵中第4行代表的是第7个元素的连接情况。</p><h4 id="toc_103">特征值</h4><pre><code class="lang-python">#求矩阵特征值以及特征向量
eig_value, eig_vector = np.linalg.eig(L)
eig_value</code></pre><p>特征值及其可视化：</p><p>$$
[4.44089210e-16, 1.13357211e+00, 3.05427452e+00, 3.31740297e+00, 4.00000000e+00, 5.67905993e+00, 6.47332881e+00, 6.34236165e+00]
$$</p><pre><code class="lang-python">def autolabel(rects):
    for rect in rects:
        height = rect.get_height()
        height_pos = height + .1 if height &gt;= -0.1 else height - .1
        plt.text(
            rect.get_x() + rect.get_width() / 2,
            height_pos,
            '{:.5f}'.format(height),
            size=10,
            family=&quot;Times new roman&quot;,
            horizontalalignment='center',
            verticalalignment='center'
        )


fig = plt.bar([i for i in range(len(eig_value))], np.sort(eig_value))
autolabel(fig)

plt.title('Eigenvalues')
plt.show()</code></pre><div class="photos large"><figure><img class="" alt="图1" data-src="https://image.manyacan.com/202312121008665.png-wms#vwid=534&vhei=435" src="https://image.manyacan.com/202312121008665.png-wms#vwid=534&vhei=435"><figcaption>图1</figcaption></figure><figure><img class="" alt="图2" data-src="https://image.manyacan.com/202312121442059.png-wms#vwid=534&vhei=435" src="https://image.manyacan.com/202312121442059.png-wms#vwid=534&vhei=435"><figcaption>图2</figcaption></figure></div><p>图1有一个接近零的特征值，表明图是连通的。图2特征值有两个接近于零的值，这与图中的两个连通分量相对应。<strong>特征值为0的数量</strong>恰好等于图的连通分量的数量。</p><p>图2的 Fiedler 值（最小非0值）为1.58，该 Fiedler 值对应的特征向量是：</p><p>$$
\begin{bmatrix}
0.       \\
0.       \\
0.       \\
-0.4472136 \\
-0.4472136 \\
-0.4472136 \\
-0.4472136 \\
-0.4472136 \\
\end{bmatrix}
$$</p><p>说明，该 Fiedler 值代表的是3、4、5、6、7节点对应的连通分量的连通性。</p><p>总结：图1的连通性更强，因为其特征值中仅有一个为0；图2包含两个连通分量，因为其特征值中包含两个0。图2中3、4、5、6、7节点组成的连通分量的连通性要高于图1整体的连通性。因为图2中3、4、5、6、7节点组成的连通分量的 Fiedler 值为1.58，大于图1整体的连通分量1.13。</p><p>Fiedler 值也被称为代数连通性，它反映了图的稀疏性或稠密性。一个较高的Fiedler值意味着图具有较强的连通性，而较低的Fiedler 值则意味着图可能容易被分割成独立的组件。</p><blockquote><h6 id="toc_104">Thinking/ 思考</h6><p>管网数据分析表明：随着管网中节点数的增多，Fiedler 值（代数连通性）越来越小，说明越大的管网环状比例越小。是不是可以这样理解为：大部分管网新建的时候都是城区环状管网，随着城市的发展，开始逐渐向周围以支状管网扩散，这就导致了大型管网的环状比例都较小。</p></blockquote><h4 id="toc_105">特征向量</h4><p>特征向量（图1）：</p><p>$$
\begin{bmatrix}
0.35355339 &amp;  0.40809973 &amp; -0.38534069 &amp; -0.32322928 &amp;  0.61237244 &amp; 0.10317586 &amp; -0.24182446 &amp;  0.10660991 \\
0.35355339 &amp;  0.21821011 &amp;  0.07059821 &amp; -0.06640201 &amp; -0.20412415 &amp; 0.58748394 &amp;  0.64631494 &amp;  0.11603433 \\
0.35355339 &amp;  0.36261755 &amp; -0.3221172  &amp;  0.67753284 &amp; -0.20412415 &amp; -0.23709192 &amp; -0.00834996 &amp; -0.28766179 \\
0.35355339 &amp;  0.18086105 &amp;  0.27243317 &amp; -0.5085369  &amp; -0.20412415 &amp; -0.62680632 &amp;  0.20197088 &amp; -0.18470141 \\
0.35355339 &amp;  0.05048967 &amp;  0.33222523 &amp;  0.17458035 &amp; -0.20412415 &amp; -0.05547633 &amp; -0.37548832 &amp;  0.7388255  \\
0.35355339 &amp; -0.15837433 &amp;  0.24016423 &amp; -0.13207484 &amp; -0.20412415 &amp; 0.41726191 &amp; -0.52854257 &amp; -0.52883224 \\
0.35355339 &amp; -0.40809973 &amp;  0.38534069 &amp;  0.32322928 &amp;  0.61237244 &amp; -0.10317586 &amp;  0.24182446 &amp; -0.10660991 \\
0.35355339 &amp; -0.65380405 &amp; -0.59330365 &amp; -0.14509945 &amp; -0.20412415 &amp; -0.08537128 &amp;  0.06409502 &amp;  0.14633561 \\
\end{bmatrix}
$$</p><p>将特征值从小到大排序，然后可视化特征向量：</p><pre><code class="lang-python">def plot_eigenvectors(value, vector):
    vector = vector[:, np.argsort(value)]
    value = np.sort(value)

    # plt.figure(dpi=100)
    fig, ax_arr = plt.subplots(len(value), 1, sharex='col', sharey='row', figsize=(5, 2 * len(value)))
    fig.subplots_adjust(hspace=0.05, wspace=0.03)

    for i in range(len(value)):
        ax_arr[i].stem([i for i in range(len(value))], vector[:, i])
        ax_arr[i].set_ylabel(f'$u_<ruby>{i}}}(n)$')


plot_eigenvectors(eig_value, eig_vector)</code></pre><div class="photos large"><figure><img class="" alt="图1" data-src="https<rp>(</rp><rt>//image.manyacan.com/202312121014402.png-wms#vwid=482&vhei=1275" src="https<rp>(</rp><rt>//image.manyacan.com/202312121014402.png-wms#vwid=482&vhei=1275"><figcaption>图1</figcaption></figure><figure><img class="" alt="图2" data-src="https://image.manyacan.com/202312121445387.png-wms#vwid=482&vhei=1275" src="https://image.manyacan.com/202312121445387.png-wms#vwid=482&vhei=1275"><figcaption>图2</figcaption></figure></div><p>上面两个图是按照特征值排序后的特征向量，下面依次来解释特征向量有着什么样的含义：</p><ul><li><strong>第一个特征向量的含义</strong>：对于任何图，拉普拉斯矩阵的第一个特征值总是0。对于零特征值，其对应的特征向量（通常是一个所有元素都相等的向量）实际上表示了图中所有节点的一种“平均”状态或者均匀状态。对于连通图（图1），这反映了图中所有节点在某种意义上是等价的，没有任何节点是孤立的。对于非连通图（图2），对于非连通图，拉普拉斯矩阵的零特征值的个数等于图的连通分量的数量，每个零特征值的特征向量反映了对应连通分量中的节点关系。例如图2的第一个特征向量有三个值不为0，那么就说明图2的第一个连通分量中有三个元素；第二个特征向量有四个值不为0，那么就说明第二个连通分量中有四个元素。总的来说，连通图的第一个特征向量不反映任何局部结构或节点间的差异，而是显示了图作为一个整体的特性，即全局特征。</li><li><strong>Fiedler向量（第二个特征向量）：</strong>在Fiedler向量中，正值和负值分别代表了图中的不同群体，这种划分往往揭示了图的潜在社区结构，其中社区内部的节点比跨社区的节点更紧密地连接。例如图1中，Fiedler向量的前5个值为负值，后3个为正值，这说明图1更容易分为两个簇：前5个节点（0、1、2、7、3）、后3个节点（4、5、6）。</li></ul><blockquote><h6 id="toc_106">Thinking / 思考</h6><p>除了可以根据Fiedler向量对图中节点进行简单的正负划分外，还可以根据不同值的接近程度进行更为细致的划分。例如，假设一个Fiedler向量为[-100,-99,-1,2,3,6,7,8]：</p><ol><li><p><strong>基本的二分法</strong>：首先，根据Fiedler向量的正负符号，可以将图分为两个主要群体：</p><ul><li>第一个群体：包含节点1、2、3（对应于Fiedler向量中的值为-100, -99, -1）；</li><li>第二个群体：包含节点4、5、6、7、8（对应于Fiedler向量中的值为2, 3, 6, 7, 8）。</li></ul></li><li><p><strong>更细致的分组</strong>：在每个主要群体内，可以根据Fiedler向量值的接近程度进行更细致的分组：</p><ul><li>在第一个主要群体中，节点1和2（Fiedler向量值为-100和-99）更接近彼此，而节点3（值为-1）相对较远；</li><li>在第二个主要群体中，节点4和5（Fiedler向量值为2和3）更接近彼此，而节点6、7、8（值为6, 7, 8）更接近彼此。</li></ul></li></ol><p>如果Fiedler向量的这种特性，在管网的图结构中，是否可以对管网中的节点进行分类，分为不同的簇，进而达到简化管网的目的？</p></blockquote><h3 id="toc_107">NetworkX中获取特征值（谱）</h3><p>获取邻接矩阵的特征值：</p><pre><code class="lang-python">print(np.real(nx.adjacency_spectrum(G)))</code></pre><p>计算拉普拉斯矩阵的特征值：</p><pre><code class="lang-python">print(np.real(nx.laplacian_spectrum(G)))</code></pre><h2 id="toc_108">NetworkX中常见图（网络）生成器</h2><h3 id="toc_109">完全图（全连接图）</h3><pre><code class="lang-python"># 生成包含n个节点的完全图（全连接图）
n = 10
G1 = nx.complete_graph(10)
pos = nx.circular_layout(G1)
nx.draw(G1, pos, node_size=500, node_color='red', with_labels=True)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192129064.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312192129064.png-wms#vwid=660&vhei=499"></figure></p><h3 id="toc_110">星型图</h3><pre><code class="lang-python"># 生成包含n个节点的星型图
n = 10
G2 = nx.star_graph(n-1)
pos = nx.spring_layout(G2)
nx.draw(G2, pos, node_size=500, node_color='red', with_labels=True)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192130866.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312192130866.png-wms#vwid=660&vhei=499"></figure></p><h3 id="toc_111">ER随机图</h3><pre><code class="lang-python"># 生成包含n个节点，连边概率为p的ER随机图
n, p = 20, 0.2
G3 = nx.erdos_renyi_graph(n, p)
nx.draw(G3, node_size=500, node_color='red', with_labels=True)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192130636.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312192130636.png-wms#vwid=660&vhei=499"></figure></p><h3 id="toc_112">WS小世界网络</h3><pre><code class="lang-python"># 生成包含n个节点，重连概率为p的WS小世界网络
n, k, p = 20, 4, 0.2

# 当p=0时，便退化成了k近邻规则网络
G4 = nx.watts_strogatz_graph(n, k, p)
pos = nx.circular_layout(G4)
nx.draw(G4, pos, node_size=500, node_color='red', with_labels=True)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192131443.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312192131443.png-wms#vwid=660&vhei=499"></figure></p><h3 id="toc_113">BA无标度网络</h3><pre><code class="lang-python"># 生成包含n个节点，参数m=2的BA无标度网络
n, m = 50, 2
G5 = nx.barabasi_albert_graph(n, m)
pos = nx.spring_layout(G5)
nx.draw(G5, pos, node_size=500, node_color='red', with_labels=True)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192132570.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312192132570.png-wms#vwid=660&vhei=499"></figure></p><h2 id="toc_114">外部变量（数据）创建图结构</h2><h3 id="toc_115">dict对象</h3><p>将字典数据转化为网络：</p><pre><code class="lang-python">d = {0: {1: {&quot;weight&quot;: 1}, 2: {&quot;weight&quot;: 2</rt><rp>)</rp></ruby>, 1: {2: {&quot;weight&quot;: 3.5}}}
G = nx.Graph(d)
# 或者
# G = nx.from_dict_of_dicts(d)
edge_width = nx.get_edge_attributes(G, &quot;weight&quot;)
# print(width)
nx.draw(G, node_size=500, node_color='red', with_labels=True, width=list(edge_width.values()))</code></pre><p>反过来把网络转换成字典数据：</p><pre><code class="lang-python">print(nx.to_dict_of_dicts(G))</code></pre><h3 id="toc_116">list对象</h3><p>转化为<code>list</code>对象：</p><pre><code class="lang-python">edgelist = nx.to_edgelist(G)
print(edgelist)</code></pre><p>从<code>list</code>格式创建：</p><pre><code class="lang-python">G = nx.from_edgelist(edgelist)</code></pre><h3 id="toc_117">array对象</h3><p>转化为<code>array</code>对象（邻接矩阵）格式：</p><pre><code class="lang-python">nx.adjacency_matrix(G)</code></pre><p>从<code>array</code>对象（邻接矩阵）格式转化：</p><pre><code class="lang-python">nx.from_numpy_array(A)</code></pre><h3 id="toc_118">DataFrame对象</h3><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192219857.png-wms#vwid=677&vhei=649" src="https://image.manyacan.com/202312192219857.png-wms#vwid=677&vhei=649"></figure></p><pre><code class="lang-python">df = pd.read_excel(&quot;edges.xlsx&quot;)
G = nx.from_pandas_edgelist(df, 'source', 'target','weight', create_using = nx.Graph())
# 若为有向图，create_using = nx.DiGraph()
# 若为无权无向网络则：G = nx.from_pandas_edgelist(df, 'source', 'target', create_using = nx.Graph())
edge_width = nx.get_edge_attributes(G, &quot;weight&quot;)
nx.draw(G, node_size=500, node_color='red', with_labels=True, width=list(edge_width.values()))</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312192219757.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312192219757.png-wms#vwid=660&vhei=499"></figure></p><h2 id="toc_119">NetworkX可视化</h2><h3 id="toc_120">常用属性值</h3><p>设置节点大小与节点颜色：</p><pre><code class="lang-python">nx.draw(G, node_size=100, node_color=&quot;red&quot;)</code></pre><p>更加复杂的格式：</p><pre><code class="lang-python"># 当设置的属性较多时，可以将其保存在字典中，以**不定长参数传入
options = {
    'pos': nx.spring_layout(G),
    'node_size': 300,
    'node_color': &quot;red&quot;,
    'edge_color': &quot;gray&quot;,
    'width': 1.0, # 连边粗细
    'with_labels': True,
}
nx.draw(G, **options)</code></pre><h3 id="toc_121">布局方式</h3><p><code>networkx</code> 库提供了多种布局算法来可视化图，每种布局算法都有其独特的特性和适用场景。以下是一些常用的布局算法：</p><ol><li><p><strong>Spring Layout（Fruchterman-Reingold Force-directed Algorithm）</strong>:</p><ul><li>实现了所谓的“弹簧”布局算法（也称为Fruchterman-Reingold算法），它是一种力导向图绘制算法。</li><li>使用方法：<code>nx.spring_layout(G)</code></li></ul></li><li><p><strong>Circular Layout</strong>:</p><ul><li>将节点放置在一个圆上，通常用于突出循环结构。</li><li>使用方法：<code>nx.circular_layout(G)</code></li></ul></li><li><p><strong>Random Layout</strong>:</p><ul><li>将节点随机放置在画布上，用于快速生成节点位置。</li><li>使用方法：<code>nx.random_layout(G)</code></li></ul></li><li><p><strong>Spectral Layout</strong>:</p><ul><li>基于图的拉普拉斯特征向量（使用拉普拉斯矩阵的第二小和第三小的特征值对应的特征向量，这两个特征向量用于在二维空间中定义节点的位置），尝试将连接的节点放置得更近。</li><li>使用方法：<code>nx.spectral_layout(G)</code></li></ul></li><li><p><strong>Shell Layout</strong>:</p><ul><li>将图中的节点排列在同心圆上，适用于层级结构。</li><li>使用方法：<code>nx.shell_layout(G)</code></li></ul></li><li><p><strong>Kamada-Kawai Layout</strong>:</p><ul><li>基于路径长度的力导向算法，旨在使路径长度在图上的表现与其在几何空间中的长度相匹配。</li><li>使用方法：<code>nx.kamada_kawai_layout(G)</code></li></ul></li><li><p><strong>Bipartite Layout</strong>:</p><ul><li>专门用于二分图的布局，将节点分为两组，每组形成一列。</li><li>使用方法：<code>nx.bipartite_layout(G, nodes)</code></li></ul></li><li><p><strong>Planar Layout</strong>:</p><ul><li>如果图是平面图，这个算法会找到一个平面布局（即让所有的边都不相交）。</li><li>使用方法：<code>nx.planar_layout(G)</code></li></ul></li></ol><div class="photos large"><figure><img class="" alt="Circular Layout" data-src="https://image.manyacan.com/202312200937882.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312200937882.png-wms#vwid=660&vhei=499"><figcaption>Circular Layout</figcaption></figure><figure><img class="" alt="Spectral Layout" data-src="https://image.manyacan.com/202312200928781.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312200928781.png-wms#vwid=660&vhei=499"><figcaption>Spectral Layout</figcaption></figure><figure><img class="" alt="Bipartite Layout" data-src="https://image.manyacan.com/202312200918818.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312200918818.png-wms#vwid=660&vhei=499"><figcaption>Bipartite Layout</figcaption></figure><figure><img class="" alt="Planar Layout" data-src="https://image.manyacan.com/202312200920361.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312200920361.png-wms#vwid=660&vhei=499"><figcaption>Planar Layout</figcaption></figure></div><h3 id="toc_122">点定位与边权重的设置</h3><p>创建一个有权无向图：</p><pre><code class="lang-python">G = nx.Graph()
edge_list = [(0, 1, 2), (0, 2, 8), (0, 3, 1), (1, 2, 6),
             (1, 4, 1), (2, 3, 7), (2, 4, 5), (2, 5, 1),
             (2, 6, 2), (3, 6, 9), (4, 5, 3), (4, 7, 8),
             (5, 6, 4), (5, 7, 6), (6, 7, 3)]
G.add_weighted_edges_from(edge_list)
nx.draw(G, node_size=500, with_labels=True)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312200950294.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312200950294.png-wms#vwid=660&vhei=499"></figure></p><p>自定义节点的位置并将边的权重作为图中边的宽度进行绘制：</p><pre><code class="lang-python"># 自定义各个节点的坐标
pos = {0: (-2, 0), 1: (-1, 1), 2: (-1, 0), 3: (-1, -1),
       4: (1, 1), 5: (1, 0), 6: (1, -1), 7: (2, 0)}

# 提取边的权重并作为标签
e_labels = nx.get_edge_attributes(G, 'weight')

e_width = [G.get_edge_data(*e)['weight'] for e in G.edges()]

options = {
    'pos': pos,
    'node_size': 500,
    'node_color': &quot;red&quot;,
    'edge_color': &quot;gray&quot;,
    'width': e_width,
    'with_labels': True,
}
nx.draw(G, **options)
nx.draw_networkx_edge_labels(G, pos, edge_labels=e_labels)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201013745.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312201013745.png-wms#vwid=660&vhei=499"></figure></p><h3 id="toc_123">以节点度区分颜色</h3><pre><code class="lang-python">G = nx.barabasi_albert_graph(20, 2)
# 绘制网络图，按度值大小设定节点大小和颜色
# 设置节点大小与度成正比
nodesize = [G.degree(i) * 100 for i in G.nodes()]
node_colors = [G.degree(i) for i in G.nodes()]
options = {
    'pos': nx.spring_layout(G),
    'node_size': nodesize,
    'node_color': node_colors,
    'cmap': plt.cm.cool,  # 设置节点colormap
    'edge_color': &quot;gray&quot;,
    'with_labels': True,
}
nx.draw(G, **options)
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201018487.png-wms#vwid=660&vhei=499" src="https://image.manyacan.com/202312201018487.png-wms#vwid=660&vhei=499"></figure></p><h3 id="toc_124">更高阶的玩法</h3><ul><li>更多NetworkX可视化案例见：<a href="https://networkx.org/documentation/stable/auto_examples/index.html">https://networkx.org/documentation/stable/auto_examples/index.html</a>；</li><li>Gephi是网络图可视化领域中无敌的软件：<a href="https://gephi.org/">https://gephi.org/</a>。</li></ul><h2 id="toc_125">实战——FackBook社交网络分析</h2><h3 id="toc_126">说明</h3><p>这个案例来自<a href="https://networkx.org/nx-guides/content/exploratory_notebooks/facebook_notebook.html">NetworkX官方网站</a>，通过对10个FackBook朋友圈社交网络的分析，来复习下图论中的一些基本概念以及相关NetworkX包的使用。请注意：</p><ul><li>每个节点代表一个FackBook匿名用户，每条边表示两个用户之间的朋友关系；</li><li>FackBook朋友圈社交网络为无权无向图；</li><li>节点0, 107, 348, 414, 686, 698, 1684, 1912, 3437, 3980为<code>spotlight nodes</code>，也就是上面提到的10个朋友圈的主人，这也就意味着他们是图结构中的核心节点。</li></ul><h3 id="toc_127">引包</h3><pre><code class="lang-python">import pandas as pd
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
from random import randint</code></pre><h3 id="toc_128">读取文件并创建图</h3><pre><code class="lang-python">facebook_df = pd.read_csv(
    &quot;./data/facebook_combined.txt.gz&quot;,
    compression=&quot;gzip&quot;,
    sep=&quot; &quot;,
    names=[&quot;start_node&quot;, &quot;end_node&quot;],
)
facebook_df</code></pre><p>读取到的DataFrame共有88234行，每一行代表一个边（即一个连接关系）：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201043782.png-wms#vwid=1417&vhei=662" src="https://image.manyacan.com/202312201043782.png-wms#vwid=1417&vhei=662"></figure></p><p>根据DataFrame创建一个图结构：</p><pre><code class="lang-python">G = nx.from_pandas_edgelist(facebook_df, &quot;start_node&quot;, &quot;end_node&quot;)</code></pre><p>接下来就是进行图的可视化。因为默认情况下我们并不清楚图的数据结构是什么样的，因此选择随机布局（<code>nx.random_layout(G</code>)）来绘制图形：</p><pre><code class="lang-python">fig, ax = plt.subplots(figsize=(15, 9))
ax.axis(&quot;off&quot;)
plot_options = {&quot;node_size&quot;: 10, &quot;with_labels&quot;: False, &quot;width&quot;: 0.15}
nx.draw_networkx(G, pos=nx.random_layout(G), ax=ax, **plot_options)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201059653.png-wms#vwid=1182&vhei=713" src="https://image.manyacan.com/202312201059653.png-wms#vwid=1182&vhei=713"></figure></p><p>显然，从上面的可视化结果中我们看不出来任何信息。因为默认的随机布局看起来杂乱无章。</p><p><code>nx.spring_layout(G)</code>可以根据节点和边的关系对图结构进行布局，但是考虑到本图结构中节点数众多，可以通过设置其参数<code>iterations</code>来避免算法迭代次数过多：</p><pre><code class="lang-python">pos = nx.spring_layout(G, iterations=15, seed=666)
fig, ax = plt.subplots(figsize=(20, 20))
ax.axis(&quot;off&quot;)
plot_options = {&quot;node_size&quot;: 2, &quot;with_labels&quot;: False, &quot;width&quot;: 0.05}
nx.draw_networkx(G, pos=pos, ax=ax, **plot_options)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201404317.png-wms#vwid=1570&vhei=1560" src="https://image.manyacan.com/202312201404317.png-wms#vwid=1570&vhei=1560"></figure></p><p>经过重新布局后，图中的结构似乎有那么一丝“拨云见日”了。①：图结构有聚类的性质，不同的节点分为几个大类；②：少数节点拥有较高的度，符合社交网络的度分布情况。</p><h3 id="toc_129">图结构的基本拓扑属性</h3><p>查看节点数与边数：</p><pre><code class="lang-python">G.number_of_nodes(), G.number_of_edges()</code></pre><p>平均度（即图中每个节点平均有几个邻居）：</p><pre><code class="lang-python">np.mean([d for _, d in G.degree()])</code></pre><p>或者：</p><pre><code class="lang-python">sum(dict(G.degree()).values()) / len(G)</code></pre><p>图结构中有很多属性与路径有关，例如网络直径和平均最短路径。计算这两个属性值都需要涉及到计算图中所有节点对之间的最短路径，这一个非常消耗计算资源的步骤。</p><pre><code class="lang-python">shortest_path_lengths = dict(nx.all_pairs_shortest_path_length(G))</code></pre><p><code>shortest_path_lengths</code>返回的结果是一个<code>dict-of-dict</code>格式的对象：</p><pre><code class="lang-python">shortest_path_lengths[42][0], shortest_path_lengths[1][32]  # 节点42到节点0的最短路径、节点1到节点32的最短路径</code></pre><p>有上面离心率和直径的基本概念可以得之：$ \text{diameter}(G) = \max_{v \in G} \text{eccentricity}(v) $。因此，可以通过：</p><pre><code class="lang-python">diameter = max(nx.eccentricity(G, sp=shortest_path_lengths).values())
diameter</code></pre><p>求图中所有节点的离心率最大值来“曲线”求图的直径，通过参数<code>sp=shortest_path_lengths</code>来使用计算好的最短路径来求，避免了计算资源的消耗。</p><p>同理，对于求平均最短路径而言，我们可以使用<code>*nx.average_shortest_path_length()</code>命令直接求，但是这样会造成计算资源的浪费。因此，仍可以通过上面计算的<code>shortest_path_lengths</code>来“曲线”求解：</p><pre><code class="lang-python"># Compute the average shortest path length for each node
average_path_lengths = [
    np.mean(list(spl.values())) for spl in shortest_path_lengths.values()
]
# The average over all nodes
np.mean(average_path_lengths)</code></pre><p>求得平均最短路径为3.6，这说明在社交网络中一份“信息”的平均传递人数是3.6。😂这说明，当你把一个“秘密”在互联网上告诉了另一个人，另一个人是有很大概率告诉另外一个人的。这也说明了“三人成虎”是有科学依据的。😂</p><p>查看最短路径的直方图分布情况：</p><pre><code class="lang-python">plt.rcParams.update({
'font.size': 20,
'font.family': ['Times New Roman', 'SimSun']
})

# We know the maximum shortest path length (the diameter), so create an array
# to store values from 0 up to (and including) diameter
path_lengths = np.zeros(diameter + 1, dtype=int)

# Extract the frequency of shortest path lengths between two nodes
for pls in shortest_path_lengths.values():
    pl, cnts = np.unique(list(pls.values()), return_counts=True)
    path_lengths[pl] += cnts

# Express frequency distribution as a percentage (ignoring path lengths of 0)
freq_percent = 100 * path_lengths[1:] / path_lengths[1:].sum()

# Plot the frequency distribution (ignoring path lengths of 0) as a percentage
fig, ax = plt.subplots(figsize=(15, 8))
ax.bar(np.arange(1, diameter + 1), height=freq_percent)
ax.set_title(&quot;Distribution of shortest path length in G&quot;)
ax.set_xlabel(&quot;Shortest Path Length&quot;)
ax.set_ylabel(&quot;Frequency (%)&quot;)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201518473.png-wms#vwid=1251&vhei=734" src="https://image.manyacan.com/202312201518473.png-wms#vwid=1251&vhei=734"></figure></p><p>查看网络密度：</p><pre><code class="lang-python">nx.density(G)</code></pre><p>网络密度为0.0108，远远小于1，说明社交网络也是一个稀疏网络。也很容易理解，中国有14亿人，你认识的有几个呢？</p><p>获取连通组件（子图）的数量：</p><pre><code class="lang-python">nx.number_connected_components(G)</code></pre><p>返回结果为1。说明，整个社交网络都是连通的。</p><h3 id="toc_130">FaceBook社交网络中心性分析</h3><h4 id="toc_131">度中心性</h4><p>采用度中心性进行计算：</p><pre><code class="lang-python">degree_centrality = nx.centrality.degree_centrality(G)  # save results in a variable to use again, nx.degree_centrality(G)也可以

(sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True))[:8]</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201546279.png-wms#vwid=1408&vhei=483" src="https://image.manyacan.com/202312201546279.png-wms#vwid=1408&vhei=483"></figure></p><p>返回的结果中有一些有意思的信息：节点107、1684、1912、3437以及节点0都是<code>spotlight nodes</code>，因此其具有更好的中心性也无可厚非。但节点2543、2347、1888也就有非常高的度中心性，说明这三个人可能非常喜欢吃瓜🍉🍉🍉。</p><p>获取度排名前8的选手：</p><pre><code class="lang-python">(sorted(G.degree, key=lambda item: item[1], reverse=True))[:8]</code></pre><p>获取网络中心性分布直方图：</p><pre><code class="lang-python">plt.figure(figsize=(15, 8))
plt.hist(degree_centrality.values(), bins=25)
plt.xticks(ticks=[0, 0.025, 0.05, 0.1, 0.15, 0.2])  # set the x axis ticks
plt.title(&quot;Degree Centrality Histogram &quot;)
plt.xlabel(&quot;Degree Centrality&quot;)
plt.ylabel(&quot;Counts&quot;)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201553769.png-wms#vwid=1279&vhei=734" src="https://image.manyacan.com/202312201553769.png-wms#vwid=1279&vhei=734"></figure></p><p>以节点度为节点的大小和颜色区分，可视化网络结构：</p><pre><code class="lang-python">import matplotlib.pyplot as plt

node_size = [
    v**2 * 10000 for v in degree_centrality.values()
]

plt.figure(figsize=(20, 20))
nx.draw_networkx(G, pos=pos, node_size=node_size, with_labels=False, width=0.15,node_color = node_size,
cmap= plt.cm.cool)
plt.axis(&quot;off&quot;)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201600018.png-wms#vwid=1570&vhei=1560" src="https://image.manyacan.com/202312201600018.png-wms#vwid=1570&vhei=1560"></figure></p><h4 id="toc_132">介数中心性</h4><p>对于一个节点的介数中心性，简单来讲就是一个网络中所有任意两节点之间最短路径中有几条经过了该节点。反映到社交网络中，介数中心性反映了该节点影响他人能力的大小。例如：当一个人有很高的介数中心性，说明社交网络中的很多信息都需要经过她/他来传播。</p><p>计算介数中心性排名前八的用户：</p><pre><code class="lang-python">betweenness_centrality = nx.centrality.betweenness_centrality(
    G
)  # save results in a variable to use again
(sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True))[:8]</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201634170.png-wms#vwid=1421&vhei=499" src="https://image.manyacan.com/202312201634170.png-wms#vwid=1421&vhei=499"></figure></p><p>在介数中心性排名前八的用户中，节点0, 107, 1684, 1912, 3437的度中心性也在前八之中，说明这些节点不仅仅是<code>spotlight nodes</code>，其对于社交网络中信息的传播也十分重要。而对于节点567, 1085，其度中心性远远落后于前八的值：</p><pre><code class="lang-python">degree_centrality[567],  degree_centrality[1085]  # (0.015601783060921248, 0.016344725111441305)</code></pre><p>但是两者却拥有了很高的介数中心性，说明两者虽然在影响力上并不大，但是在信息传播过程中却非常重要（有点像吃瓜群众）。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201642850.png-wms#vwid=1570&vhei=1560" src="https://image.manyacan.com/202312201642850.png-wms#vwid=1570&vhei=1560"></figure></p><h4 id="toc_133">接近度中心性</h4><p>接近度中心性在控制社交网络中虚假信息的传播方面非常有研究价值。如果一个节点（用户）有很高的接近度中心性，那么说明其发布的信息更容易在短时间内就迅速影响到一大批人。</p><p>计算接近度中心性排名前八的用户：</p><pre><code class="lang-python">closeness_centrality = nx.centrality.closeness_centrality(
    G
)  # save results in a variable to use again
(sorted(closeness_centrality.items(), key=lambda item: item[1], reverse=True))[:8]</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201650887.png-wms#vwid=1419&vhei=496" src="https://image.manyacan.com/202312201650887.png-wms#vwid=1419&vhei=496"></figure></p><h3 id="toc_134">聚类系数</h3><p>查看图平均聚类系数：</p><pre><code class="lang-python">nx.clustering(G).values()</code></pre><p>所有节点聚类系数的直方图分布：</p><pre><code class="lang-python">plt.figure(figsize=(15, 8))
plt.hist(nx.clustering(G).values(), bins=50)
plt.title(&quot;Clustering Coefficient Histogram &quot;)
plt.xlabel(&quot;Clustering Coefficient&quot;)
plt.ylabel(&quot;Counts&quot;)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312202113505.png-wms#vwid=1265&vhei=734" src="https://image.manyacan.com/202312202113505.png-wms#vwid=1265&vhei=734"></figure></p><h3 id="toc_135">桥检测</h3><pre><code class="lang-python">nx.has_bridges(G)</code></pre><p>结果返回<code>True</code>，说明图结构中存在“易破坏的点”。</p><pre><code class="lang-python">bridges = list(nx.bridges(G))
print(len(bridges))

for i in bridges:
    print(i)</code></pre><p>结果返回<code>75</code>，说明图结构中存在75个桥。之所以存在这么多的桥是因为该社交网络仅使用了10个<code>spotlight nodes</code>，对于每个<code>spotlight nodes</code>的朋友节点的朋友圈并没有考虑。</p><p>查看本地桥数量：</p><pre><code class="lang-python">local_bridges = list(nx.local_bridges(G, with_span=False))
len(local_bridges)</code></pre><p>可视化桥与本地桥：</p><pre><code class="lang-python">plt.figure(figsize=(20, 20))
nx.draw_networkx(G, pos=pos, node_size=10, with_labels=False, width=0.15)
nx.draw_networkx_edges(
    G, pos, edgelist=local_bridges, width=0.5, edge_color=&quot;lawngreen&quot;
)  # green color for local bridges
nx.draw_networkx_edges(
    G, pos, edgelist=bridges, width=0.5, edge_color=&quot;r&quot;
)  # red color for bridges
plt.axis(&quot;off&quot;)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312202059450.png-wms#vwid=1570&vhei=1560" src="https://image.manyacan.com/202312202059450.png-wms#vwid=1570&vhei=1560"></figure></p><h3 id="toc_136">度同配性</h3><p>计算社交网络的度同配性：</p><pre><code class="lang-python">nx.degree_assortativity_coefficient(G)</code></pre><p>或者：</p><pre><code class="lang-python">nx.degree_pearson_correlation_coefficient(
    G
)  # use the potentially faster scipy.stats.pearsonr function.</code></pre><p>显示FB社交网络的度同配性为0.064，比较接近于0。说明：用户的社交关系在度数上既不显示同配也不显示异配的特征（non-assortative）。</p><h3 id="toc_137">网络社区分类</h3><p><code>networkx</code> 库提供了多种社区检测算法，其中 <code>nx.community.label_propagation_communities(G)</code> 和 <code>nx.community.asyn_fluidc(G, k, seed=0)</code> 是两种不同的社区发现算法。它们在社区检测的方法和理论基础上有所不同。</p><ol><li><p><strong>标签传播算法（Label Propagation）</strong>:</p><ul><li><strong>函数</strong>：<code>nx.community.label_propagation_communities(G)</code></li><li><strong>原理</strong>：此算法基于网络中节点的标签传播。最初，每个节点被赋予一个唯一的标签，然后在迭代过程中，每个节点会采用其邻居中最常见的标签。最终，具有相同标签的节点被分为同一个社区。</li><li><strong>特点</strong>：这种算法简单且运行速度快，但它可能不稳定，即不同的运行可能产生不同的结果。此算法适用于大型网络，但可能不适合发现重叠社区或具有层次结构的社区。</li></ul></li><li><p><strong>异步流体社区检测（Asynchronous Fluid Communities）</strong>:</p><ul><li><strong>函数</strong>：<code>nx.community.asyn_fluidc(G, k, seed=0)</code></li><li><strong>原理</strong>：这是一种基于流体动力学的社区检测方法。算法试图通过模拟 k 个流体的扩散来确定社区。每个流体源（源自一个节点）扩散到网络，逐渐形成社区，直到达到稳定状态。</li><li><strong>特点</strong>：这种算法适用于中等大小的网络，并且需要预先指定社区数量（k）。它通常能够找到比较均衡的社区结构，但对于非常大的网络，算法的效率和效果可能受限。</li></ul></li></ol><p>两者的不同之处：</p><ul><li><strong>算法原理</strong>：标签传播算法依赖于标签的传播和统一，而异步流体社区检测基于流体动力学的模型。</li><li><strong>社区数量</strong>：标签传播算法不需要预先指定社区的数量，它会自然形成，而异步流体社区检测需要预先指定社区数量 k。</li><li><strong>适用性</strong>：标签传播算法适用于大型网络且运行快速，但可能不够稳定；异步流体社区检测适用于中等规模的网络，需要预设社区数量，可能对社区大小更加均衡。</li></ul><p>标签传播算法：</p><pre><code class="lang-python">colors = [&quot;&quot; for x in range(G.number_of_nodes())]  # initialize colors list
counter = 0
for com in nx.community.label_propagation_communities(G):
    color = &quot;#%06X&quot; % randint(0, 0xFFFFFF)  # creates random RGB color
    counter += 1
    for node in list(
            com
    ):  # fill colors list with the particular color for the community nodes
    colors[node] = color
    
        
plt.figure(figsize=(15, 9))
plt.axis(&quot;off&quot;)
nx.draw_networkx(
    G, pos=pos, node_size=10, with_labels=False, width=0.15, node_color=colors
)    </code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201704526.png-wms#vwid=1182&vhei=713" src="https://image.manyacan.com/202312201704526.png-wms#vwid=1182&vhei=713"></figure></p><p>异步流体社区检测可视化：</p><pre><code class="lang-python">colors = [&quot;&quot; for x in range(G.number_of_nodes())]
for com in nx.community.asyn_fluidc(G, 8, seed=0):
    color = &quot;#%06X&quot; % randint(0, 0xFFFFFF)  # creates random RGB color
    for node in list(com):
        colors[node] = color
        
plt.figure(figsize=(15, 9))
plt.axis(&quot;off&quot;)
nx.draw_networkx(
    G, pos=pos, node_size=10, with_labels=False, width=0.15, node_color=colors
) </code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202312201703555.png-wms#vwid=1182&vhei=713" src="https://image.manyacan.com/202312201703555.png-wms#vwid=1182&vhei=713"></figure></p>
]]></content:encoded>
<slash:comments>2</slash:comments>
<comments>https://blog.manyacan.com/archives/2044/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2044/</wfw:commentRss>
</item>
<item>
<title>遗传算法——以背包问题为例</title>
<link>https://blog.manyacan.com/archives/2043/</link>
<guid>https://blog.manyacan.com/archives/2043/</guid>
<pubDate>Wed, 20 Sep 2023 14:21:48 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[What's Genetic Algorithm?A Genetic Algorithm (GA) is a type of optimization algorithm that is ins...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<h2 id="toc_138">What's Genetic Algorithm?</h2><p>A Genetic Algorithm (GA) is a type of optimization algorithm that is inspired by the process of natural selection and genetics. GAs are used to find approximate solutions to optimization and search problems, especially in cases where the search space is vast and complex. They are particularly useful when you have a large solution space and don't know the mathematical form of the objective function you're trying to optimize.</p><h2 id="toc_139">什么是背包问题？</h2><p>假设我们有一个背包，最多只能装6件物品且物品总重量不超过80，如何才能找到一个组合，可以尽量让装进去的物品总价值最高？</p><table><thead><tr><th align="center"> </th><th align="center">物品1</th><th align="center">物品2</th><th align="center">物品3</th><th align="center">物品4</th><th align="center">物品5</th><th align="center">物品6</th></tr></thead><tbody><tr><td align="center">重量</td><td align="center">25</td><td align="center">15</td><td align="center">20</td><td align="center">30</td><td align="center">20</td><td align="center">15</td></tr><tr><td align="center">价值</td><td align="center">15</td><td align="center">5</td><td align="center">10</td><td align="center">20</td><td align="center">10</td><td align="center">10</td></tr></tbody></table><p>这，就是背包问题。</p><h2 id="toc_140">GA算法解决背包问题</h2><h3 id="toc_141">随机初始化种群函数</h3><pre><code class="lang-python">def init_population(population_size: int = 50) -&gt; list:
    &quot;&quot;&quot;
    Create a population of random solutions
    :param population_size: Number of organisms in a population
    :return: Randomly generated population
    &quot;&quot;&quot;
    population = []
    for i in range(population_size):
        chromosome = []
        for j in range(num_items):
            chromosome.append(random.randint(0, 1))
        population.append(chromosome)

    return population</code></pre><p>该函数用于初始化一个种群，该种群中具有<code>population_size</code>个成员。</p><p>以随机化得到的第二个成员<code>[1, 1, 0, 1, 1, 1]</code>为例：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202309201119815.png-wms#vwid=975&vhei=395" src="https://image.manyacan.com/202309201119815.png-wms#vwid=975&vhei=395"></figure></p><p>表示选择1、2、4、5、6号物品装入背包的组合。</p><h3 id="toc_142">基因评价函数</h3><pre><code class="lang-python">def evaluate_fitness(chrom: list) -&gt; int:
    &quot;&quot;&quot;
    Evaluate the fitness of a solution using your objective function
    :param chrom: 基因序列
    :return: 返回该基因序列的“质量高低“
    &quot;&quot;&quot;
    weight_sum, value_sum = 0, 0
    for i in range(len(chrom)):
        if chrom[i] == 1:
            weight_sum, value_sum = weight_sum + weights[i], value_sum + values[i]

    return 0 if weight_sum &gt; capacity else value_sum</code></pre><p>该函数的作用是，传入一个成员的基因（物品）组合，然后返回其基因质量评分。对应到背包问题，就是返回该种组合物品的总价值。</p><blockquote><p>需要特殊说明的是，当物品总重量超过限制值时（<code>weight_sum &gt; capacity</code>），则返回0，因为此时价格没有意义。</p></blockquote><h3 id="toc_143">种群优质成员选择</h3><pre><code class="lang-python">def select_parents(population: list, selection_rate: float = 0.5) -&gt; list:
    &quot;&quot;&quot;
    Select parents based on their fitness
    :param population: All members of the population
    :param selection_rate: Selection ratio of high-quality members
    :return: high-quality members(Selected by function evaluate_fitness())
    &quot;&quot;&quot;
    population_fitness_values = []
    for chrom in population:  # 遍历种群中每一个成员的基因，得到其基因”评分“
        population_fitness_values.append(evaluate_fitness(chrom))

    sorted_population = [x for _, x in
                         sorted(zip(population_fitness_values, population), reverse=True)]  # 将种群中的成员按照其基因”质量评分“升序排列
    cut_num = int(selection_rate * len(sorted_population))  # 只选择前cut_num个”优质“种群成员用于后续交配繁衍
    return sorted_population[:cut_num]  # 返回”优质“种群成员</code></pre><p>该函数的作用是对种群中的优质成员进行筛选。反应到背包问题中，就是对当前所有物品组合的价值进行排序，过滤价值较高的组合。</p><h3 id="toc_144">父类繁衍函数</h3><pre><code class="lang-python">def crossover(parent_0: list, parent_1: list) -&gt; list:
    &quot;&quot;&quot;
    Perform crossover to create offspring
    :param parent_0: First parent class member
    :param parent_1: Second parent class member
    :return: Two offspring by exchanging information between two parents
    &quot;&quot;&quot;
    cut_point = random.randint(0, len(parent_0) - 1)
    child = parent_0[:cut_point] + parent_1[cut_point:]
    # child_1 = parent_1[:cut_point] + parent_0[cut_point:]
    return child</code></pre><p>该函数的作用是对两个传入父类的基因进行交叉重组，得到一个新的子类。</p><p><figure><img class="" alt="函数用法举例" data-src="https://image.manyacan.com/202309201410081.png-wms#vwid=1712&vhei=264" src="https://image.manyacan.com/202309201410081.png-wms#vwid=1712&vhei=264"><figcaption>函数用法举例</figcaption></figure></p><h3 id="toc_145">基因突变函数</h3><pre><code class="lang-python">def mutate(chrom: list, mutation_rate: float = 0.01) -&gt; list:
    &quot;&quot;&quot;
    Apply mutation to a solution
    :param mutation_rate: Probability of gene mutations
    :param chrom: Normal chromosomes
    :return: Mutated chromosomes
    &quot;&quot;&quot;
    for i in range(len(chrom)):
        if random.random() &lt; mutation_rate:
            j = random.randint(0, num_items - 1)
            chrom[i], chrom[j] = chrom[j], chrom[i]

    return chrom</code></pre><p>该函数的作用是对某个成员的基因进行突变。</p><p><figure><img class="" alt="函数用法举例" data-src="https://image.manyacan.com/202309201414887.png-wms#vwid=1604&vhei=231" src="https://image.manyacan.com/202309201414887.png-wms#vwid=1604&vhei=231"><figcaption>函数用法举例</figcaption></figure></p><h2 id="toc_146">GA算法思路</h2><pre><code class="lang-python"># Main GA loop
num_iterations = 100  # 循环迭代数——即进行多少代的繁衍
population = init_population(100)  # 初始化100个种群成员

for generation in range(num_iterations):  # 开始优胜略汰循环繁衍
    # 对初始种群成员进行过滤筛选，保留“高质量”种群成员基因
    parents = select_parents(population)

    # 使用“高质量”种群成员基因交配繁衍新成员
    offspring = []
    for _ in range(len(population) - len(parents)):  # 优胜略汰淘汰了几个种群成员，那么就再在“优秀”成员中繁衍出几个新成员
        parent_0, parent_1 = random.choice(parents), random.choice(parents)  # 随机选择两个高质量成员
        child = crossover(parent_0, parent_1)  # 交换基因得到新成员
        child = mutate(child)  # 新成员进行基因变异
        offspring.append(child)

    # 将新成员补充到种群中
    population = parents + offspring

# 对经过多次迭代循环后的种群基因进行排序，选择出最好的
best_chrom = max(population, key=evaluate_fitness)
best_fitness = evaluate_fitness(best_chrom)
print('Best Solution: ', best_chrom)
print('Best Fitness: ', best_fitness)</code></pre><p><figure><img class="" alt="最终解" data-src="https://image.manyacan.com/202309201415455.png-wms#vwid=867&vhei=116" src="https://image.manyacan.com/202309201415455.png-wms#vwid=867&vhei=116"><figcaption>最终解</figcaption></figure></p><p>对于该问题，最终的解为选择物品1、3、4装入背包，总重量为75（满足小于80的需求），总价值为45。</p>
]]></content:encoded>
<slash:comments>12</slash:comments>
<comments>https://blog.manyacan.com/archives/2043/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2043/</wfw:commentRss>
</item>
<item>
<title>离散傅立叶变换的Python实现</title>
<link>https://blog.manyacan.com/archives/2041/</link>
<guid>https://blog.manyacan.com/archives/2041/</guid>
<pubDate>Thu, 27 Jul 2023 17:08:00 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[😀 基本概念离散傅里叶变换（Discrete Fourier Transform，缩写为DFT），是指傅里叶变换在时域和频域上都呈现离散的形式，将时域信号的采样变换为在离散时间傅里叶变换（DTF...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<h2 id="toc_147">😀 基本概念</h2><p>离散傅里叶变换（Discrete Fourier Transform，缩写为DFT），是指傅里叶变换在时域和频域上都呈现离散的形式，将时域信号的采样变换为在离散时间傅里叶变换（DTFT）频域的采样。在形式上，变换两端（时域和频域上）的序列是有限长的，而实际上这两组序列都应当被认为是离散周期信号的主值序列。即使对有限长的离散信号做DFT，也应当对其经过周期延拓成为周期信号再进行变换。在实际应用中，通常采用快速傅里叶变换来高效计算DFT。</p><p>$$
X_k=\sum_{n=0}^{N-1}{x_n\cdot e^{-i2\pi kn/N}}=\sum_{n=0}^{N-1}{x_n[\cos\mathrm{(}2\pi kn/N)-i\cdot \sin\mathrm{(}2\pi kn/N)]}
$$</p><h2 id="toc_148">🫠 为何需要离散傅立叶变换</h2><p>傅立叶变换本身具有的三个特点：</p><ol><li>时间的积分长度是无穷的；</li><li>频率空间是无穷的；</li><li>函数f(t)是连续的，其本身也包含了无穷多的点。</li></ol><p>正是因为傅立叶变换中这些“无穷”的特点，导致了其不能在计算机上实现，所以就出现了离散傅立叶变换。</p><p>现实世界中获得的数据，只能是有限的时间段，且我们只能针对其中有限个点进行采样。那么我们采样得到的数据能让我们对函数原本的形状了解到什么样的程度呢？</p><p>这个时候就出现了采样定理：设时间连续信号f(t)，其最高截至频率为f_m，如果用时间间隔为T≤1/(2f_m)对信号f(t)进行抽样，则连续信号f(t)可以被抽样信号唯一的表示。采样定理告诉我们，如果采样频率为f_s，则我们对原函数最高了解到[0, f_s/2]范围内的频率信息。</p><p>采样定理，又称香农采样定理，奈奎斯特采样定理，只要采样频率大于或等于有效信号最高频率的两倍，采样值就可以包含原始信号的所有信息，被采样的信号就可以不失真地还原成原始信号。</p><p>为了获取连续函数的离散值，我们的抽取时间间隔取T_s。其实在做信号分析前，我们对信号是一无所知的。根据“采样定理”，当我们选取了抽样时间间隔，其实已经确定了原信号能分析的频率范围[0, 1/(T_s*2)](采样频率f_s=1/(T_s))。</p><blockquote><p>采样定理其实我也没搞太明白，但是不影响后面的理解。</p></blockquote><h2 id="toc_149">😁 DFT的Python实现</h2><blockquote><h5 id="toc_150">Tips / 提示</h5><p>接下来使用一个Python编程实例，来了解DFT究竟可以干什么。</p><p>使用Numpy创建三个不同频率、不同振幅的正弦函数$y_0, y_1, y_2$，然后将其相加合并成为一个函数$y_3$。从时域角度看，$y_0, y_1, y_2$已经完全“融入”$y_3$中，如果想从$y_3$中“挑出来”$y_0, y_1, y_2$中的一个，显然不可能。但是当我们对该函数进行DFT，从频域的角度我们会发现$y_0, y_1, y_2$函数中的振幅、频率信息仍然保存在函数$y_3$中。</p></blockquote><p>引包：</p><pre><code class="lang-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.fftpack import fft, ifft</code></pre><p>分别创建4个正弦函数：</p><p>$$
y_0=3\sin \left( 2\pi \cdot 1\cdot t \right) 
\\
y_1=\sin \left( 2\pi \cdot 4.3\cdot t \right) 
\\
y_2=0.5\sin \left( 2\pi \cdot 7\cdot t \right) 
\\
y_3=y_0+y_1+y_2
$$</p><pre><code class="lang-python"># 样本采样率(每秒钟采几个样)
sr = 100
# 样本采样时间间隔
T_s = 1. / sr  # T_s=0.01
# 样本采样的时间长度为5s，样本采样的个数为500，所以说最小频率=1/(N*T_s)=1/(500*0.01)=0.2Hz
t = np.arange(0, 5, T_s)

y_0 = 3 * np.sin(2 * np.pi * 1 * t)  # ω=2π/T=2πf,sin(ωt)

y_1 = np.sin(2 * np.pi * 4.3 * t)

y_2 = 0.5 * np.sin(2 * np.pi * 7 * t)

y_3 = y_0 + y_1 + y_2</code></pre><p>绘制出4个函数的图像：</p><pre><code class="lang-python">fig, ax = plt.subplots(2, 2, figsize=(6, 6), sharex='col')
fig.subplots_adjust(hspace=0.2, wspace=0.3)

ax[0, 0].plot(t, y_0)
ax[0, 1].plot(t, y_1)
ax[1, 0].plot(t, y_2)
ax[1, 1].plot(t, y_3)

ax[1, 0].set_xlabel('Time')
ax[1, 1].set_xlabel('Time')
ax[0, 0].set_ylabel('Amplitude')
ax[1, 0].set_ylabel('Amplitude')

ax[0, 0].set_title('$y_0=3\sin(2 \pi \cdot t)$')
ax[0, 1].set_title('$y_1=\sin(2 \pi \cdot 4.3t)$')
ax[1, 0].set_title('$y_2=0.5\sin(2 \pi \cdot 7t)$')
ax[1, 1].set_title('$y_3=y_0+y_1+y_2$')

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307271234897.png-wm04#vwid=547&vhei=549" src="https://image.manyacan.com/202307271234897.png-wm04#vwid=547&vhei=549"></figure></p><p>从图中<strong>时域角度</strong>可以看出，$y_0, y_1, y_2$共同“融合”组成了$y_3$。从时域角度，如果想从$y_3$中分离出$y_0, y_1, y_2$其中的一个，显然是不可能的。</p><p>下面我们对$y_3$进行傅立叶变换，换一个角度，从频域的角度来看看会有什么不一样的。</p><pre><code class="lang-python"># 傅里叶变换结果，返回长度=1/2奈奎斯频率/最小频率=1/2*100/0.2=250，250*2=500
y_3_fft = fft(y_3)
N = len(t)

# 采样数据的idx
n = np.arange(N)

# 总的采样时间
T = N / sr  # 5

# 频率区间：奈奎斯频率/2；n/T*sr = n/(N*T_s)=n*w；刚好奈奎斯频率限制和最小刻度值一起给出了频率空间，直接查看freq就懂了
freq = n / T

# 实际幅度
y_3_fft_norm = y_3_fft / N * 2  # 为何要÷N×2？</code></pre><p>绘图可视化DFT结果：</p><pre><code class="lang-python">fig, ax = plt.subplots(1, 2, figsize=(10, 4), dpi=150)

ax[0].stem(freq, np.abs(y_3_fft), 'b', markerfmt=' ', basefmt='-b')

# ax[0].set_xlim(0, 10)

ax[0].set_xlabel('Freq(Hz)')
ax[0].set_ylabel('FFT Amplitude |X(freq)|')

ax[1].stem(freq, np.abs(y_3_fft_norm), 'b', markerfmt=' ', basefmt='-b')

ax[1].set_xlim(0, 10)

ax[1].set_xlabel('Freq(Hz)')
ax[1].set_ylabel('FFT Amplitude |X(freq)|')

ax[1].annotate(
    r'$y_0=3\sin(2 \pi \cdot t)$',
    xy=(1, 2.8),
    xytext=(+30, -30),
    textcoords='offset points',
    arrowprops=dict(arrowstyle='-&gt;', connectionstyle=&quot;arc3,rad=.2&quot;)
)

ax[1].annotate(
    r'$y_1=\sin(2 \pi \cdot 4.3t)$',
    xy=(4.2, .4),
    xytext=(+10, 50),
    textcoords='offset points',
    arrowprops=dict(arrowstyle='-&gt;', connectionstyle=&quot;arc3,rad=-.5&quot;)
)

ax[1].annotate(
    r'$y_2=0.5\sin(2 \pi \cdot 7t)$',
    xy=(7, .4),
    xytext=(+10, 30),
    textcoords='offset points',
    arrowprops=dict(arrowstyle='-&gt;', connectionstyle=&quot;arc3,rad=-.5&quot;)
)

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307271237327.png-wms#vwid=1329&vhei=554" src="https://image.manyacan.com/202307271237327.png-wms#vwid=1329&vhei=554"></figure></p><p>上图中，左边是<code>scipy.fftpack.fft</code>直接返回的结果，可以看出DFT的输出结果是关于采样率的一半对称的（上面我们设置采样率<code>sr = 100</code>，表示每秒钟采100个样）。这一半的采样率被称为奈奎斯特频率（Nyquist frequency）或折叠频率，它是以电子工程师哈里·奈奎斯特的名字命名的。他和克劳德•香农（Claude Shannon）共同定义了Nyquist-Shannon采样定理——如果一个信号只包含低于采样频率一半的频率成分，那么以一定速率采样的信号就可以完全重建，因此，从DFT得到的最高频率输出是采样频率的一半。</p><p>还有一个问题是左图中虽然有明显的三个振幅，但是这三个振幅对应的值却与原来函数$y_0, y_1, y_2$不对应，这是因为离散傅立叶内部公式实现上的原因导致，细节不用纠结，记住这一步就行了。除以N是因为<code>scipy</code>包中封装的离散傅立叶变换公式为了和傅立叶变换公式保持一致，所以内部没有除以N；乘以2是因为由于复数的引入，同一个振幅被分配至两个共轭复数上。</p><p>这也就是为什么我们需要将函数返回的振幅值<code>y_3_fft</code>进行<code>y_3_fft_norm = y_3_fft / N * 2</code>后，才可以得到真正的振幅值。</p><h2 id="toc_151">🥰 DFT应用——信号降噪</h2><p>创建一个原始信号，并为原始信号加上一个随机数噪音：</p><pre><code class="lang-python"># 采样频率
sr = 1000
# 采样时间间隔
ts = 1. / sr

# 样本采样点
t = np.arange(0, 2, ts)  # 在2s的时间内，每隔(1./sr)进行一次采样

# 原始信号
f_clean = 5

freq = 10
f_clean += 2 * np.sin(2 * np.pi * freq * t + 3)  # ω=2π/T=2πf,sin(ωt)=sin(2πf·t)

freq = 30
f_clean += 5 * np.sin(2 * np.pi * freq * t)

# 信号噪音
f_noise = f_clean + 3 * np.random.randn(len(t))</code></pre><p>又上面的代码可以看出，原始信号由三项组成：常数项5、正弦项$2\sin(2\pi \cdot 10 \cdot t+3)$、正弦项$5\sin(2\pi \cdot 30 \cdot t)$以及一个随机噪音项组成。</p><p>绘制信号：</p><pre><code class="lang-python"># 绘制信号
fig, ax = plt.subplots(figsize=(12, 3))

ax.plot(t, f_noise, linewidth=.5, color='c', label='Noisy')
ax.plot(t, f_clean, linewidth=.5, color='r', label='Clean')

ax.set_xlabel('Sampling Time')
ax.set_ylabel('Amplitude')
ax.legend()

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307271639210.png-wms#vwid=1008&vhei=294" src="https://image.manyacan.com/202307271639210.png-wms#vwid=1008&vhei=294"></figure></p><p>对比原始信号与加上噪音后的信号，可以发现加上噪音后，数据整体大概的趋势不变，但是局部信息受到较大扰动。</p><p>进行傅立叶变换：</p><pre><code class="lang-python"># 傅里叶变换
&quot;&quot;&quot;
1、采样频率sr = 1000
2、采样时间间隔 = 1/sr = 0.001
3、采样点个数 = 2000
4、最小频率 = 1/(N*T_s)=1/(2000/1000) = 0.5Hz
&quot;&quot;&quot;

# 傅立叶变换结果，返回长度=1/2奈奎斯频率/最小频率=1/2*1000/0.2=250，再加上负频率，250*2=500
X = fft(f_noise)
N = len(X)

# 采样数据的idx
n = np.arange(N)

# 总的采样时间
T = N / sr

# 频率区间：奈奎斯频率/2；n/T=n/N*sr=n/(N*T_s)=n*w；刚好奈奎斯频率限制和最小刻度值一起给出了频率空间，直接查看freq就懂了
freq = n / T</code></pre><p>绘图可视化观察DFT结果：</p><pre><code class="lang-python">fig, ax = plt.subplots(2, 1, figsize=(10, 8))

ax[0].stem(freq, np.abs(X), 'b', markerfmt=' ', basefmt='-b')

# ax[0].set_xlim(0, 10)

ax[0].set_xlabel('Freq(Hz)')
ax[0].set_ylabel('FFT Amplitude |X(freq)|')

# 实际幅度
X_norm = X / N * 2  # 为何获取真实幅度的时候要✖(2/N)？

ax[1].stem(freq, np.abs(X_norm), 'b', markerfmt=' ', basefmt='-b')

ax[1].set_xlim(-1, 40)

ax[1].set_xlabel('Freq(Hz)')
ax[1].set_ylabel('FFT Amplitude |X(freq)|')

ax[1].annotate(
    r'5(Constant terms)',
    xy=(0, 5),
    xytext=(+10, 50),
    textcoords='offset points',
    arrowprops=dict(arrowstyle='-&gt;', connectionstyle=&quot;arc3,rad=-.5&quot;)
)

ax[1].annotate(
    r'$2\sin(2 \pi \cdot 10 t+3)$',
    xy=(10, 2),
    xytext=(+10, 30),
    textcoords='offset points',
    arrowprops=dict(arrowstyle='-&gt;', connectionstyle=&quot;arc3,rad=-.5&quot;)
)

ax[1].annotate(
    r'$5\sin(2 \pi \cdot 30 t)$',
    xy=(30, 4),
    xytext=(+10, 30),
    textcoords='offset points',
    arrowprops=dict(arrowstyle='-&gt;', connectionstyle=&quot;arc3,rad=-.5&quot;)
)

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307271645872.png-wms#vwid=877&vhei=679" src="https://image.manyacan.com/202307271645872.png-wms#vwid=877&vhei=679"></figure></p><p>对DFT结果进行噪音去除，过滤除去低振幅项：</p><pre><code class="lang-python">freq_clean = pd.Series(X).apply(lambda x: x if np.abs(x) &gt; 1000 else 0).to_numpy()</code></pre><p>可视化去除后的效果：</p><pre><code class="lang-python">fig, ax = plt.subplots(figsize=(10, 4))

ax.stem(freq, np.abs(freq_clean), 'b', markerfmt=' ', basefmt='-b')

ax.set_xlim(-1, 100)

ax.set_xlabel('Freq(Hz)')
ax.set_ylabel('FFT Amplitude |X(freq)|')

ax.annotate(
    r'5(Constant terms)',
    xy=(0, 5 * N / 2),
    xytext=(+10, 50),
    textcoords='offset points',
    arrowprops=dict(arrowstyle='-&gt;', connectionstyle=&quot;arc3,rad=-.5&quot;)
)

ax.annotate(
    r'$2\sin(2 \pi \cdot 10 t+3)$',
    xy=(10, 2 * N / 2),
    xytext=(+10, 30),
    textcoords='offset points',
    arrowprops=dict(arrowstyle='-&gt;', connectionstyle=&quot;arc3,rad=-.5&quot;)
)

ax.annotate(
    r'$5\sin(2 \pi \cdot 30 t)$',
    xy=(30, 4 * N / 2),
    xytext=(+10, 30),
    textcoords='offset points',
    arrowprops=dict(arrowstyle='-&gt;', connectionstyle=&quot;arc3,rad=-.5&quot;)
)

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307271649632.png-wms#vwid=881&vhei=371" src="https://image.manyacan.com/202307271649632.png-wms#vwid=881&vhei=371"></figure></p><p>将过滤后的信号进行傅立叶逆变换：</p><pre><code class="lang-python"># 逆傅里叶变换
ix = ifft(freq_clean)</code></pre><p>可视化观察过滤后的结果：</p><pre><code class="lang-python"># 绘制信号
fig, ax = plt.subplots(figsize=(12, 3))

ax.plot(t, ix, linewidth=.5, color='c', label='IFFT')
ax.plot(t, f_clean, linewidth=.5, color='r', linestyle='-.', label='Raw signal', alpha=0.7)

ax.set_xlabel('Sampling Time')
ax.set_ylabel('Amplitude')
ax.legend()

plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307271651753.png-wms#vwid=999&vhei=294" src="https://image.manyacan.com/202307271651753.png-wms#vwid=999&vhei=294"></figure></p><h2 id="toc_152">😜 纯代码实现DFT</h2><p>$$
X_k=\sum_{n=0}^{N-1}{x_n\cdot e^{-i2\pi kn/N}}
$$</p><p>上面这个公式就是DFT实现的算法，这么一看觉得好简单~😁</p><pre><code class="lang-python">import numpy as np
from scipy.fft import fft


def DFT_slow(x):
    x = np.asarray(x, dtype=float)  # ensure the data type
    N = x.shape[0]  # get the x array length
    n = np.arange(N)  # 1d array
    k = n.reshape((N, 1))  # 2d array, 10 x 1, aka column array
    M = np.exp(-2j * np.pi * k * n / N)
    return np.dot(M, x)  # [a,b] . [c,d] = ac + bd, it is a sum


x = np.random.random(1024)
np.allclose(DFT_slow(f_noise), fft(f_noise))</code></pre><h2 id="toc_153">🙃 傅立叶变换中的哲学</h2><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202304261832989.png-wm04#vwid=540&vhei=378" src="https://image.manyacan.com/202304261832989.png-wm04#vwid=540&vhei=378"></figure></p><blockquote><ol><li>你眼中看似落叶纷飞变化无常的世界，实际只是躺在上帝怀中一份早已谱好的乐章。</li><li>The life you live on may have a completely different new face that can only be seen with a kind of transform.</li></ol></blockquote><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307271702693.gif#vwid=256&vhei=256" src="https://image.manyacan.com/202307271702693.gif#vwid=256&vhei=256"></figure></p><blockquote><ol><li>The big circle is our country, our era. We as an individual is the small tiny inner circle. Without the big circle that drives everything, we are really can’t do too much.</li><li>If you are rich or very successful sometimes, somewhere, it is probably not all because of your own merit, but largely because of your country, people around you, or the good company you work with. Without those big circles that drive you forward, you may not able to achieve what you have now.</li></ol></blockquote><h2 id="toc_154">🤣 参考阅读</h2><ul><li><a href="https://towardsdatascience.com/clean-up-data-noise-with-fourier-transform-in-python-7480252fd9c9">Clean Up Data Noise with Fourier Transform in Python</a></li><li><a href="https://pythonnumericalmethods.berkeley.edu/notebooks/chapter24.00-Fourier-Transforms.html">《Python Numerical Methods》——Chapter 24. Fourier Transform</a></li><li><a href="https://dibsmethodsmeetings.github.io/fourier-transforms/">Duke Institute for Brain Sciences Methods Meetings</a></li></ul>
]]></content:encoded>
<slash:comments>2</slash:comments>
<comments>https://blog.manyacan.com/archives/2041/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2041/</wfw:commentRss>
</item>
<item>
<title>「卷积神经网络」深入浅出</title>
<link>https://blog.manyacan.com/archives/2040/</link>
<guid>https://blog.manyacan.com/archives/2040/</guid>
<pubDate>Sun, 23 Jul 2023 19:55:00 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[六月份初开启了我神经网络相关内容的学习，眨眼间一个月过去了，是时候来总结下自己这个月的学习心得了。卷积层——提取特征卷积核的特点：局部性；平移不变性。卷积的作用在数学上，卷积核的标准定义是两个函...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<p>六月份初开启了我神经网络相关内容的学习，眨眼间一个月过去了，是时候来总结下自己这个月的学习心得了。</p><h2 id="toc_155">卷积层——提取特征</h2><p>卷积核的特点：</p><ul><li>局部性；</li><li>平移不变性。</li></ul><h3 id="toc_156">卷积的作用</h3><p>在数学上，卷积核的标准定义是<strong>两个函数在反转和移位后的乘积的积分：</strong></p><p>$$
(f*g)(t)=\int_{-\infty}^{+\infty}{f}(\tau )g(t-\tau )d\tau
$$</p><p>B站上面有一位数学老师把这个概念讲的特别清楚，大家可以参考：</p><ul><li>Bilibili @小元老师高数线代概率：<a href="https://www.bilibili.com/video/BV1yg4y1b7dC/">【小动画】彻底理解卷积【超形象】卷的由来，小元老师</a></li></ul><p>但是我自己看完觉得即使不去明白数学上的卷积是什么意思，也不影响我们理解深度学习中的卷积（所以说就不用看上面的视频辣！）。</p><blockquote><p>最近又花了几天的时间专门去扣了下“卷积”这两个字，总结就是：数学上的卷积与卷积神经网络中的卷积确实在思想上有一定的相似性，但是不能等价于一个概念。不建议大家为了理解卷积神经网络中的“卷积”而去学习数学中的卷积！！！</p></blockquote><p>在上面的函数表达式中，函数$g$被称为<strong>过滤器(filters)</strong>，函数$f$指的是<strong>信号/图像</strong>。</p><p>而在卷积神经网络里，卷积核其实也被称为过滤器。与上面公式中不同的是，在卷积神经网络里，它不做反转，而是直接<strong>执行逐</strong>元素的乘法和加法。</p><p>之所以在图像处理领域引入了卷积的概念，是因为上个世纪有科学家研究发现，视觉皮层的很多神经元都有一个小的局部感受野，神经元只对有限区域的感受野上的刺激物做出反应。不同的感受野可以重叠，他们共同铺满整个视野。并且发现，一些神经元仅仅对横线有反应，有一些神经元对其他方向的线条有反应，有些神经元的感受野比较大。因此，高级别的神经元的刺激是源于相邻低级别神经元的反应。</p><p>利用这个观点，经过不断的努力，逐渐发展成了现在的卷积神经网络。<strong>通过卷积核提取图像的局部特征</strong>，生成一个个神经元，再经过深层的连接，就构建出了卷积神经网络。</p><blockquote><p>读到这里，你已经得到了一个反复强调的概念，那就是：<strong>卷积核是用来提取特征的</strong>。</p></blockquote><h3 id="toc_157">如何卷积</h3><p>卷积的工作流程如下：</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202306262056449.gif-wm04#vwid=627&vhei=495" src="https://image.manyacan.com/202306262056449.gif-wm04#vwid=627&vhei=495"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202306262056598.gif-wm04#vwid=608&vhei=493" src="https://image.manyacan.com/202306262056598.gif-wm04#vwid=608&vhei=493"></figure></div><p>由上面的动画可以看出，卷积的过程就是使用卷积核对输入矩阵进行一步步地扫描。</p><p>假设输入矩阵为<code>input</code>，卷积核为<code>kernel</code>：</p><pre><code class="lang-python">input = torch.tensor([  # 卷积层输入Tensor
    [1, 2, 0, 3, 1],
    [0, 1, 2, 3, 1],
    [1, 2, 1, 0, 0],
    [5, 2, 3, 1, 1],
    [2, 1, 0, 1, 1]
])

kernel = torch.tensor([  # 卷积核
    [1, 2, 1],
    [0, 1, 0],
    [2, 1, 0]
])</code></pre><p>卷积的结果：</p><pre><code class="lang-python">import torch.nn.functional as F
F.conv2d(input, kernel)
Out[6]: 
tensor([[[[10, 12, 12],
          [18, 16, 16],
          [13,  9,  3]]]])</code></pre><p>以卷积结果的第一行第一列的10为例：其计算过程为：</p><p>$$
10=1×1+2×2+0×1+0×0+1×1+2×0+1×2+2×1+1×0
$$</p><h3 id="toc_158">为什么卷积可以提取特征？</h3><p>这个问题，一直困扰了我很久——为什么卷积的过程就可以提取特征？</p><p>上面卷积的过程中，对于一个3×3卷积核的卷积结果：</p><p>$$
10=1×1+2×2+0×1+0×0+1×1+2×0+1×2+2×1+1×0
$$</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306302024187.png-wm04#vwid=716&vhei=620" src="https://image.manyacan.com/202306302024187.png-wm04#vwid=716&vhei=620"></figure></p><p>上述计算过程可以进一步抽象为：</p><p>$$
S=w_{11}×x_{11}+w_{12}×x_{12}+w_{13}×x_{13}+w_{21}×x_{21}+w_{22}×x_{22}+w_{23}×x_{23}+w_{31}×x_{31}+w_{32}×x_{32}+w_{33}×x_{33}
$$</p><p>上面这个计算过程，像不像向量的内积计算？对于两个向量$a$与$b$，其内积定义为：</p><p>$$
a\cdot b=\left| a \right|\left| b \right|\cos \theta
$$</p><p>当其两者非常相似时，意味着两者之间的夹角$\theta$很小，他们的内积$a \cdot b$会很大，当$\theta=0$时内积取得最大值，此时$a$与$b$重合；当$\theta=180 \degree$时内积取得最小值，此时$a$与$b$共线反向。</p><p>由此过程，上述卷积的结果$S$也被定义为<strong>相似度</strong>。</p><blockquote><p>在《动手学深度学习 PyTorch》一书（P163）中写道，卷积运算也可以被称之为互相关运算，这个“互相关”感觉和这里的相关性有点联系哇！</p></blockquote><h4 id="toc_159">举个🌰</h4><p>如图所示，我们定义一个<code>3×3</code>的卷积核：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306302035153.png#vwid=402&vhei=132" src="https://image.manyacan.com/202306302035153.png#vwid=402&vhei=132"></figure></p><p>对一个输入矩阵：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306302035929.png-wm04#vwid=556&vhei=198" src="https://image.manyacan.com/202306302035929.png-wm04#vwid=556&vhei=198"></figure></p><p>进行卷积。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306302036646.png#vwid=703&vhei=697" src="https://image.manyacan.com/202306302036646.png#vwid=703&vhei=697"></figure></p><p>如图所示卷积过程我们共进行了16次计算，可以发现，经过卷积过程，我们切切实实地从输入矩阵中提取出来了卷积核的特征。</p><p>正是因为卷积层可以提取特征的特性，因此很多教科书中也会把卷积层称为过滤器。经过神经网络的原始数据与刚输入是的“模样”差别越来越大，而其中关于最终结果的信息却越来越丰富。深度学习网络可以看作多层信息蒸馏操作，信息通过连续的过滤器，其纯度越来越高。</p><p>至此，我们已经掌握了卷积的核心，再来大声朗读三遍：</p><ol><li>卷积是为了提取特征！！！</li><li>卷积是为了提取特征！！！</li><li>卷积是为了提取特征！！！</li></ol><p><figure><img class="" alt="一个卷积核提取特征的示例" data-src="https://image.manyacan.com/202307111627383.png-wm04#vwid=1626&vhei=990" src="https://image.manyacan.com/202307111627383.png-wm04#vwid=1626&vhei=990"><figcaption>一个卷积核提取特征的示例</figcaption></figure></p><h3 id="toc_160">卷积核参数</h3><p>卷积核的参数主要有三个：</p><ul><li>核大小：<code>kernel_size</code>；</li><li>步长：<code>stride</code>；</li><li>填充步数：<code>padding</code>；</li><li>空隙：<code>dilation</code>。</li></ul><p><code>kernel_size</code>：定义了卷积的大小范围，在网络中代表感受野的大小，二维卷积核最常见的就是<code>3×3</code>的卷积核。一般情况下，卷积核越大，感受野越大，看到的图片信息越多，所获得的全局特征越好。但大的卷积核会导致计算量的暴增，计算性能也会降低。</p><blockquote><p>上面的Python代码块中所定义的<code>kernel</code>变量是一个<code>3×3</code>的卷积核，因此其卷积核大小为3。</p></blockquote><p><code>stride</code>：卷积核的步长代表提取的精度，步长定义了当卷积核在图像上面进行卷积操作的时候，每次卷积跨越的长度。对于size为2的卷积核，如果step为1，那么相邻步感受野之间就会有重复区域；如果step为2，那么相邻感受野不会重复，也不会有覆盖不到的地方；如果step为3，那么相邻步感受野之间会有一道大小为1颗像素的缝隙，从某种程度来说，这样就遗漏了原图的信息。</p><table><thead><tr><th align="center">kernel_size=2, stride=1</th><th align="center">kernel_size=2, stride=2</th></tr></thead><tbody><tr><td align="center"><figure><img class="" alt="" data-src="https://image.manyacan.com/202306301912927.gif#vwid=244&vhei=259" src="https://image.manyacan.com/202306301912927.gif#vwid=244&vhei=259"></figure></td><td align="center"><figure><img class="" alt="" data-src="https://image.manyacan.com/202306301914060.gif#vwid=294&vhei=288" src="https://image.manyacan.com/202306301914060.gif#vwid=294&vhei=288"></figure></td></tr></tbody></table><p>对于上述<code>5×5</code>输入矩阵<code>input</code>，卷积核<code>kernel</code>的步长<code>stride</code>设置为2，完成一次卷积后的结果是<code>2×2</code>：</p><pre><code class="lang-python">F.conv2d(input, kernel, stride=2)
Out[7]: 
tensor([[[[10, 12],
          [13,  3]]]])</code></pre><p><code>padding</code>：卷积核与图像尺寸不匹配，会造成了卷积后的图片和卷积前的图片尺寸不一致，为了避免这种情况，需要先对原始图片做边界填充处理。</p><table><thead><tr><th align="center">kernel_size=5, stride=1, padding=1</th><th align="center">kernel_size=7, stride=1, padding=2</th></tr></thead><tbody><tr><td align="center"><figure><img class="" alt="" data-src="https://image.manyacan.com/202306301919165.gif#vwid=395&vhei=449" src="https://image.manyacan.com/202306301919165.gif#vwid=395&vhei=449"></figure></td><td align="center"><figure><img class="" alt="" data-src="https://image.manyacan.com/202306301919845.gif#vwid=495&vhei=576" src="https://image.manyacan.com/202306301919845.gif#vwid=495&vhei=576"></figure></td></tr></tbody></table><p><code>padding=1</code>参数为输入矩阵的上下左右周围添加了一圈为0的值，输入矩阵变成了7×7，如下面的<code>input_pad_1</code>所示：</p><pre><code class="lang-python">F.conv2d(input, kernel, padding=1)
Out[8]: 
tensor([[[[ 1,  3,  4, 10,  8],
          [ 5, 10, 12, 12,  6],
          [ 7, 18, 16, 16,  8],
          [11, 13,  9,  3,  4],
          [14, 13,  9,  7,  4]]]])

input_pad_1 = torch.tensor([
    [0 for i in range(7)],
    [0, 1, 2, 0, 3, 1, 0],
    [0, 0, 1, 2, 3, 1, 0],
    [0, 1, 2, 1, 0, 0, 0],
    [0, 5, 2, 3, 1, 1, 0],
    [0, 2, 1, 0, 1, 1, 0],
    [0 for i in range(7)]
])
input_pad_1 = torch.reshape(input_pad_1, (-1, 1, 7, 7))

F.conv2d(input_pad_1, kernel)  # 与添加padding=1参数后得到了相同的结果
Out[10]: 
tensor([[[[ 1,  3,  4, 10,  8],
          [ 5, 10, 12, 12,  6],
          [ 7, 18, 16, 16,  8],
          [11, 13,  9,  3,  4],
          [14, 13,  9,  7,  4]]]])</code></pre><blockquote><p><code>padding</code>参数的添加，有效防止了图像边缘信息的缺失。为了使输入2维Tensor与输出具有相同的宽高，我们可以设置$padding=\frac{kernel\_size-1}{2}$。卷积神经网络中，卷积核的宽、高通常情况下为奇数且相等，这样是为了方便在四周添加相同数量的行（也就是<code>padding</code>）。</p></blockquote><p><code>dilation</code>：这个参数不知道其对应的中文翻译是什么，还是上图来直接看吧：</p><p><figure><img class="" alt="" data-src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/dilation.gif#vwid=395&vhei=381" src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/dilation.gif#vwid=395&vhei=381"></figure></p><p>用图的方式表达就非常明显了，当设置了<code>dilation</code>参数后，卷积过程会被“扩散”开来。</p><blockquote><p>注意，<code>dilation</code>参数的默认值为1，上图的动画过程，设置了<code>dilation=2</code>，太奇葩了！！！不能理解！！！</p></blockquote><p>对于上述<code>5×5</code>输入矩阵<code>input</code>，卷积核<code>kernel</code>的<code>dilation</code>设置为2，完成一次卷积后的结果是<code>1×1</code>：</p><pre><code class="lang-python">F.conv2d(input, kernel, dilation=2)

tensor([[[[7]]]])</code></pre><p>具体计算过程为：</p><p>$$
7=1×1+0×2+1×1+1×0+1×1+0×0+2×2+0×1+1×0
$$</p><h3 id="toc_161">多通道卷积</h3><p>上述讲解的卷积过程只有一个通道，被称为单通道卷积。听名字就可以看出来，与之对应的还有多通道卷积。对于常规的<code>JPG</code>格式图片，其图片颜色由R（红）G（绿）B（蓝）三通道构成。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306302011562.jpeg#vwid=1000&vhei=194" src="https://image.manyacan.com/202306302011562.jpeg#vwid=1000&vhei=194"></figure></p><p>那么对于三个通道的输入层，我们也可以使用三通道的卷积核来进行卷积运算：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306302012857.gif-wm04#vwid=640&vhei=236" src="https://image.manyacan.com/202306302012857.gif-wm04#vwid=640&vhei=236"></figure></p><p>上面的动图里面，输入层为<code>3×5×5</code>（3个通道，每个通道为3×3）；卷积层为<code>3×3×3</code>。三个通道完成分别完成卷积后，在按照对应位置相加，得到最后的结果。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307030924419.gif-wm04#vwid=640&vhei=250" src="https://image.manyacan.com/202307030924419.gif-wm04#vwid=640&vhei=250"></figure></p><h3 id="toc_162">卷积核尺寸、个数的确定</h3><p>首先卷积核表示尺寸、个数的参数一共有4个$[out\_channels, in\_channels, width, height]$：</p><ul><li><code>out_channels</code>：这个参数由输出的通道数决定，也就是通过该层，你想提取几个特征。</li><li><code>in_channels</code>：这个参数由输入矩阵的通道数决定，当输入为三通道RGB图像时，那么对应的<code>in_channels=3</code>。</li><li><code>width</code>、<code>height</code>：这两个代表的就是单个卷积核的尺寸大小，也就是上面叙述过程中反复提到的<code>kernel_size</code>，一般情况下<code>width</code>=<code>height</code>=<code>kernel_size</code>。</li></ul><p>下面我们来通过代码具体看下：</p><pre><code class="lang-python">import torch
from torch.nn import Conv2d
in_channels = 3  #输入通道数量
out_channels =10 #输出通道数量
width = 100      #每个输入通道上尺寸的宽
height = 100     #每个输入通道上尺寸的高
kernel_size = 3  #每个输入通道上的卷积尺寸3×3
batch_size = 1   #批数量

input = torch.randn(batch_size, in_channels, width, height)
conv_layer = torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size)
out_put = conv_layer(input)

print(input.shape)
print(out_put.shape)
print(conv_layer.weight.shape)
torch.Size([1, 3, 100, 100]) 
torch.Size([1, 10, 98, 98])
torch.Size([10, 3, 3, 3])</code></pre><ul><li><code>input.shape=[1, 3, 100, 100]</code>：说明输入了1张图片，该张图片3个通道（RGB），图片尺寸为100×100；</li><li><code>conv_layer.weight.shape=[10, 3, 3, 3]</code>：说明卷积核共有10组，每组有3个通道（对应图片的RGB3个通道，每个通道都有一个卷积核），每个卷积核的尺寸大小为3×3；</li><li><code>out_put.shape=[1, 10, 98, 98]</code>：说明输出了1个对象（对应输入的1张图片），该张图片有10个通道（对应10组卷积核，也就是说提取了10组特征），每个图片的大小为98×98。</li></ul><p><code>out_put</code>输出的图片尺寸大小计算方式为（以高为例，宽的计算方法相同）：</p><p>$$
Height_{Output} = Height_{Input} - Kernel\_Size + 1
$$</p><blockquote><p>上面的计算方式有点局限，仅适用于<code>padding=1</code>、<code>stride=1</code>、<code>dilation=1</code>的情况下。</p></blockquote><p>总结一句话就是：</p><ul><li><strong>输入通道个数 = 卷积核通道个数；</strong></li><li><strong>卷积核个数 = 输出通道个数。</strong></li></ul><p>基于上面的分析与讲解，我们可以对卷积核参数的作用进行一个总结：</p><ul><li>核大小<code>kernel_size</code>：卷积核的元素决定了其可以提取的特征，卷积核大小决定了扫描的范围；</li><li>步长<code>stride</code>：设置该参数可以解决原始输入图像分辨率冗余的问题，大幅减小图像的宽高；</li><li>填充步数<code>padding</code>：防止原始图像丢失边缘信息；</li><li>空隙：<code>dilation</code>。</li></ul><h2 id="toc_163">池化层——压缩特征</h2><p>“池化”这俩字儿有点抽象，我更喜欢<a href="https://zh.d2l.ai/">《动手学深度学习 PyTorch版》</a>中的名称——汇聚层，“汇聚”两个字就把池化层的作用描述的非常形象——将局部特征进行“汇聚”，从而达到压缩信息的目的。</p><p>其中，池化分为两种：最大池化和平均池化。以最大池化为例，其工作原理如下图所示：</p><p><figure><img class="" alt="最大池化原理图" data-src="https://image.manyacan.com/202306302021564.png-wm04#vwid=958&vhei=621" src="https://image.manyacan.com/202306302021564.png-wm04#vwid=958&vhei=621"><figcaption>最大池化原理图</figcaption></figure></p><p>正如上所说，池化层的目的是压缩特征信息。对于图片这种数据，对其进行特征压缩是十分有必要的，而对于某些情况下，例如阿尔法Go的卷积神经网络设计中就没有池化层，因为对于围棋来说，每一个棋子（相当于一个像素）的位置信息都是至关重要的。</p><p>代码实现：</p><pre><code class="lang-python">import torch
from torch.nn.functional import max_pool2d

a = torch.tensor([
    [1, 1, 2, 4],
    [5, 6, 7, 8],
    [3, 2, 1, 0],
    [1, 2, 3, 4]
], dtype=torch.float32)
a = a.reshape((1, 1, 4, 4))

a
Out[4]: 
tensor([[[[1., 1., 2., 4.],
          [5., 6., 7., 8.],
          [3., 2., 1., 0.],
          [1., 2., 3., 4.]]]])

max_pool2d(a, kernel_size=2)
Out[5]: 
tensor([[[[6., 8.],
          [3., 4.]]]])</code></pre><blockquote><p>注意：池化层的步长<code>stride</code>默认等于其核大小，并不是1！！！因此对于任意一个<code>n×n</code>的图像，在经过<code>kernel_size=m</code>的池化层后，其大小应该变为$\frac{n}{m}×\frac{n}{m}$。</p></blockquote><p>除了最大值池化，还有一种池化方法为平均值池化：</p><pre><code class="lang-python">from torch.nn.functional import avg_pool2d


avg_pool2d(a, kernel_size=2)
Out[7]: 
tensor([[[[3.2500, 5.2500],
          [2.0000, 2.0000]]]])</code></pre><p>PyTorch官方文档：</p><ul><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html?highlight=max_pool2d#torch.nn.functional.max_pool2d">TORCH.NN.FUNCTIONAL.MAX_POOL2D</a></li><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.avg_pool2d.html?highlight=avgpool2d">TORCH.NN.FUNCTIONAL.AVG_POOL2D</a></li></ul><p>池化层的作用与存在的意义就是将卷积层提取出来的特征进行压缩，从每一个感受野中提取出来最大值或者平均值，用来代表感受野内整体的分布情况，从而<strong>达到压缩特征的目的</strong>。</p><h2 id="toc_164">激活层</h2><p>避免层数塌陷</p><h2 id="toc_165">小Tips</h2><p>为什么DL模型中复杂度越高的模型往往是层数越多，而不是每一层的权重参数越多呢？</p><blockquote><p>换句话形象的话来问这个问题就是：为什么DL模型都是往“长”处发展，而不是往“胖”处发展？这是因为权重参数或者是卷积核个数的增加代表着是分解的特征多，而往“长”处发展意味着我们对一些特征往“精”处学。往“胖”处发展有点像我们学了很多们技术，但是都是浅尝辄止；而往“长”处发展意味着我们这对某几门技术往“死”里学，虽然我们学的相对少，但是只要学“精”了，一样是好的。</p></blockquote><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307041255292.png-wm04#vwid=756&vhei=391" src="https://image.manyacan.com/202307041255292.png-wm04#vwid=756&vhei=391"></figure></p><h2 id="toc_166">常见卷积神经网络</h2><h3 id="toc_167">LeNet</h3><p>LeNet是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。这个模型是由AT&T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名），目的是识别邮件图像中的手写数字。</p><p>当时，Yann LeCun发表了第一篇通过反向传播成功训练卷积神经网络的研究，这项工作代表了十多年来神经网络研究开发的成果。当时，LeNet取得了与支持向量机（support vector machines）性能相媲美的成果，成为监督学习的主流方法。</p><p>LeNet被广泛用于自动取款机（ATM）机中，帮助识别处理支票的数字。</p><p>时至今日，一些自动取款机仍在运行Yann LeCun和他的同事Leon Bottou在上世纪90年代写的代码呢！</p><h4 id="toc_168">网络结构</h4><pre><code class="lang-python">net = Sequential(
    Conv2d(1, 6, kernel_size=5, padding=2), Sigmoid(),  # Input: 256×1×28×28; Output: 256×6×28×28.
    AvgPool2d(kernel_size=2, stride=2),  # Input: 256×6×28×28; Output: 256×6×14×14.
    Conv2d(6, 16, kernel_size=5), Sigmoid(),  # Input: 256×6×14×14; Output: 256×16×10×10.
    AvgPool2d(kernel_size=2, stride=2),  # Input: 256×16×10×10; Output: 256×16×5×5.
    Flatten(),  # Input: 256×16×5×5; Output: 256×400.
    Linear(16 * 5 * 5, 120), Sigmoid(),  # Input: 256×400; Output: 256×120.
    Linear(120, 84), Sigmoid(),  # Input: 256×120; Output: 256×84.
    Linear(84, 10)  # Input: 256×84; Output: 256×10.
)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307121227629.png-wm04#vwid=1413&vhei=888" src="https://image.manyacan.com/202307121227629.png-wm04#vwid=1413&vhei=888"></figure></p><h3 id="toc_169">AlexNet</h3><p>在LeNet提出后，卷积神经网络在计算机视觉和机器学习领域中很有名气。但卷积神经网络并没有主导这些领域。这是因为虽然LeNet在小数据集上取得了很好的效果，但是在更大、更真实的数据集上训练卷积神经网络的性能和可行性还有待研究。事实上，在上世纪90年代初到2012年之间的大部分时间里，神经网络往往被其他机器学习方法超越，如支持向量机（support vector machines）。</p><p>Alex Krizhevsky、Ilya Sutskever和Geoff Hinton提出了一种新的卷积神经网络变体<strong>AlexNet</strong>。在2012年ImageNet挑战赛中取得了轰动一时的成绩。AlexNet以Alex Krizhevsky的名字命名，他是论文Krizhevsky.Sutskever.Hinton.2012的第一作者。</p><p>AlexNet和LeNet的设计理念非常相似，但也存在显著差异。</p><ol><li>AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。</li><li>AlexNet使用ReLU而不是sigmoid作为其激活函数。</li></ol><p>下面的内容将深入研究AlexNet的细节。</p><h4 id="toc_170">模型设计</h4><p>在AlexNet的第一层，卷积窗口的形状是$11\times11$。由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标。第二层中的卷积窗口形状被缩减为$5\times5$，然后是$3\times3$。此外，在第一层、第二层和第五层卷积层之后，加入窗口形状为$3\times3$、步幅为2的最大汇聚层。而且，AlexNet的卷积通道数目是LeNet的10倍。</p><p>在最后一个卷积层后有两个全连接层，分别有4096个输出。这两个巨大的全连接层拥有将近1GB的模型参数。由于早期GPU显存有限，原版的AlexNet采用了双数据流设计，使得每个GPU只负责存储和计算模型的一半参数。幸运的是，现在GPU显存相对充裕，所以现在很少需要跨GPU分解模型（因此，本书的AlexNet模型在这方面与原始论文稍有不同）。</p><h4 id="toc_171">激活函数</h4><p>此外，AlexNet将sigmoid激活函数改为更简单的ReLU激活函数。一方面，ReLU激活函数的计算更简单，它不需要如sigmoid激活函数那般复杂的求幂运算。另一方面，当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易。当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数。相反，ReLU激活函数在正区间的梯度总是1。因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。</p><h4 id="toc_172">容量控制和预处理</h4><p>AlexNet通过暂退法控制全连接层的模型复杂度，而LeNet只使用了权重衰减。为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色。这使得模型更健壮，更大的样本量有效地减少了过拟合。</p><h4 id="toc_173">网络结构</h4><pre><code class="lang-python">net = nn.Sequential(
    # 这里使用一个11*11的更大窗口来捕捉对象。
    # 同时，步幅为4，以减少输出的高度和宽度。
    # 另外，输出通道的数目远大于LeNet
    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(), # Input: 128×1×224×224; Output: 128×96×54×54.
    nn.MaxPool2d(kernel_size=3, stride=2),
    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数
    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # 使用三个连续的卷积层和较小的卷积窗口。
    # 除了最后的卷积层，输出通道的数量进一步增加。
    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度
    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Flatten(),
    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合
    nn.Linear(6400, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(4096, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000
    nn.Linear(4096, 10)
)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307121233470.png-wm04#vwid=1459&vhei=1458" src="https://image.manyacan.com/202307121233470.png-wm04#vwid=1459&vhei=1458"></figure></p><h3 id="toc_174">VGG</h3><p>与芯片设计中工程师从放置晶体管到逻辑元件再到逻辑块的过程类似，神经网络架构的设计也逐渐变得更加抽象。研究人员开始从单个神经元的角度思考问题，发展到整个层，现在又转向块，重复层的模式。使用块的想法首先出现在牛津大学的<a href="http://www.robots.ox.ac.uk/~vgg/">视觉几何组（visual geometry group）</a>的<strong>VGG网络</strong>中。通过使用循环和子程序，可以很容易地在任何现代深度学习框架的代码中实现这些重复的架构。</p><p>经典卷积神经网络的基本组成部分是下面的这个序列：</p><ol><li>带填充以保持分辨率的卷积层；</li><li>非线性激活函数，如ReLU；</li><li>汇聚层，如最大汇聚层。</li></ol><p>而一个VGG块与之类似，由一系列卷积层组成，后面再加上用于空间下采样的最大汇聚层。在最初的VGG论文中，作者使用了带有$3\times3$卷积核、填充为1（保持高度和宽度）的卷积层，和带有$2 \times 2$汇聚窗口、步幅为2（每个块后的分辨率减半）的最大汇聚层。</p><p><figure><img class="" alt="VGG结构与AlexNet对比" data-src="https://image.manyacan.com/202307121408221.svg" src="https://image.manyacan.com/202307121408221.svg"><figcaption>VGG结构与AlexNet对比</figcaption></figure></p><h4 id="toc_175">网络结构</h4><pre><code class="lang-python">def vgg_block(num_convs, in_channels, out_channels):
    layers = []
    for _ in range(num_convs):
        layers.append(nn.Conv2d(in_channels, out_channels,
                                kernel_size=3, padding=1))
        layers.append(nn.ReLU())
        in_channels = out_channels
    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
    return nn.Sequential(*layers)


def vgg(conv_arch):
    conv_blks = []
    in_channels = 1
    # 卷积层部分
    for (num_convs, out_channels) in conv_arch:
        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))
        in_channels = out_channels

    return nn.Sequential(
        *conv_blks, nn.Flatten(),
        # 全连接层部分
        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 10)
    )
  

 conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))
net = vgg(conv_arch)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307121356261.png-wm04#vwid=1503&vhei=991" src="https://image.manyacan.com/202307121356261.png-wm04#vwid=1503&vhei=991"></figure></p><h3 id="toc_176">NiN</h3><p>最初的NiN网络是在AlexNet后不久提出的，显然从中得到了一些启示。NiN使用窗口形状为$11\times 11$、$5\times 5$和$3\times 3$的卷积层，输出通道数量与AlexNet中的相同。每个NiN块后有一个最大汇聚层，汇聚窗口形状为$3\times 3$，步幅为2。</p><p>NiN和AlexNet之间的一个显著区别是NiN完全取消了全连接层。相反，NiN使用一个NiN块，其输出通道数等于标签类别的数量。最后放一个<strong>全局平均汇聚层</strong>（global average pooling layer），生成一个对数几率   （logits）。NiN设计的一个优点是，它显著减少了模型所需参数的数量。然而，在实践中，这种设计有时会增加训练模型的时间。</p><h4 id="toc_177">网络结构</h4><p>NIN块：</p><pre><code class="lang-python">def nin_block(in_channels, out_channels, kernel_size, strides, padding):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU()
    )</code></pre><p>网络结构：</p><pre><code class="lang-python">net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, strides=4, padding=0),
    nn.MaxPool2d(3, stride=2),
    nin_block(96, 256, kernel_size=5, strides=1, padding=2),
    nn.MaxPool2d(3, stride=2),
    nin_block(256, 384, kernel_size=3, strides=1, padding=1),
    nn.MaxPool2d(3, stride=2),
    nn.Dropout(0.5),
    # 标签类别数是10
    nin_block(384, 10, kernel_size=3, strides=1, padding=1),
    nn.AdaptiveAvgPool2d((1, 1)),
    # 将四维的输出转成二维的输出，其形状为(批量大小,10)
    nn.Flatten()
)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307132336791.png-wm04#vwid=1665&vhei=1941" src="https://image.manyacan.com/202307132336791.png-wm04#vwid=1665&vhei=1941"></figure></p><h3 id="toc_178">GoogLeNet</h3><p>在2014年的ImageNet图像识别挑战赛中，一个名叫<strong>GoogLeNet</strong>的网络架构大放异彩。GoogLeNet吸收了NiN中串联网络的思想，并在此基础上做了改进。</p><p>本文的一个观点是，有时使用不同大小的卷积核组合是有利的。</p><p>在GoogLeNet中，基本的卷积块被称为<strong>Inception块</strong>（Inception block）。这很可能得名于电影《盗梦空间》（Inception），因为电影中的一句话“我们需要走得更深”（“We need to go deeper”）。</p><p>Inception块由四条并行路径组成。前三条路径使用窗口大小为$1\times 1$、$3\times 3$和$5\times 5$的卷积层，从不同空间大小中提取信息。中间的两条路径在输入上执行$1\times 1$卷积，以减少通道数，从而降低模型的复杂性。第四条路径使用$3\times 3$最大汇聚层，然后使用$1\times 1$卷积层来改变通道数。</p><p>这四条路径都使用合适的填充来使输入与输出的高和宽一致，最后我们将每条线路的输出在通道维度上连结，并构成Inception块的输出。在Inception块中，通常调整的超参数是每层输出通道数。</p><h4 id="toc_179">网络结构</h4><p>Inception块：</p><pre><code class="lang-python">class Inception(nn.Module):
    # c1--c4是每条路径的输出通道数
    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):
        super(Inception, self).__init__(**kwargs)
        # 线路1，单1x1卷积层
        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)
        # 线路2，1x1卷积层后接3x3卷积层
        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)
        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)
        # 线路3，1x1卷积层后接5x5卷积层
        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)
        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)
        # 线路4，3x3最大汇聚层后接1x1卷积层
        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)

    def forward(self, x):
        p1 = F.relu(self.p1_1(x))
        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))
        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))
        p4 = F.relu(self.p4_2(self.p4_1(x)))
        # 在通道维度上连结输出
        return torch.cat((p1, p2, p3, p4), dim=1)</code></pre><p>网络结构：</p><pre><code class="lang-python">b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
                   nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))

b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),
                   nn.ReLU(),
                   nn.Conv2d(64, 192, kernel_size=3, padding=1),
                   nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))

b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),
                   Inception(256, 128, (128, 192), (32, 96), 64),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))

b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),
                   Inception(512, 160, (112, 224), (24, 64), 64),
                   Inception(512, 128, (128, 256), (24, 64), 64),
                   Inception(512, 112, (144, 288), (32, 64), 64),
                   Inception(528, 256, (160, 320), (32, 128), 128),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))

b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),
                   Inception(832, 384, (192, 384), (48, 128), 128),
                   nn.AdaptiveAvgPool2d((1, 1)),
                   nn.Flatten())

net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307132349604.png-wm04#vwid=1235&vhei=1498" src="https://image.manyacan.com/202307132349604.png-wm04#vwid=1235&vhei=1498"></figure></p><h2 id="toc_180">完</h2><p>当你把深度学习神经网络中的全部数学知识捋一遍会发现，好像其实也没有那么难以理解，甚至其中除了矩阵运算相关的内容有点“高深”以外，剩下的数学知识有个高中水平就可以来理解。</p><p><strong>但事实证明，当这些看起来觉得非常简单的数学问题组成了足够大的规模，就可以产生魔法般的效果。</strong></p>
]]></content:encoded>
<slash:comments>0</slash:comments>
<comments>https://blog.manyacan.com/archives/2040/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2040/</wfw:commentRss>
</item>
<item>
<title>上帝公式——Euler's formula</title>
<link>https://blog.manyacan.com/archives/2039/</link>
<guid>https://blog.manyacan.com/archives/2039/</guid>
<pubDate>Fri, 14 Jul 2023 19:56:00 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[定义什么是欧拉公式？$$e^{i\pi}+1=0$$这个公式将：$e$：自然对数的底；$i$：虚数的单位；$\pi$：圆周率结合到了一起，优美巧妙，因此也被称为“上帝公式”。Quote / 参考...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<h2 id="toc_181">定义</h2><p>什么是欧拉公式？</p><p>$$
e^{i\pi}+1=0
$$</p><p>这个公式将：</p><ul><li>$e$：自然对数的底；</li><li>$i$：虚数的单位；</li><li>$\pi$：圆周率</li></ul><p>结合到了一起，优美巧妙，因此也被称为“上帝公式”。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307141954638.webp-wm04#vwid=2560&vhei=1440" src="https://image.manyacan.com/202307141954638.webp-wm04#vwid=2560&vhei=1440"></figure></p><blockquote><h4 id="toc_182">Quote / 参考</h4><p>维基百科：<a href="https://zh.wikipedia.org/wiki/%E6%AC%A7%E6%8B%89%E5%85%AC%E5%BC%8F">欧拉公式</a>。</p></blockquote><h2 id="toc_183">复数i与自然常数e</h2><p>在推导与证明欧拉公式之前，有必要对其中两个重要组成部分：</p><ul><li>复数——$i$；</li><li>自然常数——$e$</li></ul><p>进行复习。</p><h3 id="toc_184">复数i</h3><p>复数$i$的定义其实很简单，就是：</p><p>$$
i^2=-1
$$</p><p>最初提出复数的那一帮人，就是因为解高次方程的时候会遇到这样的情况：</p><p>$$
x^2+1=0
$$</p><p>虽然在我们对于自然数的理解下，这样求解出来的数没有任何实际意义，但是其在数学中却是真实存在的。</p><p><figure><img class="" alt="数学家们之间的解方程大赛" data-src="https://image.manyacan.com/202307141110912.png-wm04#vwid=1061&vhei=637" src="https://image.manyacan.com/202307141110912.png-wm04#vwid=1061&vhei=637"><figcaption>数学家们之间的解方程大赛</figcaption></figure></p><p>对于复数这个在自然界不存在，但是在数学中却是存在的东西，笛卡尔将其命名为<code>Imaginary number</code>——想象中的数字。</p><h4 id="toc_185">意义</h4><p>所以，复数在数学中的意义到底应该是什么呢？仅仅就是为了解方程吗🤔？我们又是如何来表达它呢？接下来，让我们通过一个小例子来认识下它：</p><p>从自然数1开始，将其与$i$相乘，得到了：</p><p>$$
1×i=i
$$</p><p>在此基础上，然后再乘一个$i$：</p><p>$$
1×i×i=-1
$$</p><p>可以看到，自然数1再经过两次乘$i$后，完成了反向。如果再乘上两个：</p><p>$$
1×i×i×i×i=1
$$</p><p>之后会发现，1竟然又回到了最初的起点。</p><p>看到了这里，你的心里可能已经猜到了😆——这个过程，像极了旋转：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307141354246.png-wm04#vwid=579&vhei=471" src="https://image.manyacan.com/202307141354246.png-wm04#vwid=579&vhei=471"></figure></p><p>所以，这个时候我们很容易会发现复数虚部所在的轴与实部所在的轴构成了一个平面。在这个平面中，一个复数的实部为x轴，虚部$i$为y轴，两者张成了一个二维复平面。</p><p>对于一个复数$4+3i$，其在复平面上的表达类似于一个向量：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307142009064.png-wm04#vwid=574&vhei=471" src="https://image.manyacan.com/202307142009064.png-wm04#vwid=574&vhei=471"></figure></p><h4 id="toc_186">运算</h4><h5 id="toc_187">加法运算</h5><p>在复平面中，复数的运算法则遵循矢量运算法则（平行四边形法则，实部与实部相加，虚部与虚部相加），例如：</p><p>$$
(-1+2i)+(2-1i)=1+i
$$</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307141407300.png-wm04#vwid=579&vhei=471" src="https://image.manyacan.com/202307141407300.png-wm04#vwid=579&vhei=471"></figure></p><h5 id="toc_188">乘法运算</h5><p>令：</p><p>$$
y=\begin{cases}
    1, n=0\\
    \left( 1+i \right) ^n, n&gt;0\\
\end{cases}
$$</p><p>计算得：</p><p>$$
y_{n=0}=1
\\
y_{n=1}=1+i
\\
y_{n=2}=\left( 1+i \right) ^2=1+2i+\left( i \right) ^2=2i
\\
y_{n=3}=\left( 1+i \right) ^3=2i\times \left( 1+i \right) =-2+2i
\\
y_{n=4}=\left( 1+i \right) ^4=2i\times 2i=-4
\\
...
$$</p><p>依次绘制出$y_{n=0}、y_{n=1}、y_{n=2}、...$，会发现：$y_{m-1}$乘上$1+i$后变成了$y_{m}$。相比之下，$y_{m}$由$y_{m-1}$所代表的向量旋转45°，且模长变为原来得$\sqrt{2}$倍得来。其中45°是$1+i$与x轴的夹角，$\sqrt{2}$是$1+i$在复平面的模长。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307142025893.png-wm04#vwid=720&vhei=471" src="https://image.manyacan.com/202307142025893.png-wm04#vwid=720&vhei=471"></figure></p><p>由此，我们可以进行一个推广：在复平面上，一个复数$b=m+ni$乘上任意一个复数$a$，其几何含义为：让这个复数$a$所代表的向量进行旋转并缩放，旋转的角度（复数$b$的辐角，即$m+ni$与x轴的夹角）为$arctan\frac{n}{m}$，缩放倍数（复数$b$的模长）为$\sqrt{m^2+n^2}$。</p><p>一个有趣的现象，如果我们在复平面上绘制出$(1+i)^n$所代表的点：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307141439750.png-wm04#vwid=611&vhei=471" src="https://image.manyacan.com/202307141439750.png-wm04#vwid=611&vhei=471"></figure></p><h4 id="toc_189">参考Python绘图代码</h4><pre><code class="lang-python">def get_value(n):
    x = (1 + 1j) ** n
    return x.real, x.imag


def plot_arrow(x, y, ax=plt, lines=True):
    if lines:
        ax.vlines(x, 0, y, 'r', '--')
        ax.hlines(y, 0, x, 'r', '--')
    ax.arrow(0, 0, x, y,
             color='cyan',
             head_width=0.2,
             fc='y',
             length_includes_head=True
             )


def plot_text(x, y, ax=plt):
    valign, halign = None, None
    if y &gt; 0:
        text_y = f'{y}i'
        if x != 0: text_y = '+' + text_y
        y += .2
        valign = 'bottom'
    elif y == 0:
        text_y = ''
        y += .2
        valign = 'bottom'
    else:
        text_y = f'{y}i'
        y -= .2
        valign = 'top'

    if x &gt; 0:
        text_x = f'{x}'
        x += .2
        halign = 'left'
    elif x == 0:
        text_x = ''
        x += .2
        halign = 'left'
    else:
        text_x = f'{x}'
        x -= .2
        halign = 'right'

    ax.text(x=x, y=y,  #文本x、y轴坐标
            s=f'${text_x}{text_y}$',  #文本内容
            fontdict=dict(fontsize=12),  #字体属性字典
            verticalalignment=valign,
            horizontalalignment=halign,
            bbox={  #添加文字背景色
                'facecolor': 'white',  #填充色
                'edgecolor': 'gray',  #外框色
                'alpha': 0.3,  #框透明度
                'pad': .1,  #本文与框周围距离
                'boxstyle': 'round'
            }
            )


# 绘图全局设置
plt.rcParams.update({
    # 'font.size': 15,
    'font.family': ['Times New Roman', 'SimSun']
})

limit_coor_num = 200

plt.hlines(0, -limit_coor_num, limit_coor_num, '#ccc', '--')
plt.vlines(0, -limit_coor_num, limit_coor_num, '#ccc', '--')

plt.xlim([-limit_coor_num, limit_coor_num])
plt.ylim([-limit_coor_num, limit_coor_num])
plt.yticks(
    [i for i in range(-limit_coor_num, limit_coor_num + 1) if i % 40 == 0],
    [f'{i}i' for i in range(-limit_coor_num, limit_coor_num + 1) if i % 40 == 0]
)

plt.xlabel('Real')
plt.ylabel('Imaginary')
plt.title('Complex Plane')
# plt.grid()

# point_list = [(1, 0), (0, 1), (-1, 0), (0, -1)]
# point_list = [(-1, 2), (2, -1), (1, 1)]

# for x, y in point_list:
#     plot_arrow(x, y)
#     plot_text(x, y)

# for i in range(8):
#     x, y = get_value(i)
#     plot_arrow(x, y, lines=False)
#     plot_text(x, y)

points_plt = [get_value(i) for i in np.linspace(0, 100, 1000)]
x, y = zip(*points_plt)
plt.scatter(x, y)

# plot_arrow(0, -2, lines=False)
# plot_text(0, -2)

plt.show()</code></pre><blockquote><h4 id="toc_190">Quote / 参考</h4><p>Bilibili @隐姓埋名的刘老：<a href="https://www.bilibili.com/video/BV1dS4y1A7ty?vd_source=a46443a6a463a0116a6bf542812ba6dd">复数，一个充满故事又奇特的数</a>。</p></blockquote><h3 id="toc_191">自然常数e</h3><p>在数学中$e$被称为自然常数（Natural Constant）。</p><p>$$
e=2.71828...
$$</p><p>可是，自然数有这么多，为什么偏偏$e$会被称为<strong>自然常数</strong>？</p><p>先来看一个简单的案例，在经济学中，有一个概念叫做复利运算。假设银行一年的年利率为100%，你在银行存了1块钱，那么一年之后你的存款应该会变为：</p><p>$$
1×(1+100\%)=2
$$</p><p>但其实银行的利率往往还可以进行拆分，比如你把1块钱存在银行半年，这个时候利率就变成了50%，在半年后你拿到的钱就是：</p><p>$$
1×(1+50\%)=1.5
$$</p><p>然后你可以将你的一块五再存银行半年，再经过半年后，你的钱就会变成：</p><p>$$
1×(1+50\%)×(1+50\%)=1.5×(1+50\%)=2.25
$$</p><p>这个时候，你会惊奇地发现，一年分两次存钱比一次存钱要多拿到$0.25$！！！</p><p>那是不是意味着我分的次数越多就拿到的越多呢？</p><p>假设我们分为n期，那经过n期后我们的利率就会变为：</p><p>$$
(1+\frac{1}{n})^n
$$</p><p>问题就是，随着n的增大，上面的利率真的会无限增大吗？在高等数学中，有这么一个极限定义：</p><p>$$
\underset{n\rightarrow \infty}{\lim}\left( 1+\frac{1}{n} \right) ^n=e
$$</p><p>也就是说，随着$n$的无限增大，$(1+\frac{1}{n})^n$并不是也可以无穷增大的，而是趋近于一个值$2.718281828459045...$。而这个值，就是自然常数$e$的值。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307141520548.png-wm04#vwid=588&vhei=471" src="https://image.manyacan.com/202307141520548.png-wm04#vwid=588&vhei=471"></figure></p><p>上面这个分为n期的假设，其实非常符合自然界中万事万物发展的规律，一切事物的变化都不是突然来的，都是经过n期的逐渐积累，然后引发了质变。这也就是其名字“自然常数”的来历，因此其定义像极了世间万物发展的模式。</p><blockquote><h4 id="toc_192">Quote / 参考</h4><ol><li>Bilibili @隐姓埋名的刘老：<a href="https://www.bilibili.com/video/BV1t3411p7Kn?vd_source=a46443a6a463a0116a6bf542812ba6dd">自然常数e这个数，怎么就自然了？</a>；</li><li>Bilibili @隐姓埋名的刘老：<a href="https://www.bilibili.com/video/BV1bF411P7RL?vd_source=a46443a6a463a0116a6bf542812ba6dd">用几何直觉理解欧拉公式！【中学生也能懂|manim】</a>。</li></ol></blockquote><h2 id="toc_193">欧拉公式</h2><h3 id="toc_194">思想的转变</h3><p>由上面对于自然常数$e$的讲解可知：</p><p>$$
\underset{n\rightarrow \infty}{\lim}\left( 1+\frac{1}{n} \right) ^n=e
$$</p><p>$e$的定义并不是一个“实实在在”存在的数字，那么<strong>对于$e^{i\pi}$，其也并不意味着$i\pi$个$e$相乘！！！</strong></p><p>那么，$e^{i\pi}$到底代表什么呢？</p><p>对于上面提到的等式：</p><p>$$
\underset{n\rightarrow \infty}{\lim}\left( 1+\frac{1}{n} \right) ^n=e
$$</p><p>还可以进行进一步的推广：</p><p>$$
\underset{n\rightarrow \infty}{\lim}\left( 1+\frac{x}{n} \right) ^n=e^x
$$</p><p>那么欧拉公式就可以等价变换为：</p><p>$$
e^{i\pi} = \underset{n\rightarrow \infty}{\lim}\left( 1+\frac{i\pi}{n} \right) ^n
$$</p><p>上面这个等式，才是$e^{i\pi}$的真正含义！！！</p><h3 id="toc_195">可视化求解</h3><p>定义求极限的函数：</p><pre><code class="lang-python">def get_value(n, p):
    x = np.power((1 + 3.14j / n), p)
    return x.real, x.imag</code></pre><p>绘图：</p><pre><code class="lang-python">plt.xlim([-3, 3])
plt.ylim([0, 4])
plt.yticks(
    [i for i in range(0, 5) if i % 2 == 0],
    [f'{i}i' for i in range(0, 5) if i % 2 == 0]
)

for i in [1, 2, 5, 10, 20, 10000]:
    point_coor = [get_value(i, j) for j in range(1, i + 1)]
    x, y = zip(*point_coor)
    plt.scatter(x, y, s=(1 / i) * 100, marker='*')
    plt.plot(x, y, label=f'n={i}')

# x、y轴等比例
ax = plt.gca()
ax.set_aspect(1)

plt.xlabel('Real')
plt.ylabel('Imaginary')
plt.title(r'$e^{i\pi} = \underset{n\rightarrow \infty}{\lim}\left( 1+\frac{i\pi}{n} \right) ^n=-1$')
plt.legend(ncol=3, loc='lower center', bbox_to_anchor=(0.5, -0.4))
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307141703969.png-wm04#vwid=572&vhei=516" src="https://image.manyacan.com/202307141703969.png-wm04#vwid=572&vhei=516"></figure></p><p>由上面可视化的结果可以看出，对于：</p><p>$$
e^{i\pi} = \underset{n\rightarrow \infty}{\lim}\left( 1+\frac{i\pi}{n} \right) ^n
$$</p><p>当$n\rightarrow \infty$时，$\left( 1+\frac{i\pi}{n} \right)^n$趋近于$-1$。</p><p>那么对于更一般的情况：</p><p>$$
e^{i\theta} = \underset{n\rightarrow \infty}{\lim}\left( 1+\frac{i\theta}{n} \right) ^n
$$</p><p>应该为多少呢？</p><p>首先将求解极限的函数改写为：</p><pre><code class="lang-python">def get_value(n, p, theta):
    x = np.power((1 + theta * 1j / n), p)
    return x.real, x.imag</code></pre><p>以便用于支持任意角度的输入。</p><p>接下来以$\frac{\pi}{2}、\frac{2\pi}{3}、\frac{5\pi}{4}、\frac{7\pi}{4}$为例，可视化其结果：</p><pre><code class="lang-python">fig, ax_arr = plt.subplots(2, 2)
fig.subplots_adjust(hspace=0.5)

theta_list = [1 / 2, 2 / 3, 5 / 4, 7 / 4]
sub_title = [r'\frac{1}{2}', r'\frac{2}{3}', r'\frac{5}{4}', r'\frac{7}{4}']
for i in range(ax_arr.shape[0]):
    for j in range(ax_arr.shape[1]):
        cur_ax = ax_arr[i, j]

        for k in [1, 2, 5, 10, 20, 10000]:
            point_coor = [get_value(k, v, theta_list[i * 2 + j] * np.pi) for v in range(1, k + 1)]
            x, y = zip(*point_coor)
            cur_ax.scatter(x, y, s=(1 / k) * 100, marker='*')
            cur_ax.plot(x, y, label=f'n={i}')

        cur_ax.axvline(0, color='#ccc', linestyle='--')
        cur_ax.axhline(0, color='#ccc', linestyle='--')

        # x、y轴等比例
        ax = plt.gca()
        ax.set_aspect(1)

        if j == 0:
            cur_ax.set_ylabel('Imaginary')
        if i == 1:
            cur_ax.set_xlabel('Real')

        cur_ax.set_title(f'$' + sub_title[i * 2 + j] + '\pi$')


lines, labels = fig.axes[-1].get_legend_handles_labels()  # 获取最后一个子图的图例
fig.legend(lines, labels, ncol=3, loc='upper center', bbox_to_anchor=(0.5, 0.03))
plt.tight_layout()
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307141939790.png-wm04#vwid=616&vhei=540" src="https://image.manyacan.com/202307141939790.png-wm04#vwid=616&vhei=540"></figure></p><p>当$n\rightarrow \infty$时，$\left( 1+\frac{i\theta}{n} \right)^n$无限趋近于点$(\cos\theta, \sin\theta)$，也就是说：</p><p>$$
e^{i\theta} = \underset{n\rightarrow \infty}{\lim}\left( 1+\frac{i\theta}{n} \right) ^n = \cos\theta+i\sin\theta
$$</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202307141950379.gif#vwid=853&vhei=421" src="https://image.manyacan.com/202307141950379.gif#vwid=853&vhei=421"></figure></p><p>这，便是宇宙间最优美的公式——欧拉公式。</p>
]]></content:encoded>
<slash:comments>0</slash:comments>
<comments>https://blog.manyacan.com/archives/2039/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2039/</wfw:commentRss>
</item>
<item>
<title>「Deep Learning」PyTorch初步认识</title>
<link>https://blog.manyacan.com/archives/2038/</link>
<guid>https://blog.manyacan.com/archives/2038/</guid>
<pubDate>Mon, 26 Jun 2023 17:22:00 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[PyTorch的安装、CUDA环境的配置以及Tensor的基本操作请查看「深度学习」PyTorch笔记-01-基础知识。Tensor基本操作创建直接输入值创建Tensor：import torc...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<blockquote><p>PyTorch的安装、CUDA环境的配置以及Tensor的基本操作请查看<a href="https://blog.manyacan.com/archives/2030/">「深度学习」PyTorch笔记-01-基础知识</a>。</p></blockquote><h2 id="toc_196">Tensor基本操作</h2><h3 id="toc_197">创建</h3><p>直接输入值创建Tensor：</p><pre><code class="lang-python">import torch
torch.Tensor([[1, 2], [3, 4]])

Out[3]: 
tensor([[1., 2.],
        [3., 4.]])</code></pre><p>打印Tensor类型：</p><pre><code class="lang-python">a = torch.Tensor([[1, 2], [3, 4]])
a.type(), type(a)

Out[5]: ('torch.FloatTensor', torch.Tensor)</code></pre><p>创建全为1的Tensor：</p><pre><code class="lang-python">torch.ones(2, 3)

Out[11]: 
tensor([[1., 1., 1.],
        [1., 1., 1.]])</code></pre><p>创建一个与指定Tensor形状相同且全1的Tensor：</p><pre><code class="lang-python">torch.ones_like(a)

Out[12]: 
tensor([[1., 1.],
        [1., 1.]])</code></pre><p>创建全为0的Tensor：</p><pre><code class="lang-python">torch.zeros(3, 2)

Out[13]: 
tensor([[0., 0.],
        [0., 0.],
        [0., 0.]])</code></pre><p>创建一个与指定Tensor形状相同且全0的Tensor：</p><pre><code class="lang-python">torch.zeros_like(a)

Out[14]: 
tensor([[0., 0.],
        [0., 0.]])</code></pre><p>生成一个任意shape包含0~1随机值的Tensor：</p><pre><code class="lang-python">torch.rand(2, 3)

Out[15]: 
tensor([[0.0535, 0.6409, 0.0688],
        [0.5141, 0.4700, 0.5606]])</code></pre><p>生成随机一个符合正态分布的Tensor：</p><pre><code class="lang-python">torch.normal(
    mean=0,
    std=torch.rand(5)
)

Out[16]: tensor([ 0.8522, -0.2326,  0.5324, -0.0838,  1.1735])</code></pre><p>可以使用：</p><pre><code class="lang-python">torch.manual_seed(666)</code></pre><p>来设置随机种子。</p><p>创建等步长的Tensor：</p><pre><code class="lang-python">torch.arange(0, 10, 1)

Out[17]: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</code></pre><p>创建等间隔的Tensor：</p><pre><code class="lang-python">torch.linspace(0, 10, 5)

Out[18]: tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])</code></pre><p>生成随机乱序序号的Tensor：</p><pre><code class="lang-python">torch.randperm(10)

Out[19]: tensor([2, 5, 4, 6, 9, 1, 7, 8, 3, 0])</code></pre><p>创建对角Matrix的Tensor：</p><pre><code class="lang-python">torch.eye(4)

Out[20]: 
tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 1.]])</code></pre><h3 id="toc_198">索引与数据筛选</h3><h4 id="toc_199">where</h4><p><a href="https://pytorch.org/docs/stable/generated/torch.where.html?highlight=where#torch.where"><code>torch.where(condition, x, y)</code></a>： 按照条件从x和y中选出满足条件的元素组成新的tensor。</p><p>举个🌰：</p><pre><code class="lang-python">a = torch.arange(1, 10, 1).reshape(3, -1)
b = torch.ones_like(a) * 5

torch.where(a &lt; b, a, b)  # 如果a&lt;b，则输出a，否则输出b

Out[22]: 
tensor([[1, 2, 3],
        [4, 5, 5],
        [5, 5, 5]])

torch.where(a &lt; b, 1, 0)

Out[23]: 
tensor([[1, 1, 1],
        [1, 0, 0],
        [0, 0, 0]])</code></pre><h4 id="toc_200">index_select</h4><p><a href="https://pytorch.org/docs/stable/generated/torch.index_select.html?highlight=index_select#torch.index_select"><code>torch.index_select(input, dim, index, *, out=None)</code></a>: 按照指定索引输出tensor。</p><p>举个🌰：</p><pre><code class="lang-python">a

Out[24]: 
tensor([[1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]])

torch.index_select(a, dim=0, index=torch.tensor([0, 2, 1]))  # 在a的第0维上（按行划分），分别获取第0维上的0、2、1个元素

Out[25]: 
tensor([[1, 2, 3],
        [7, 8, 9],
        [4, 5, 6]])

torch.index_select(a, dim=1, index=torch.tensor([0, 2]))  # 在a的第1维上（按列划分），分别获取第0维上的0、2个元素

Out[26]: 
tensor([[1, 3],
        [4, 6],
        [7, 9]])</code></pre><h4 id="toc_201">gather</h4><p><code>torch.gather(input, dim, index, *, sparse_grad=False, out=None)</code>: 在指定维度上按照索引赋值输出tensor。</p><pre><code class="lang-python">a = torch.tensor([[1,2,3], [4,5,6]])

torch.gather(input=a, dim=1, index=torch.tensor([[2,0,2,1], [1,1,0,0]]))

Out[28]: 
tensor([[3, 1, 3, 2],
        [5, 5, 4, 4]])</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306251942840.png-wm04#vwid=1444&vhei=436" src="https://image.manyacan.com/202306251942840.png-wm04#vwid=1444&vhei=436"></figure></p><pre><code class="lang-python">torch.gather(input=a, dim=0, index=torch.tensor([[0, 1, 0], [1,0,1], [0, 0, 0],[1,1,1]]))
Out[29]: 
tensor([[1, 5, 3],
        [4, 2, 6],
        [1, 2, 3],
        [4, 5, 6]])</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306251942705.png-wm04#vwid=1446&vhei=570" src="https://image.manyacan.com/202306251942705.png-wm04#vwid=1446&vhei=570"></figure></p><h4 id="toc_202">masked_select</h4><p><a href="https://pytorch.org/docs/stable/generated/torch.masked_select.html?highlight=masked_select#torch.masked_select"><code>torch.masked_select(input, mask, *, out=None)</code></a>: 按照mask输出tensor。</p><pre><code class="lang-python">a

Out[32]: 
tensor([[1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]])

torch.gt(a, 6)

Out[33]: 
tensor([[False, False, False],
        [False, False, False],
        [ True,  True,  True]])

torch.masked_select(a, torch.gt(a, 5))

Out[34]: tensor([6, 7, 8, 9])</code></pre><h4 id="toc_203">take</h4><p><a href="https://pytorch.org/docs/stable/generated/torch.take.html?highlight=torch+take#torch.take"><code>torch.take(input, index)</code></a>: 将输入看成1D Tensor，按照索引得到输出tensor。</p><pre><code class="lang-python">torch.take(a, index=torch.tensor([8, 6, 3, 2, 1, 0]))

Out[35]: tensor([9, 7, 4, 3, 2, 1])</code></pre><h4 id="toc_204">nonzero</h4><p><a href="https://pytorch.org/docs/stable/generated/torch.nonzero.html?highlight=nonzero#torch.nonzero"><code>torch.nonzero(input, *, out=None, as_tuple=False)</code></a>: 输出非0元素的坐标。</p><pre><code class="lang-python">b = torch.eye(3)

b

Out[37]: 
tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]])

torch.nonzero(b)

Out[38]: 
tensor([[0, 0],
        [1, 1],
        [2, 2]])</code></pre><h3 id="toc_205">组合与拼接</h3><h4 id="toc_206">cat</h4><pre><code class="lang-python">a = torch.linspace(1, 6, 6).view(2, 3)
a
Out[39]: 
tensor([[1., 2., 3.],
        [4., 5., 6.]])
b = torch.zeros_like(a)
b
Out[40]: 
tensor([[0., 0., 0.],
        [0., 0., 0.]])
torch.cat((a, b), dim=0)
Out[41]: 
tensor([[1., 2., 3.],
        [4., 5., 6.],
        [0., 0., 0.],
        [0., 0., 0.]])
torch.cat((a, b), dim=1)
Out[42]: 
tensor([[1., 2., 3., 0., 0., 0.],
        [4., 5., 6., 0., 0., 0.]])</code></pre><h4 id="toc_207">stack</h4><pre><code class="lang-python">torch.stack((a, b), dim=0)
Out[43]: 
tensor([[[1., 2., 3.],
         [4., 5., 6.]],
        [[0., 0., 0.],
         [0., 0., 0.]]])
torch.stack((a, b), dim=0).shape
Out[44]: torch.Size([2, 2, 3])</code></pre><blockquote><p>注意<code>torch.stack()</code>与<code>torch.cat()</code>的区别，<code>torch.cat()</code>不增加Tensor的维数，<code>torch.stack()</code>增加了维数。</p></blockquote><h3 id="toc_208">切片</h3><h4 id="toc_209">chunk</h4><pre><code class="lang-python">a = torch.linspace(1, 16, 16).view(-1, 8)
a
Out[45]: 
tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12., 13., 14., 15., 16.]])
torch.chunk(a, 2)
Out[46]: 
(tensor([[1., 2., 3., 4., 5., 6., 7., 8.]]),
 tensor([[ 9., 10., 11., 12., 13., 14., 15., 16.]]))
torch.chunk(a, 4, dim=1)
Out[47]: 
(tensor([[ 1.,  2.],
         [ 9., 10.]]),
 tensor([[ 3.,  4.],
         [11., 12.]]),
 tensor([[ 5.,  6.],
         [13., 14.]]),
 tensor([[ 7.,  8.],
         [15., 16.]]))</code></pre><h4 id="toc_210">split</h4><pre><code class="lang-python">torch.split(a, 2)
Out[48]: 
(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],
         [ 9., 10., 11., 12., 13., 14., 15., 16.]]),)
torch.split(a, 4, dim=1)
Out[49]: 
(tensor([[ 1.,  2.,  3.,  4.],
         [ 9., 10., 11., 12.]]),
 tensor([[ 5.,  6.,  7.,  8.],
         [13., 14., 15., 16.]]))</code></pre><blockquote><p><code>torch.chunk(a, 4, dim=1)</code>中的“4”代表分为4份，<code>torch.split(a, 4, dim=1)</code>中的4代表每组有4个。</p></blockquote><h2 id="toc_211">读取数据集——Dataset</h2><p>PyTorch中使用<a href="https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset"><code>torch.utils.data.Dataset</code></a>加载数据集，类具体的定义方法为：</p><pre><code class="lang-python">class MyDataset(Dataset):
    def __init__(self, root_dir, label):
        self.root_dir = root_dir
        self.label = label
        self.img_path = self.get_img_path()

    def __getitem__(self, idx):
        data = Image.open(self.img_path[idx])
        return data, self.label

    def get_img_path(self):
        path = os.path.join(self.root_dir, self.label)
        return glob.glob(os.path.join(path, '*.jpg'))

    def __len__(self):
        return len(self.img_path)</code></pre><h2 id="toc_212">图片格式调整——tensorboard</h2><p>使用<a href="https://pytorch.org/vision/stable/transforms.html#transforms-scriptability"><code>torchvision.transforms</code></a>类对图片格式进行调整，选几个常用方法进行学习：</p><h3 id="toc_213">.ToTensor()</h3><p>将输入的<code>PIL</code>图片转化为Tensor对象：</p><pre><code class="lang-python">from PIL import Image
from torchvision import transforms

img_path = r'D:\code\...\16838648_415acd9e3f.jpg'
img = Image.open(img_path)

trans_tensor = transforms.ToTensor()
img_tensor = trans_tensor(img)
img_tensor</code></pre><h3 id="toc_214">.Normalize()</h3><p>传入均值和标准差，对图片Tensor进行标准化：</p><pre><code class="lang-python">trans_nor = transforms.Normalize([.5, .5, .5], [.5, .5, .5])
img_nor = trans_nor(img_tensor)
img_nor</code></pre><h3 id="toc_215">.Rescale()</h3><p>对图片大小进行reshape：</p><pre><code class="lang-python">trans_resize = transforms.Resize((512, 512))
img_resize = trans_resize(img)
img_resize.size</code></pre><h3 id="toc_216">.Compose()</h3><p>将多个transforms方法进行串联：</p><pre><code class="lang-python">transformer = transforms.Compose([
    transforms.RandomGrayscale(.4),
    transforms.ColorJitter(.4),
    transforms.Resize(512),
    transforms.ToTensor()
])</code></pre><h2 id="toc_217">加载数据集——DataLoader</h2><h2 id="toc_218">可视化工具——tensorboard</h2><ul><li>中文介绍：<a href="https://zhuanlan.zhihu.com/p/471198169">https://zhuanlan.zhihu.com/p/471198169</a></li><li>官方文档：<a href="https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter#torch.utils.tensorboard.writer.SummaryWriter">https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter#torch.utils.tensorboard.writer.SummaryWriter</a></li></ul><h3 id="toc_219">引包</h3><pre><code class="lang-python">from torch.utils.tensorboard.writer import SummaryWriter

# 查看帮助
help(SummaryWriter)

# 创建对象
writer = SummaryWriter('logs')  # 需要传入log地址</code></pre><h3 id="toc_220">写入图片</h3><p>写入单张图片：</p><pre><code class="lang-python">writer.add_image('demo', img_array, dataformats='HWC')</code></pre><p>写入多张图片：</p><pre><code class="lang-python">writer.add_images('Test Data in Batching', imgs, i)</code></pre><h3 id="toc_221">写入折线图</h3><pre><code class="lang-python"># Examples
for i in range(100):
    writer.add_scalar('$y=x^2+1$', i, i ** 2 + 1)</code></pre><p>如果需要在一行写入两个图像，例如：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306261522585.png-wm04#vwid=1389&vhei=591" src="https://image.manyacan.com/202306261522585.png-wm04#vwid=1389&vhei=591"></figure></p><p>可以使用<code>/</code>作为图名的分隔符来操作：</p><pre><code class="lang-python"> writer.add_scalar('Loss/Train', epoch_train_loss.item(), epoch)
writer.add_scalar('Loss/Test', epoch_test_loss.item(), epoch)</code></pre><h3 id="toc_222">模型的可视化</h3><pre><code class="lang-python">writer.add_graph(module, demo_inputs)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306261654028.png-wm04#vwid=1917&vhei=1919" src="https://image.manyacan.com/202306261654028.png-wm04#vwid=1917&vhei=1919"></figure></p><h3 id="toc_223">最后记得关闭对象</h3><pre><code class="lang-python">writer.close()</code></pre><h3 id="toc_224">一个奇奇怪怪的BUG</h3><p>明明已经按照提示使用<kbd>Ctrl</kbd>+<kbd>C</kbd>结束了进程，但是点击IP地址还是可以访问到该端口：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306262215010.png-wm04#vwid=2144&vhei=361" src="https://image.manyacan.com/202306262215010.png-wm04#vwid=2144&vhei=361"></figure></p><p>而且这个时候，如果我再次运行别的项目的Tensorboard，浏览器端口中的内容不会实时更新。<a href="https://blog.csdn.net/qq_34342853/article/details/124793166">CSDN @YuQiao0303</a>回答了在Linux端的解决方案：</p><ol><li>查看占用该端口的程序；</li><li>强制结束该程序；</li><li>重新运行Tensorboard。</li></ol><p>那我就在windows下也操作一遍：</p><pre><code class="lang-shell">C:\Windows\System32&gt;netstat -aon|findstr &quot;6006&quot;  # 查看占用6006端口程序的PID
  TCP    127.0.0.1:6006         0.0.0.0:0              LISTENING       27796

C:\Windows\System32&gt;tasklist|findstr &quot;6006&quot;  # 查看占用6006端口的程序

C:\Windows\System32&gt;taskkill /T /F /PID 27796  # 强制杀死该程序
SUCCESS: The process with PID 27796 (child process of PID 30540) has been terminated.</code></pre><p>然后重新运行<code>tensorboard</code>即可，完美解决问题。</p><h2 id="toc_225">神经网络模型的建立——torch.nn</h2><p><a href="https://pytorch.org/docs/stable/nn.html"><code>torch.nn</code></a>定义了PyTorch中的所有网络层。</p><h3 id="toc_226">基本结构</h3><p>模型的基本结构：</p><pre><code class="lang-python">import torch

class MyModule(torch.nn.Module):
    def __init__(self):
        &quot;&quot;&quot;
        定义模型的初始化参数、方法
        &quot;&quot;&quot;
        super(MyModule, self).__init__()

    def forward(self, input):
        &quot;&quot;&quot;
        向前传播
        :param input:  
        :return: 
        &quot;&quot;&quot;
        output = input + 1
        return output


demo = MyModule()
x = torch.tensor(1.)
demo(x)  # tensor(2.)</code></pre><h3 id="toc_227">单个卷积层演示</h3><pre><code class="lang-python">input = torch.tensor([  # 卷积层输入Tensor
    [1, 2, 0, 3, 1],
    [0, 1, 2, 3, 1],
    [1, 2, 1, 0, 0],
    [5, 2, 3, 1, 1],
    [2, 1, 0, 1, 1]
])

kernel = torch.tensor([  # 卷积核
    [1, 2, 1],
    [0, 1, 0],
    [2, 1, 0]
])</code></pre><p>输入矩阵与卷积核的shape改造为符合卷积神经网络输入的格式，官方文档将其定义为：input – input tensor of shape (minibatch, in_channels, iH,iW)。想想也确实是这么个理，神经网络主要应用与图像处理，对于一个512×512大小的RGB三通道图片，其形状为3×512×512。如果使用DataLoader读取文件，batch_size=64，那么其输入矩阵形状为64×3×512×512。</p><pre><code class="lang-python">input = torch.reshape(input, (-1, 1, 5, 5))
kernel = torch.reshape(kernel, (-1, 1, 3, 3))
input.shape, kernel.shape  # Reshape
Out[5]: (torch.Size([1, 1, 5, 5]), torch.Size([1, 1, 3, 3]))</code></pre><p>在卷积层中，滤波器（也称为卷积核或特征检测器）是一组权重数组，它以滑动窗口的方式在图像上进行扫描，计算每一步的点积，并将该点积输出到一个称为特征图的新数组中。这种滑动窗口的扫描称为卷积。让我们看一下这个过程的示例，以帮助理解正在发生的事情。</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202306262056449.gif-wm04#vwid=627&vhei=495" src="https://image.manyacan.com/202306262056449.gif-wm04#vwid=627&vhei=495"></figure><figure><img class="" alt="图片" data-src="https://image.manyacan.com/202306262056598.gif-wm04#vwid=608&vhei=493" src="https://image.manyacan.com/202306262056598.gif-wm04#vwid=608&vhei=493"><figcaption>图片</figcaption></figure></div><blockquote><p>卷积过程的可视化可以参考：<a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">Convolution arithmetic</a>。</p></blockquote><p>卷积过程：</p><pre><code class="lang-python">import torch.nn.functional as F
F.conv2d(input, kernel)
Out[6]: 
tensor([[[[10, 12, 12],
          [18, 16, 16],
          [13,  9,  3]]]])</code></pre><p>以卷积结果的第一行第一列的10为例：其计算过程为：</p><p>$$
10=1×1+2×2+0×1+0×0+1×1+2×0+1×2+2×1+1×0
$$</p><p>对于一个5×5的矩阵，卷积核步长<code>stride</code>设置为2，使用3×3的卷积核完成一次卷积后的结果是2×2：</p><pre><code class="lang-python">F.conv2d(input, kernel, stride=2)
Out[7]: 
tensor([[[[10, 12],
          [13,  3]]]])</code></pre><p><code>padding=1</code>参数为输入矩阵的上下左右周围添加了一圈为0的值，输入矩阵变成了7×7，如下面的<code>input_pad_1</code>所示：</p><pre><code class="lang-python">F.conv2d(input, kernel, padding=1)
Out[8]: 
tensor([[[[ 1,  3,  4, 10,  8],
          [ 5, 10, 12, 12,  6],
          [ 7, 18, 16, 16,  8],
          [11, 13,  9,  3,  4],
          [14, 13,  9,  7,  4]]]])

input_pad_1 = torch.tensor([
    [0 for i in range(7)],
    [0, 1, 2, 0, 3, 1, 0],
    [0, 0, 1, 2, 3, 1, 0],
    [0, 1, 2, 1, 0, 0, 0],
    [0, 5, 2, 3, 1, 1, 0],
    [0, 2, 1, 0, 1, 1, 0],
    [0 for i in range(7)]
])
input_pad_1 = torch.reshape(input_pad_1, (-1, 1, 7, 7))

F.conv2d(input_pad_1, kernel)  # 与添加padding=1参数后得到了相同的结果
Out[10]: 
tensor([[[[ 1,  3,  4, 10,  8],
          [ 5, 10, 12, 12,  6],
          [ 7, 18, 16, 16,  8],
          [11, 13,  9,  3,  4],
          [14, 13,  9,  7,  4]]]])</code></pre><h3 id="toc_228">最大池化——MaxPool2d()</h3><p>池化层与卷积层类似，都是通过滤波器对输入数据（通常是从卷积层输出的特征图）进行卷积运算。</p><p>然而，池化层的功能不是特征检测，而是降低维度或降采样。最常用的两种池化方法是最大池化和平均池化。在最大池化中，滤波器在输入上滑动，并在每一步选择具有最大值的像素作为输出。在平均池化中，滤波器输出滤波器所经过像素的平均值。</p><p>首先来定义一个用于输入模型的Tensor：</p><pre><code class="lang-python">a = torch.tensor([
    [1, 2, 0, 3, 1],
    [0, 1, 2, 3, 1],
    [1, 2, 1, 0, 0],
    [5, 2, 3, 1, 1],
    [2, 1, 0, 1, 1]
], dtype=torch.float32)  # 如果不使用float类型，MaxPool2d()将报错：RuntimeError: &quot;max_pool2d&quot; not implemented for 'Long'
a = torch.reshape(a, (-1, 1, 5, 5))
a.shape
Out[11]: torch.Size([1, 1, 5, 5])</code></pre><p>定义模型：</p><pre><code class="lang-python">class MyModule(torch.nn.Module):
    def __init__(self):
        super(MyModule, self).__init__()
        self.maxpool_00 = torch.nn.MaxPool2d(
            kernel_size=3,
            ceil_mode=True  # 当卷积核走到最后，发现余下的不够走一步了，是否还继续“强走”
        )
    def forward(self, input):
        output = self.maxpool_00(input)
        return output</code></pre><p>输出结果：</p><pre><code class="lang-python">module = MyModule()
module(a)
Out[12]: 
tensor([[[[2., 3.],
          [5., 1.]]]])</code></pre><p>卷积输出结果中，第一行第一列的2是<code>a</code>左上角前三行前三列中的最大值。</p><h3 id="toc_229">非线性激活层</h3><ul><li>官方文档：<a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity</a></li></ul><div class="photos large"><figure><img class="" alt="ReLU函数" data-src="https://image.manyacan.com/202306261559694.png#vwid=640&vhei=480" src="https://image.manyacan.com/202306261559694.png#vwid=640&vhei=480"><figcaption>ReLU函数</figcaption></figure><figure><img class="" alt="Sigmoid函数" data-src="https://image.manyacan.com/202306261600220.png#vwid=640&vhei=480" src="https://image.manyacan.com/202306261600220.png#vwid=640&vhei=480"><figcaption>Sigmoid函数</figcaption></figure></div><p>以ReLU函数为例，当输入小于0时，全部记为0；当输入大于0时，不做处理：</p><pre><code class="lang-python">a = torch.tensor([
    [0, -.5],
    [-1, 3]
])
a = torch.reshape(a, (-1, 1, 2, 2))
a.shape

torch.nn.ReLU()(a)
Out[15]: 
tensor([[[[0., 0.],
          [0., 3.]]]])</code></pre><h3 id="toc_230">串联多个网络层——Sequential</h3><p>实际操作的神经网络都是十分复杂的，以下面这个基于<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>数据集的神经网络模型为例：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306261618009.png#vwid=850&vhei=201" src="https://image.manyacan.com/202306261618009.png#vwid=850&vhei=201"></figure></p><p>作用非常简单，就是将多个网络层串联到一起，没有使用<code>nn.Sequential()</code>前：</p><pre><code class="lang-python">class MyModule(torch.nn.Module):
    def __init__(self):
        super(MyModule, self).__init__()
        self.conv_00 = torch.nn.Conv2d(3, 32, 5, padding=2)  # Input: 3@32×32, Output: 32@32×32
        self.maxpool_00 = torch.nn.MaxPool2d(2)  # Input: 32@32×32, Output: 32@16×16
        self.conv_01 = torch.nn.Conv2d(32, 32, 5, padding=2)  # Input: 32@16×16, Output: 32@16×16
        self.maxpool_01 = torch.nn.MaxPool2d(2)  # Input: 32@16×16, Output: 32@8×8
        self.conv_02 = torch.nn.Conv2d(32, 64, 5, padding=2)  # Input: 32@8×8, Output: 64@8×8
        self.maxpool_02 = torch.nn.MaxPool2d(2)  # Input: 64@8×8, Output: 64@4×4
        self.flatten = torch.nn.Flatten()  # Input: 64@4×4, Output: 1024
        self.linear_00 = torch.nn.Linear(1024, 64)  # Input: 1024, Output: 64
        self.linear_01 = torch.nn.Linear(64, 10)  # Input: 64, Output: 10

    def forward(self, inputs):
        _ = self.conv_00(inputs)
        _ = self.maxpool_00(_)
        _ = self.conv_01(_)
        _ = self.maxpool_01(_)
        _ = self.conv_02(_)
        _ = self.maxpool_02(_)
        _ = self.flatten(_)
        _ = self.linear_00(_)
        outputs = self.linear_01(_)
        return outputs</code></pre><p>使用<code>nn.Sequential()</code>后：</p><pre><code class="lang-python">from torch.nn import Conv2d, MaxPool2d, Flatten, Linear

# 使用Sequential来优化网络结构
class MyModule(torch.nn.Module):
    def __init__(self):
        super(MyModule, self).__init__()

        self.model = torch.nn.Sequential(
            Conv2d(3, 32, 5, padding=2),  # Input: 3@32×32, Output: 32@32×32
            MaxPool2d(2),  # Input: 32@32×32, Output: 32@16×16
            Conv2d(32, 32, 5, padding=2),  # Input: 32@16×16, Output: 32@16×16
            MaxPool2d(2),  # Input: 32@16×16, Output: 32@8×8
            Conv2d(32, 64, 5, padding=2),  # Input: 32@8×8, Output: 64@8×8
            MaxPool2d(2),  # Input: 64@8×8, Output: 64@4×4
            Flatten(),  # Input: 64@4×4, Output: 1024
            Linear(1024, 64),  # Input: 1024, Output: 64
            Linear(64, 10)  # Input: 64, Output: 10
        )

    def forward(self, inputs):
        outputs = self.model(inputs)
        return outputs</code></pre><h2 id="toc_231">损失函数</h2><ul><li>官方文档：<a href="https://pytorch.org/docs/stable/nn.html#loss-functions">https://pytorch.org/docs/stable/nn.html#loss-functions</a></li></ul><p>损失函数的作用有两点：</p><ol><li>计算实际输出和目标之间的差距；</li><li>为我们更新输出提供一定的依据（反向传播）。</li></ol><p>第一点很容易理解，既然叫做了”损失函数“，顾名思义，就是用来计算”损失“的函数，那么这个损失来自哪里呢？假设我们的真实值是<code>y_true</code>，在进行训练的过程中，我们会有一个预测值<code>y_pred</code>。损失函数就是用来描述两者之间的差异的。</p><p>以L1损失函数为例：</p><pre><code class="lang-python">y_true = torch.tensor([2, 3, 4], dtype=torch.float32)
y_pred = torch.tensor([2, 1, 6], dtype=torch.float32)

torch.nn.L1Loss(reduction='sum')(y_true, y_pred)  # ()
Out[18]: tensor(4.)

torch.nn.L1Loss()(y_true, y_pred)
Out[19]: tensor(1.3333)</code></pre><p>当设置参数<code>reduction='sum'</code>时，相当于：</p><pre><code class="lang-python">torch.sum(torch.abs(y_pred - y_true))
Out[20]: tensor(4.)</code></pre><p>参数为空时，相当于：</p><pre><code class="lang-python">torch.sum(torch.abs(y_pred - y_true)) / len(y_true)</code></pre><h2 id="toc_232">优化器——optim</h2><p>优化器的作用是配合Loss函数的输出，进行反向传播，优化模型参数。</p><pre><code class="lang-python">optim = torch.optim.SGD(module.parameters(), lr=0.01)  # 定义优化器时候，需要传入优化参数与学习率</code></pre><blockquote><p>如果出现每一轮训练后，Loss不降反增的情况，请尝试减小学习率。至于为什么会出现这种情况，请参考<a href="https://blog.manyacan.com/archives/2036/">「Machine Learning」梯度下降</a>。</p></blockquote><p>优化器配合Loss函数进行反向传播优化：</p><pre><code class="lang-python">for epoch in range(20):
    epoch_loss = 0  # 对每一轮的loss进行累加，观察经过多轮学习后，loss是否有下降
    for i, data in enumerate(test_loader):
        imgs, targets = data
        outputs = module(imgs)
        res_loss = loss(outputs, targets)
        optim.zero_grad()  # 每一次训练前，都需要将上一步的梯度归零
        res_loss.backward()  # Loss函数反向传播
        optim.step()  # 优化器更新参数
        epoch_loss += res_loss
        print(f'第{epoch}轮中的第{i}批数据训练Loss值为：{res_loss.item()}.')

    print(f'第{epoch}轮的累积Loss值为：{epoch_loss.item()}.')</code></pre><h2 id="toc_233">修改定义好的模型</h2><h3 id="toc_234">加载预训练模型</h3><p>以<code>vgg16</code>模型为例，如何对包内置模型进行修改使用：</p><pre><code class="lang-python">import torch
import torchvision

vgg_pretrained = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.IMAGENET1K_V1)
vgg = torchvision.models.vgg16()</code></pre><p><code>vgg_pretrained</code>模型是导入了训练好参数的模型。</p><pre><code class="lang-python">vgg_pretrained
Out[4]: 
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))

    ...
      
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    ...      
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)</code></pre><h3 id="toc_235">修改模型输出参数</h3><p>观察模型网络结构可以发现，vgg模型的输出<code>out_features=1000</code>，说明其是针对1000个target进行分类的。</p><p>而我们的任务是针对10个target进行分类，因此可以在<code>vgg_pretrained</code>模型的最后再添加一层新的线性层：</p><pre><code class="lang-python">vgg_pretrained.add_module('Linear', torch.nn.Linear(1000, 10))
vgg_pretrained
Out[9]: 
VGG(
  (features): Sequential(
...
  )
  (avgpool): ...
  (classifier): Sequential(
     ...
  )
  (Linear): Linear(in_features=1000, out_features=10, bias=True)
)
</code></pre><p>也可以使用：</p><pre><code class="lang-python">vgg_pretrained.classifier.add_module('Linear', torch.nn.Linear(1000, 10))
vgg_pretrained
Out[12]: 
VGG(
  (features): Sequential(
...
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
...
    (Linear): Linear(in_features=1000, out_features=10, bias=True)
  )
)
</code></pre><blockquote><p>观察两种添加方式有何不同。</p></blockquote><p>除此之外，我们还可以对最后一层输出的进行修改，将最后一个线性层的<code>out_features=1000</code>改为<code>out_features=10</code>：</p><pre><code class="lang-python">vgg.classifier[6] = torch.nn.Linear(4096, 10)
vgg
Out[13]: 
VGG(
  (features): Sequential(
 ...
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
...
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)</code></pre><p>至此，就完成了对<code>VGG16</code>模型的修改，已经可以在我们自己的数据集上面使用。</p><h3 id="toc_236">训练结果展示</h3><p>一次完美的训练过程：Loss逐渐下降、准确度逐渐上升。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306261550812.png-wm04#vwid=1437&vhei=1292" src="https://image.manyacan.com/202306261550812.png-wm04#vwid=1437&vhei=1292"></figure></p><h2 id="toc_237">模型的保存与加载</h2><h3 id="toc_238">保存模型结构+模型参数</h3><pre><code class="lang-python">torch.save(vgg_pretrained,'SavedModule.pth')</code></pre><p>模型的加载：</p><pre><code class="lang-python"># 模型的加载
model = torch.load('./SavedModule.pth')</code></pre><h3 id="toc_239">只保留模型参数</h3><pre><code class="lang-python">torch.save(vgg_pretrained.state_dict(), 'SavedStateDict.pth')</code></pre><p>模型的加载：</p><pre><code class="lang-python">model = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.IMAGENET1K_V1)
model.classifier.add_module('Linear', torch.nn.Linear(1000, 10))
model.load_state_dict(torch.load('SavedStateDict.pth'))
model</code></pre><blockquote><p>注意：这种保存方式是官方所推荐的，可以显著减小模型文件的体积。但是加载模型的时候，需要先引入模型，如果模型的结构有所修改，也要进行修改后才可以传入保存的模型参数。</p></blockquote><h2 id="toc_240">使用GPU进行训练</h2><h3 id="toc_241">CUDA的安装</h3><p>PyTorch必须要借助于CUDA才可以使用Nvidia显卡对模型进行训练，因此必须先安装CUDA，具体的安装过程参考：<a href="https://blog.manyacan.com/archives/2030/">「深度学习」PyTorch笔记-01-基础知识</a>。</p><h3 id="toc_242">数据转移到GPU</h3><p>使用GPU完成训练过程，必须将模型、损失函数、输入数据转移到GPU中。</p><h4 id="toc_243">第一种转移方式</h4><p>模型的转移：</p><pre><code class="lang-python"># 创建网络模型
module = MyModule()

# 在GPU上训练模型
if torch.cuda.is_available():
    print('GPU is available in this computer.')
    module.cuda()</code></pre><p>损失函数的转移：</p><pre><code class="lang-python"># 损失函数
loss_fun = CrossEntropyLoss()

if torch.cuda.is_available():
    # 转移到GPU上
    loss_fun.cuda()</code></pre><p>训练/测试数据的转移：</p><pre><code class="lang-python"># 检验当前模型在测试集上的效果
# module.eval()  # 参考module.train()
with torch.no_grad():  # 在测试集上检验效果，不需要进行梯度下降优化
    for i, data in enumerate(test_loader):
        imgs, targets = data

        # 将数据转移到GPU
        if torch.cuda.is_available():
            imgs = imgs.cuda()
            targets = targets.cuda()</code></pre><h4 id="toc_244">第二种转移方式</h4><p>第一种转移方式每次都需要经过<code>if</code>判断，不够高效。一般都使用第二种：</p><pre><code class="lang-python">device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 将模型转移到GPU上
module.to(device)

...

# 将损失函数转移到GPU上
loss_fun.to(device)

...

# 将数据转移到GPU上
imgs = imgs.to(device)
targets = targets.to(device)</code></pre><h2 id="toc_245">使用Google colab</h2><p>大厂还是大厂哇，Google colab为所有用户提供了一周30个小时免费时长高性能服务器。</p><p>首先打开<a href="https://colab.google/">Google colab</a>，点击左上角<code>New Notebook</code>。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306262012708.png-wm04#vwid=2140&vhei=855" src="https://image.manyacan.com/202306262012708.png-wm04#vwid=2140&vhei=855"></figure></p><p>之后就会进入一个在线版的<code>Jupyter Book</code>。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306262016947.png-wm04#vwid=3840&vhei=1934" src="https://image.manyacan.com/202306262016947.png-wm04#vwid=3840&vhei=1934"></figure></p><p>默认下是未开启GPU运算的，需要点击<code>修改</code>，然后点击<code>笔记本设置</code>。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202306262016404.png-wm04#vwid=1148&vhei=774" src="https://image.manyacan.com/202306262016404.png-wm04#vwid=1148&vhei=774"></figure></p><p>然后开启GPU加速即可。发现提供的硬件加速GPU是Tesla T4。</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202306262017201.png-wm04#vwid=948&vhei=555" src="https://image.manyacan.com/202306262017201.png-wm04#vwid=948&vhei=555"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202306262020491.png-wm04#vwid=1034&vhei=631" src="https://image.manyacan.com/202306262020491.png-wm04#vwid=1034&vhei=631"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202306262031733.png-wm04#vwid=1175&vhei=761" src="https://image.manyacan.com/202306262031733.png-wm04#vwid=1175&vhei=761"></figure></div><h2 id="toc_246">完整的模型训练套路</h2><h3 id="toc_247">文件的读取</h3><p>分别使用两张照片来测试模型效果：</p><div class="photos large"><figure><img class="" alt="dogs" data-src="https://image.manyacan.com/202306261708559.png-wm04#vwid=1260&vhei=963" src="https://image.manyacan.com/202306261708559.png-wm04#vwid=1260&vhei=963"><figcaption>dogs</figcaption></figure><figure><img class="" alt="plane" data-src="https://image.manyacan.com/202306261709345.png-wm04#vwid=1560&vhei=860" src="https://image.manyacan.com/202306261709345.png-wm04#vwid=1560&vhei=860"><figcaption>plane</figcaption></figure></div><pre><code class="lang-python">from PIL import Image

dog_img_path = './data/dog.png'
plane_img_path = './data/plane.png'

dog_img = Image.open(dog_img_path)
plane_img = Image.open(plane_img_path)
dog_img = dog_img.convert('RGB')
plane_img = plane_img.convert('RGB')
dog_img.show()
plane_img.show()</code></pre><p>PNG图片格式是4个通道，除了RGB三通道外，还有一个透明度通道。所以，我们调用<code>image = image.convert('RGB')</code>保留其颜色通道。当然，一如果图片本来就是三个颜色通道，经过此操作不变。</p><h3 id="toc_248">文件格式的转换</h3><p>读取的文件格式在输入模型前，需要根据模型的input要求进行变换：</p><pre><code class="lang-python">transformer = torchvision.transforms.Compose([
    torchvision.transforms.Resize((32, 32)),
    torchvision.transforms.ToTensor()
])

dog_img = transformer(dog_img)  # 改变图片尺寸大小
plane_img = transformer(plane_img)
plane_img.shape


dog_img = torch.reshape(dog_img, (1, 3, 32, 32))  # 将图片Tensor改变为模型input的要求
plane_img = torch.reshape(plane_img, (1, 3, 32, 32))  </code></pre><h3 id="toc_249">加载模型</h3><pre><code class="lang-python">model = torch.load('../14-ModifiedModule/SavedModule.pth')</code></pre><p>注意，在使用<code>torch.load()</code>读取训练好的模型之前，必须先导入模型的类！！！</p><p>还有个注意点，读取的模型之前是在GPU上训练好的，而现在想要传入模型的数据<code>image</code>则是在CPU中，如果直接传入模型进行训练，会报错：</p><blockquote><h3 id="toc_250">BUGS / 报错</h3><p>RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor.</p></blockquote><p>这个时候有两种解决方案：</p><ol><li>将模型读取到CPU中，在CPU中完成运算；</li><li>将想要传入模型的数据<code>image</code>转入到GPU中，在GPU中完成运算。</li></ol><p>第一张方法需要在读取模型时加入参数：</p><pre><code class="lang-python">model = torch.load('../15-CompleteTrainingProcess/module/module_19.pth', map_location=torch.device('cpu'))</code></pre><p>第二种方法：</p><pre><code class="lang-python">device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
image = image.to(device)</code></pre><h3 id="toc_251">测试数据并输出结果</h3><p>预测修🐕图像的结果为5，正确！</p><pre><code class="lang-python"># 测试模型效果
model.eval()
with torch.no_grad():
    output = model(dog_img)
    print(torch.argmax(output))   # 输出预测概率最大的target，tensor(5, device='cuda:0')</code></pre><p>预测✈的图像结果为0，正确！</p><pre><code class="lang-python"># 测试模型效果
model.eval()
with torch.no_grad():
    output = model(plane_img)
    print(torch.argmax(output))</code></pre><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202306261715416.png-wm04#vwid=1025&vhei=604" src="https://image.manyacan.com/202306261715416.png-wm04#vwid=1025&vhei=604"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202306261717509.png-wm04#vwid=1390&vhei=641" src="https://image.manyacan.com/202306261717509.png-wm04#vwid=1390&vhei=641"></figure></div><p>也不奇怪，之前所保存的模型经过50轮的学习后，在测试集上面的预测正确率已经可以达到80%以上。</p>
]]></content:encoded>
<slash:comments>3</slash:comments>
<comments>https://blog.manyacan.com/archives/2038/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2038/</wfw:commentRss>
</item>
<item>
<title>2023市政/环境工程博士申请记录</title>
<link>https://blog.manyacan.com/archives/2037/</link>
<guid>https://blog.manyacan.com/archives/2037/</guid>
<pubDate>Tue, 30 May 2023 16:57:00 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[🧪 引经过了很长时间的考虑，终于还是放弃了清华院的工作，决定继续读博深造。想要放弃一件事你会有成千上万个理由；而想要做一件事，只需要一个理由。结合我自己的申请经历，我觉得对于学生来讲最重要的有三...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<h2 id="toc_252">🧪 引</h2><p>经过了很长时间的考虑，终于还是放弃了清华院的工作，决定继续读博深造。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305071034926.jpg#vwid=873&vhei=140" src="https://image.manyacan.com/202305071034926.jpg#vwid=873&vhei=140"></figure></p><blockquote><p>想要放弃一件事你会有成千上万个理由；而想要做一件事，只需要一个理由。</p></blockquote><p>结合我自己的申请经历，我觉得对于学生来讲最重要的有三点：文章、学校以及个人能力，下面细展开说。</p><blockquote><p>因为是结合自己的经历来讲，因此本篇文章具有很大的主观性。</p></blockquote><h3 id="toc_253">文章</h3><p>文章就是申请博士的敲门砖，没有文章寸步难行。对于一个硕士研究生，对其科研能力进行评价最直接的指标就是文章。关于这个指标，申请博士一般没有具体的硬性要求，学校不会直接说必须有几篇SCI才可以报名。但是在材料初审阶段，却是把大家放在一起，进行比较，优胜略汰。</p><p>不同的学校、不同的专业，没有必要进行对比的必要。例如，四大天坑——生化环材的硕士研究生发表1~2篇SCI1区、2区的顶刊在双非学校也已经不是什么稀奇古怪的事。但是在土木等比较偏向于工程实践的专业或者是基础物理等纯理科的专业，能有一篇中文核心好像就挺厉害了。</p><p>因此，文章这个指标，最好就是和自己同专业的人比。简单来说，就看和你所在学校与申博院校中同专业学生们都发什么水平的文章，大概有几篇。通过这个对比，来判断自己是否站在了大多人的前列。</p><p>例如，我所联系的某位环境工程专业顶尖211的导师告诉我，如果想申请他们院的博士生，基本只有二区以上的文章在才有价值。</p><h3 id="toc_254">学校</h3><p>无可厚非，对于一个学生最直接的了解，就是其出身学校。但是值得庆幸的是大部分学校的报考条件并没有明确的限制。</p><p>学校只是当你文章不行时，导师觉得你下头的一个借口。</p><p>上面所说，大部分学校的报考条件是对学校没有限制的。但是近些年来，很多二本，甚至三本都有了硕士点，部分学校对于博士招生的报考条件也提出了一些限制。例如长安大学所发布的长大研〔2021〕196号文件中就注明了：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305071231086.png-wm04#vwid=931&vhei=402" src="https://image.manyacan.com/202305071231086.png-wm04#vwid=931&vhei=402"></figure></p><p>以申请考核制报考的考生其硕士所在学校必须具有硕士推荐免试资格。</p><p>合肥工业大学的申请考核制博士招生文件中也明确说明：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305071450714.png-wm04#vwid=1273&vhei=488" src="https://image.manyacan.com/202305071450714.png-wm04#vwid=1273&vhei=488"></figure></p><p>双非院校需要在全国学科评估排名中达到前25%。</p><h3 id="toc_255">个人能力</h3><p>个人能力并不是能否赢得博导青睐的关键因素，但是却是当你遇到同级别竞争对手时的加分项。“个人能力”是一个非常宽泛的名词，接下来我主要从以下几个方面来谈谈我的见解。</p><p>生而为人，<strong>做人的能力</strong>最为关键。不就是做人吗？都活了20多年了，谁还不会做人啊？为什么要把做人的能力放在第一个，因为我觉得“做人”这件事是伴随我们终生的学习计划。</p><p>读博是一个漫长且煎熬的过程，首先你要有<strong>抵抗压力的能力</strong>。有来自科研的🍐——一遍遍的实验却总是没有效果；有来自生活的🍐——同龄人都已成家立业，而你却还是个“穷学生”。</p><p>读博你接触的人会有很多，你要有<strong>社交的能力</strong>。在课题组中，如何维护同门师兄弟之间的关系；在家庭中，如何维护好家里人的关系；在恋人关系中，如何平衡恋爱与工作之间的关系；等等等~</p><p>读博最主要的搞研究，你要有<strong>学术的能力</strong>。阅读外文文献以及参加学术会议中，你的英语阅读和口语能力是否过硬；在进行实验数据分析以及图表绘制过程中，你是否可以熟练使用一些编程语言和绘图软件。</p><p>以上这些，通过一封Email是远远看不出来的，往往导师在觉得你的文章可以满足来他组的要求时，都会提前与你见上一面，而这个见面的主要目的，就是来看看你的个人能力是否达到他的标准。</p><blockquote><p>简单来说，文章只是你进入学校或者课题组的基本要求，而你所展现给导师或者面试老师的各方面综合能力，可以成为当你遇到同级别对手时的加分项。</p></blockquote><h3 id="toc_256">重点（必看）</h3><p>好了，上面说的其实都是从我们个人角度出发的一些主观因素。但现在申请博士的环境，异常恶劣，外部客观因素非常不友好。</p><p>首先就是现在读博的人太多，而一个博士生导师正常情况下每年只能招1~2个博士生，如果博导当年有学生延毕，好像还要扣除相应的名额。2020年以来，硕士招生规模大范围扩大，这也就导致分母不断增大，而分子却仅微量增加。</p><p>其次就是对于大部分博导都会优先考虑自己组内的硕转博，其次是考虑自己认识老师的学生（熟人推荐方式），最后才是那些发邮件当中比较优秀的。</p><p>对于这些现状，我们无法改变，只能从以下几点来争取：</p><ol><li>多发文章，增强自己的硬实力；</li><li>寻找博导一定要依靠自己身边的老师推荐，他们一句话，顶你努力几个月；</li><li>如果只能靠自己，那么一定是越早联系越好，尽量在研二结束的暑假就开始，不要害怕被拒绝，广撒网。</li></ol><blockquote><p>现在申请博士，最重要的不是你优秀不优秀，因为敢去申请博士的，肯定都是有点东西的。最关键的是你怎么竞争得过他人，让导师觉得你未来很有培养价值。</p></blockquote><p>接下里给大家分享下，我申请博士时了解的几个国内211，主要涉及到的专业是环境工程与市政工程。</p><h2 id="toc_257">🏫 河海大学</h2><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202302201247272.jpg-wm04#vwid=1080&vhei=597" src="https://image.manyacan.com/202302201247272.jpg-wm04#vwid=1080&vhei=597"></figure></p><h3 id="toc_258">🎤 学校专业简介</h3><h4 id="toc_259">🪠 市政工程</h4><p>2003年获<strong>硕士和博士学位授予权</strong>。该学科紧密围绕经济建设和社会发展中水污染控制和供水安全保障等问题，结合国家战略规划和学科发展方向，在饮用水安全保障理论与技术、城镇水系统优化理论与技术、污水处理及资源化利用理论与技术、城市与工业节水理论与技术等方面开展基础理论与应用技术研究。本学科的特色在于以城乡水系统良性循环为核心，围绕水的社会循环中供排水领域的关键科学问题和技术难题，并进行多学科高新技术交叉与联合攻关。通过学科交叉，在城镇饮用水安全保障理论与技术、污水处理及资源化利用理论与技术等方面产出了一批具有国内重要影响和应用价值的高水平研究成果，已成为在全国市政工程领域有重要影响的学科。</p><h4 id="toc_260">🏞️ 环境科学与工程</h4><p>1993年和1998年获得环境工程<strong>硕士和博士学位授予权</strong>，2000年获得博士后流动站和环境科学硕士授予权，2003年获得一级学科博士学位授予权。2017年入选<strong>首批国家“双一流”学科</strong>建设序列。该学科重点在水资源保护理论与水环境修复技术，环境与生态水力学及应用，流域水污染控制和水环境质量改善，固体废弃物处置与资源化技术，污水处理及废水回用技术等方面开展基础理论与应用技术研究。目前已形成以水资源保护与水环境修复等为鲜明特色的学科发展方向，通过学科交叉，凝练出一批具有国内外重要影响和重大应用价值的高水平研究成果，环境生态学ESI排名进入0.3%，已成为在全国环境领域有重要影响的学科。</p><h4 id="toc_261">🌊 生态水利</h4><p>生态水利隶属于环境科学与工程一级学科，河海大学生态水利专业是在“水文学与水资源学”国家重点学科和“环境科学与工程”国家一级学科的基础上，历经多年积累，于2002年经国家教育部批准建立成为<strong>博士、硕士学位授权点</strong>。</p><p>研究方向：</p><ol><li>生态水文学及生态水力学；</li><li>水生态环境保护与修复；</li><li>生态水利规划管理及工程生态效应；</li><li>水土资源利用与生态安全。</li></ol><h3 id="toc_262">🧑‍🏫 导师选择</h3><ul><li><a href="https://jszy.hhu.edu.cn/jsflcx/list.htm?keyword=&selectedCareers=&selectedDepartments=18&selectedletters=">环境学院</a>——环境科学与工程、市政工程</li><li><a href="https://jszy.hhu.edu.cn/jsflcx/list.htm?keyword=&selectedCareers=&selectedDepartments=18&selectedletters=">水文水资源学院</a>——城市水务、生态水利</li></ul><h3 id="toc_263">ℹ️ 公布信息</h3><ul><li>公布时间：2023-01-12，链接：<a href="https://gs.hhu.edu.cn/2023/0112/c17278a256211/page.htm">河海大学2023年博士研究生招生公告 （普通招考-“申请-考核”）</a>。</li><li>报名时间：2023年1月16日 上午9:00~2月15日 下午17:00。</li><li>报名考试费标准：120元/人。</li><li>报名网址：<a href="http://yzss.hhu.edu.cn/logon">http://yzss.hhu.edu.cn/logon</a></li></ul><h3 id="toc_264">📃 材料提交</h3><ol><li>《河海大学报考攻读博士学位研究生登记表》一份（网报成功后从博士报名网站下载打印），<strong>表中各处签名务必完整、真实、准确。</strong></li><li>本科和硕士阶段的课程学习成绩单（须学校教务部门盖章或档案管理部门盖章）、外语水平证明材料。</li><li>二代居民身份证复印件；往届生的硕士毕业证书、硕士学位证书复印件；应届生的学生证复印件（目前正在国（境）外学校就读的应届硕士研究生，还须提供国（境）外就读学校出具的学籍和成绩证明）；同等学力申请者的学士学位证书复印件；在国（境）外获得学历或学位的申请者，提交教育部留学服务中心出具的《国（境）外学历学位认证书》复印件。</li><li>攻读学术学位博士研究生科学研究设想（学术学位博士研究生申请者提交）或者攻读专业学位博士研究生计划书（专业学位博士研究生申请者提交）（从博士报名网站下载打印模板）。</li><li>从事相关学科或专业领域的研究成果（如已发表或录用的学术论文、发明专利、科研获奖等）；从事相关工程项目等的工程实践成果。</li><li>其他可以体现本人能力与水平的相关材料等（同等学力申请者还须按照申请条件中的要求提供相关材料）。</li><li>已获硕士学位的申请者须提供硕士学位论文（含评议书），应届硕士毕业生须提供硕士论文开题报告及论文进展情况。</li><li>两封由申请学科或专业有关领域内具有正高级职称专家亲笔签名的推荐书（从博士报名网站下载打印模板）。</li></ol><h3 id="toc_265">💯 复试备考</h3><p>考试科目：生态水文与水利工程生态环境效应综合</p><p>推荐书籍：</p><ol><li>《应用生态学》(张金屯)北京：科学出版社，2003年；</li><li>《生态水文学：过程，模型和实例——水资源可持续管理的方法》（David Harper）中国水利水电出版社，2012年；</li><li>董哲仁. 生态水利工程学[M]. 北京: 中国水利水电出版社, 2019.</li></ol><p>考试形式：复试为面试，满分100分，60分为合格，每生面试时间不少于30 分钟。主要考查考生综合运用所学知识能力、科研创新能力、对本学 科前沿领域及最新研究动态的掌握情况、外语水平及能力、培养潜能及素质等，同时还将考核考生的思想政治素质、道德品质、心理健康、 诚信及综合素质等方面。 每位申请人准备时长<strong>不超过15分钟英文PPT用英文介绍</strong>，内容包括个人学习简历、科研成果及未来研究计划等。</p><h2 id="toc_266">🏫 合肥工业大学</h2><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202302201246806.jpeg-wm04#vwid=1080&vhei=318" src="https://image.manyacan.com/202302201246806.jpeg-wm04#vwid=1080&vhei=318"></figure></p><h3 id="toc_267">🎤 学校专业简介</h3><h4 id="toc_268">🪠 市政工程</h4><p>2011年获得二级学科博士学位授权点，毫无疑问安徽省No.1，目前是安徽省唯一的市政工程博士点，主要研究方向：</p><ol><li>污（废）水处理与资源化理论与技术；</li><li>城镇饮用水水质安全保障；</li><li>城镇及矿山水资源系统工程；</li><li>固体废弃物减量、资源化与能源化。</li></ol><h4 id="toc_269">🏞️ 环境科学与工程</h4><p>环境科学与工程（一级学科）安徽省重点学科。 1989年开设环境工程专业，1997年获环境工程硕士学位授权，2000年获环境科学硕士学位授权，同年获得环境科学与工程一级硕士学位授权；2000年获得环境工程工程硕士学位授权领域，2018年获得环境科学与工程一级学科博士学位授权。</p><h3 id="toc_270">🧑‍🏫 导师选择</h3><ul><li><a href="http://civil.hfut.edu.cn/sz/list.htm">土木与水利工程学院</a>——市政工程</li><li><a href="http://geoscience.hfut.edu.cn/bssds/list.htm">资源与环境学院</a>——环境科学与工程</li></ul><h3 id="toc_271">ℹ️ 公布信息</h3><ul><li>公布时间：2022-11-30，链接：<a href="http://yjszs.hfut.edu.cn/2022/1130/c13536a287209/page.htm">合肥工业大学2023年博士研究生招生简章及目录</a>。</li><li>报名时间：2022年12月12日~2023年1月15日（网上报名时间），2023年3月1日前（申请材料邮寄截至时间）。</li><li>报名考试费标准：245元/人。</li><li>报名网址：<a href="http://yjszs.hfut.edu.cn">http://yjszs.hfut.edu.cn</a></li></ul><h3 id="toc_272">📃 材料提交</h3><ol><li>《申请攻读博士学位研究生登记表》（此表报名后由系统生成，考生自行下载并填写完整。）；</li><li>两名所申请学科相关领域专家推荐书（样式见附件2）；</li><li>申请人有效身份证复印件；</li><li>本科、硕士学历、学位证书（应届硕士毕业生提供硕士研究生学生证）复印件；</li><li>硕士学位课程学习成绩单，加盖管理部门公章；</li><li>发表论文、授权专利、获奖证书及其它原创性研究成果的证明材料复印件；</li><li>外语水平证明材料复印件；</li><li>非定向（全脱产）攻读博士研究生学位承诺书（样式见附件3）。</li></ol><h3 id="toc_273">💯 复试备考</h3><p>综合考核时间及方式将在公布资格审核通过名单时统一发布。</p><p>综合考核：  学院成立至少由5名专家组成的综合考核专家组，专家组由相关学科具有教授职称或相当专业技术职称以上人员组成。考核专家组对考生的思想政治素质和品德、学术水平、创新能力、科研潜质、合作精神、身体状况以及外语听、说、读能力等方面等进行综合考核。</p><ul><li><p>综合面试（满分100分）</p><ol><li>面试形式：由专家组对考生逐一考核。</li><li><p>面试内容：</p><ol><li>申请者介绍个人简历及已取得的科研成果；</li><li>专家组专家口头提问，考察其基础知识掌握、综合能力应用及表达交流能力。</li></ol></li></ol></li><li>综合考核成绩=综合面试成绩（满分100分）</li></ul><h2 id="toc_274">🏫 长安大学</h2><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202302201251825.jpg-wm04#vwid=1080&vhei=540" src="https://image.manyacan.com/202302201251825.jpg-wm04#vwid=1080&vhei=540"></figure></p><h3 id="toc_275">🎤 学校专业简介</h3><h4 id="toc_276">🏞️ 环境科学与工程</h4><p>2020年5月14日最新发布的ESI学科排名，我院负责建设的“环境/生态学”（Environment/Ecology）首次进入世界排名前1%。本学科立足西部与行业，始终瞄准国家需求和学科前沿，以培养生态环境治理与修复领域的高级人才为目标，积极推进学科内涵建设，力 通过十余年的努力，将学科打造为具有国际视野、特色鲜明、国内一流和国际上具有一定影响力的高水平学科。</p><p>研究方向：</p><ol><li>水污染治理与资源化；</li><li>大气污染控制；</li><li>旱区生态环境演化与调控；</li><li>土壤-地下水污染机理与修复；</li><li>环境监测、预警与风险管理。</li></ol><h4 id="toc_277">🪠 市政工程</h4><p>我院给排水科学与工程专业成立于1953年建立的陕西省建筑工程学校，是我国较早成立该专业的学校之一。陕西省建筑工程学校后更名为西安建筑工程学校，1978年高等教育改革后隶属于国家建设部，更名为西北建筑工程学院。1979年开始招收四年制本科“给水排水工程专业”；1984年开始招收首批硕士生；1999年给水排水实验室被建设部批准为“建设部重点实验室”；2003年获准“市政工程”硕士学位授权点；2005年获准“市政工程”博士学位授权点；2007年获准“土木工程”博士后科研流动站。2008年通过建设部高等教育给水排水工程专业评估。2010年获准国家第一批次卓越工程师计划培养专业，2012年给水排水工程专业卓越人才培养计划列入国家本科教学工程“专业综合改革试点”。</p><h3 id="toc_278">ℹ️ 公布信息</h3><ul><li>公布时间：2023-03-05，链接：<a href="https://yzb.chd.edu.cn/2023/0305/c2770a227283/page.htm">长安大学2023年学术学位博士研究生招生简章</a>。</li><li>报名时间：2023年03月20日~2023年04月05日。</li><li>报名考试费标准：245元/人。</li><li>报名网址：<a href="http://yz.chsi.com.cn/">中国研究生招生信息网</a></li></ul><h3 id="toc_279">🧑‍🏫 导师选择</h3><ul><li><a href="https://esec.chd.edu.cn/bdxx/list.htm">水利与环境学院</a>——环境科学与工程</li><li><a href="https://jzgc.chd.edu.cn/7134/list.htm">建筑工程学院</a>——市政工程</li></ul><h3 id="toc_280">📃 材料提交</h3><p>长安大学的复试资料提交太离谱了，从正式公布到报名截止只有两天的时间。而且材料上要求需要盖的公章特别多。学校的公章，在一些学校想要申请是十分麻烦的。比如在我的学校，需要你的导师提出申请，然后经过学院领导以及学校领导的一步步审批通过之后才可以预约过去盖章。学校的办事效率都懂吧？两天时间太紧了。</p><h3 id="toc_281">💯 复试备考</h3><ol><li>环境工程学：《环境工程学》（第二版）高等教育出版社 蒋展鹏  2011</li><li>现代环境科学：《现代环境科学概论》 科学出版社 周培疆 2010</li></ol>
]]></content:encoded>
<slash:comments>0</slash:comments>
<comments>https://blog.manyacan.com/archives/2037/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2037/</wfw:commentRss>
</item>
<item>
<title>「Machine Learning」梯度下降</title>
<link>https://blog.manyacan.com/archives/2036/</link>
<guid>https://blog.manyacan.com/archives/2036/</guid>
<pubDate>Mon, 22 May 2023 15:52:00 +0800</pubDate>
<dc:creator>Yacan Man</dc:creator>
<description><![CDATA[一、什么是梯度下降？1.1 口语化描述一个风和日丽的周末，你成功登顶了泰山之巅，然而此时的喜悦还未尽兴。你却突然感觉肚子一阵隐痛，大事不妙💩。然后，坏消息是最近的厕所也在山下。这个时候你会绞尽脑...]]></description>
<content:encoded xml:lang="zh-CN"><![CDATA[
<h2 id="toc_282">一、什么是梯度下降？</h2><h3 id="toc_283">1.1 口语化描述</h3><p>一个风和日丽的周末，你成功登顶了泰山之巅，然而此时的喜悦还未尽兴。你却突然感觉肚子一阵隐痛，大事不妙💩。然后，坏消息是最近的厕所也在山下。</p><p>这个时候你会绞尽脑汁🤔去想，我如何才能找到一条最快的下山路径呢？</p><p>梯度下降——就是你此时此刻的救星。当你想要尽快下山，在不考虑你人体功能限制的情况下，肯定是沿着最陡峭的路下山最快。然而事实情况是，山上怪石嶙峋，并不是沿着一条直线就可以直接下山。你需要每走一步就判断下，以当前位置来看，哪条路最陡峭（下山最快）。</p><p>于是乎，就这样你决定走一步算一步，也就是每走到一个位置时，就站在这里稍微停顿一会儿，看接下来最陡峭的一条路该怎么走，……</p><p>就这样，你以最快的速度下了山，解决了燃眉之急😊。</p><p>这个每走一步就不断寻找最陡峭路径下山的过程，就是梯度下降。</p><p>下面来看看梯度下降更加正规的表达吧~</p><h3 id="toc_284">1.2 介绍</h3><p>梯度下降法（Gradient Descent）并不是一个机器学习的算法，而是一种基于搜索的最优化方法。其作用就是可以用来最小化一个损失函数。与之相对应的还有一个叫做梯度上升法，其作用是用来最大化一个效用函数。</p><p>梯度下降其基本思想在于不断地逼近最优点，每一步的优化方向就是<strong>梯度的负方向</strong>。相反，梯度上升法中，进行优化的方向应该为梯度的方向。</p><p>梯度的本意是一个向量（矢量），表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此梯度的方向）变化最快，变化率最大（为该梯度的模）。</p><p><strong>在单变量的实值函数中，梯度可简单理解为只是导数</strong>，或者说对于一个线性函数而言，<strong>梯度就是曲线在某点的斜率</strong>。对于函数的某个特定点，它的梯度就表示从该点出发，函数值增长最为迅猛的方向（direction of greatest increase of a function）。</p><p>在一个开口向下的一元二次函数图像中，最低点左侧导数小于0，“下山”方向（$\theta - \eta \frac{d J}{d \theta}$）应该是沿$\theta$轴向右➡️（即$\theta$增大方向）；而在最低点右侧导数大于0，“下山”方向应该是沿$\theta$轴向左⬅️（即$\theta$减小方向）。</p><div class="photos large"><figure><img class="" alt="" data-src="https://image.manyacan.com/202305211553051.png#vwid=939&vhei=488" src="https://image.manyacan.com/202305211553051.png#vwid=939&vhei=488"></figure><figure><img class="" alt="" data-src="https://image.manyacan.com/202305211553319.png#vwid=951&vhei=528" src="https://image.manyacan.com/202305211553319.png#vwid=951&vhei=528"></figure></div><blockquote><p>求解当前位置的梯度，沿着梯度的负方向，也就是当前<strong>最陡峭的位置</strong>向下走，这样一直走下去。如果你每走一步，就计算一下当前位置的梯度（即当前这个位置最陡峭的方向），那么你所走过的路径将是下山最快的一条。</p></blockquote><h3 id="toc_285">1.3 学习率</h3><p>$-\eta \frac{d J}{d \theta}$中关于参数$\eta$的一些概念：</p><ul><li>$\eta$称为学习率（Learning Rate）；</li><li>$\eta$的取值影响获得最优解的速度；</li><li>$\eta$取值不合适，甚至得不到最优解；</li><li>$\eta$是梯度下降法的一个超参数。</li></ul><p>显而易见，参数$\eta$就是用来调节梯度（导数的），作为梯度下降的重要超参数，其有着重要的作用。可能遇到$\eta$太小或者太大的问题。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305211833927.png-wm04#vwid=1595&vhei=1583" src="https://image.manyacan.com/202305211833927.png-wm04#vwid=1595&vhei=1583"></figure></p><p>上面的四个图像， 我们分别设置学习率为<code>eta_list = [0.01, 0.1, 0.8, 1.1]</code>，可以发现，当<code>eta=0.01</code>时，有点过小，导致“下山”过程中，“步长”太短，需要走很多步才可以下山；当<code>eta=0.1</code>时，“步长”非常合适；当<code>eta=0.8</code>时，“步长”太大，导致一步直接又“上山”了，不过幸好还是又下来了；当<code>eta=1.8</code>时，“步长”巨大，导致“下山”过程不收敛，反而越下越高了。</p><h3 id="toc_286">1.4 局部最优解与全局最优解</h3><p>并不是所有函数都有唯一的极值点：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305211601093.png#vwid=910&vhei=429" src="https://image.manyacan.com/202305211601093.png#vwid=910&vhei=429"></figure></p><p>解决方案：</p><ul><li>多次运行，随机化初始点；</li><li>梯度下降法的初始点也是一个超参数。</li></ul><p>$$
\sum_{i=1}^{m}(y^{(i)} - \hat y^{(i)})^2
$$</p><blockquote><p>线性回归法的损失函数是一个开口向下的二次函数，具有唯一的最优解。</p></blockquote><h3 id="toc_287">1.5 梯度下降的数学概念</h3><p>对于单变量连续函数$y=f(x)$而言，其导数定义为：</p><p>$$
f^{\prime}\left( x \right) =\lim_{\varDelta x\rightarrow 0} \frac{f\left( x+\varDelta x \right) -f\left( x \right)}{\varDelta x}
$$</p><p>这个导数的定义也有另一层含义，如果$x$作微小的$\varDelta x$变化，那么$y$会如何变化呢？</p><p>$$
y=f\left( x+\varDelta x \right) \fallingdotseq f\left( x \right) +\varDelta x\cdot f^{\prime}\left( x \right)
$$</p><p>将上式推广到三位空间就是：</p><p>$$
z\left( x, y \right) =f\left( x+\varDelta x, y+\varDelta y \right) \fallingdotseq f\left( x, y \right) +\varDelta x\cdot \frac{\partial f\left( x, y \right)}{\partial x}+\varDelta y\cdot \frac{\partial f\left( x, y \right)}{\partial y}
$$</p><p>所以说，此时在三维空间中的微小变化$\varDelta z$就可以表示为：</p><p>$$
\begin{equation*}
\begin{split}

\varDelta z&amp;=f\left( x+\varDelta x, y+\varDelta y \right) -f\left( x, y \right) 
\\
&amp;\fallingdotseq \varDelta x\cdot \frac{\partial f\left( x, y \right)}{\partial x}+\varDelta y\cdot \frac{\partial f\left( x, y \right)}{\partial y}
\\
&amp;=\left[ \varDelta x, \varDelta y \right] \cdot \left[ \frac{\partial f\left( x, y \right)}{\partial x}, \frac{\partial f\left( x, y \right)}{\partial y} \right]

\end{split}
\end{equation*}
$$</p><p>经过这样的等式变化，可以发现$\varDelta z$其实就是$\left[ \varDelta x, \varDelta y \right]$与$\left[ \frac{\partial f\left( x, y \right)}{\partial x}, \frac{\partial f\left( x, y \right)}{\partial y} \right]$两个向量的内积。</p><p>而$\left[ \frac{\partial f\left( x, y \right)}{\partial x}, \frac{\partial f\left( x, y \right)}{\partial y} \right]$被称为函数$f(x, y)$在点$(x, y)$处的梯度。</p><p>由向量内积的定义可以知道，对于两个向量$a$、$b$：</p><p>$$
a\cdot b=\left| a \right|\left| b \right|\cos \theta
$$</p><p>当两者的夹角$\theta=0\degree$时，内积取得最大值（即$a$、$b$同向）；两者的夹角$\theta=180\degree$时，内积取得最小值（即$a$、$b$反向）。</p><p>所以说，如果我们的上山路径$\left[ \varDelta x, \varDelta y \right]$如果与梯度$\left[ \frac{\partial f\left( x, y \right)}{\partial x}, \frac{\partial f\left( x, y \right)}{\partial y} \right]$的方向一致，我们走的距离$\varDelta z$才会最大；如果我们下山，需要保证$\left[ \varDelta x, \varDelta y \right]$与梯度的负方向$-\left[ \frac{\partial f\left( x, y \right)}{\partial x}, \frac{\partial f\left( x, y \right)}{\partial y} \right]$一致，才可以最短距离下山。</p><p><figure><img class="" alt="某二元函数及其梯度场" data-src="https://image.manyacan.com/202306271927431.png-wm04#vwid=928&vhei=470" src="https://image.manyacan.com/202306271927431.png-wm04#vwid=928&vhei=470"><figcaption>某二元函数及其梯度场</figcaption></figure></p><h3 id="toc_288">1.6 实例：使用Excel计算梯度下降</h3><p>以$z=x^2+y^2$为例，该函数是一个开口向上的抛物线曲面，最低点显然在$(x,y)=(0,0)$处，设学习率$\eta =0.1$、起始点$(x,y)=(3,2)$（这个点是随机定的）开始进行计算：</p><table><thead><tr><th>$i$</th><th>$x_i$</th><th>$y_i$</th><th>$\frac{\partial z}{\partial x}=2x$</th><th>$\frac{\partial z}{\partial y}=2y$</th><th>$\varDelta x$</th><th>$\varDelta y$</th><th>$z$</th><th>$\varDelta x\frac{\partial z}{\partial x}+\varDelta y\frac{\partial z}{\partial y}$</th><th>$f\left( x+\varDelta x, y+\varDelta y \right) -f\left( x \right) $</th><th> </th></tr></thead><tbody><tr><td>0</td><td>3.00</td><td>2.00</td><td>6.00</td><td>4.00</td><td>-0.60</td><td>-0.40</td><td>13.00</td><td>-5.20</td><td>-4.68</td><td>-0.52</td></tr><tr><td>1</td><td>2.40</td><td>1.60</td><td>4.80</td><td>3.20</td><td>-0.48</td><td>-0.32</td><td>8.32</td><td>-3.33</td><td>-3.00</td><td>-0.33</td></tr><tr><td>2</td><td>1.92</td><td>1.28</td><td>3.84</td><td>2.56</td><td>-0.38</td><td>-0.26</td><td>5.32</td><td>-2.13</td><td>-1.92</td><td>-0.21</td></tr><tr><td>3</td><td>1.54</td><td>1.02</td><td>3.07</td><td>2.05</td><td>-0.31</td><td>-0.20</td><td>3.41</td><td>-1.36</td><td>-1.23</td><td>-0.14</td></tr><tr><td>4</td><td>1.23</td><td>0.82</td><td>2.46</td><td>1.64</td><td>-0.25</td><td>-0.16</td><td>2.18</td><td>-0.87</td><td>-0.79</td><td>-0.09</td></tr><tr><td>5</td><td>0.98</td><td>0.66</td><td>1.97</td><td>1.31</td><td>-0.20</td><td>-0.13</td><td>1.40</td><td>-0.56</td><td>-0.50</td><td>-0.06</td></tr><tr><td>6</td><td>0.79</td><td>0.52</td><td>1.57</td><td>1.05</td><td>-0.16</td><td>-0.10</td><td>0.89</td><td>-0.36</td><td>-0.32</td><td>-0.04</td></tr><tr><td>7</td><td>0.63</td><td>0.42</td><td>1.26</td><td>0.84</td><td>-0.13</td><td>-0.08</td><td>0.57</td><td>-0.23</td><td>-0.21</td><td>-0.02</td></tr><tr><td>8</td><td>0.50</td><td>0.34</td><td>1.01</td><td>0.67</td><td>-0.10</td><td>-0.07</td><td>0.37</td><td>-0.15</td><td>-0.13</td><td>-0.01</td></tr><tr><td>9</td><td>0.40</td><td>0.27</td><td>0.81</td><td>0.54</td><td>-0.08</td><td>-0.05</td><td>0.23</td><td>-0.09</td><td>-0.08</td><td>-0.01</td></tr><tr><td>10</td><td>0.32</td><td>0.21</td><td>0.64</td><td>0.43</td><td>-0.06</td><td>-0.04</td><td>0.15</td><td>-0.06</td><td>-0.05</td><td>-0.01</td></tr><tr><td>11</td><td>0.26</td><td>0.17</td><td>0.52</td><td>0.34</td><td>-0.05</td><td>-0.03</td><td>0.10</td><td>-0.04</td><td>-0.03</td><td>0.00</td></tr><tr><td>12</td><td>0.21</td><td>0.14</td><td>0.41</td><td>0.27</td><td>-0.04</td><td>-0.03</td><td>0.06</td><td>-0.02</td><td>-0.02</td><td>0.00</td></tr><tr><td>13</td><td>0.16</td><td>0.11</td><td>0.33</td><td>0.22</td><td>-0.03</td><td>-0.02</td><td>0.04</td><td>-0.02</td><td>-0.01</td><td>0.00</td></tr><tr><td>14</td><td>0.13</td><td>0.09</td><td>0.26</td><td>0.18</td><td>-0.03</td><td>-0.02</td><td>0.03</td><td>-0.01</td><td>-0.01</td><td>0.00</td></tr><tr><td>15</td><td>0.11</td><td>0.07</td><td>0.21</td><td>0.14</td><td>-0.02</td><td>-0.01</td><td>0.02</td><td>-0.01</td><td>-0.01</td><td>0.00</td></tr><tr><td>16</td><td>0.08</td><td>0.06</td><td>0.17</td><td>0.11</td><td>-0.02</td><td>-0.01</td><td>0.01</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>17</td><td>0.07</td><td>0.05</td><td>0.14</td><td>0.09</td><td>-0.01</td><td>-0.01</td><td>0.01</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>18</td><td>0.05</td><td>0.04</td><td>0.11</td><td>0.07</td><td>-0.01</td><td>-0.01</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>19</td><td>0.04</td><td>0.03</td><td>0.09</td><td>0.06</td><td>-0.01</td><td>-0.01</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>20</td><td>0.03</td><td>0.02</td><td>0.07</td><td>0.05</td><td>-0.01</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>21</td><td>0.03</td><td>0.02</td><td>0.06</td><td>0.04</td><td>-0.01</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>22</td><td>0.02</td><td>0.01</td><td>0.04</td><td>0.03</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>23</td><td>0.02</td><td>0.01</td><td>0.04</td><td>0.02</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>24</td><td>0.01</td><td>0.01</td><td>0.03</td><td>0.02</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>25</td><td>0.01</td><td>0.01</td><td>0.02</td><td>0.02</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>26</td><td>0.01</td><td>0.01</td><td>0.02</td><td>0.01</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>27</td><td>0.01</td><td>0.00</td><td>0.01</td><td>0.01</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>28</td><td>0.01</td><td>0.00</td><td>0.01</td><td>0.01</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>29</td><td>0.00</td><td>0.00</td><td>0.01</td><td>0.01</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr><tr><td>30</td><td>0.00</td><td>0.00</td><td>0.01</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr></tbody></table><p>以第一次计算为例：$(x,y)=(3,2)$，此时梯度为：</p><p>$$
\left[ \frac{\partial z}{\partial x}, \frac{\partial z}{\partial y} \right] =\left[ 2x, 2y \right] =\left[ 2\times 3, 2\times 2 \right] =\left[ 6, 4 \right] 
$$</p><p>所以说此时的“下山步长”为：</p><p>$$
-\eta \left[ \frac{\partial z}{\partial x}, \frac{\partial z}{\partial y} \right] =\left[ -0.6, -0.4 \right]
$$</p><p>“下一步落脚点”的坐标为：</p><p>$$
\left[ x_i, y_i \right] -\eta \left[ \frac{\partial z}{\partial x}, \frac{\partial z}{\partial y} \right] =\left[ 3, 2 \right] -0.1\times \left[ 6, 4 \right] =\left[ 2.4, 1.6 \right] 
$$</p><p>由计算过程我们也可以看出：</p><p>$$
\varDelta x\frac{\partial z}{\partial x}+\varDelta y\frac{\partial z}{\partial y} \fallingdotseq f\left( x+\varDelta x, y+\varDelta y \right) -f\left( x \right)
$$</p><p>两者之间并不是完全相等的，但是随着“逐渐靠近山下”，两者之间的差（最后一列）会越来越小，直到相等。</p><h2 id="toc_289">二、实现一个最简单的梯度下降示例</h2><p>这里我们使用一个一元二次函数：</p><p>$$
f(x)=(x-2.5)^2-1
$$</p><p>来可视化梯度下降求其最小值的过程。</p><p>定义函数：</p><pre><code class="lang-python">from sympy.abc import x
from sympy import lambdify, diff

# Define function
f_x = (x - 2.5) ** 2 - 1
# Calculate f(x)
f_x_fcn = lambdify(x, f_x)

# Calculate f'(x)
f_x_1_diff = diff(f_x, x)
f_x_1_diff_fcn = lambdify(x, f_x_1_diff)

x_arr = np.linspace(-1, 6, 200)
y_arr = f_x_fcn(x_arr)</code></pre><p>这里我们使用了<code>sympy.lambdify()</code>创建了函数$f(x)$，然后使用<code>sympy.diff()</code>求出其关于<code>x</code>的导数。</p><p>由二元一次函数的性质可以求出，$f(x)$的最低点应该是出现在$x=2.5$处，而$f(2.5)=-1$ 。计算最值点：</p><pre><code class="lang-python">lowest_point_x = 2.5
lowest_point_y = f_x_fcn(lowest_point_x)
(lowest_point_x, lowest_point_y)</code></pre><p>绘图观察其图像：</p><pre><code class="lang-python"># Plot image and data visualization
plot_x_min, plot_x_max, plot_y_min, plot_y_max = x_arr.min() - 1, x_arr.max() + 1, y_arr.min() - 1, y_arr.max() + 1
plt.plot(x_arr, y_arr)
plt.hlines(lowest_point_y, plot_x_min, lowest_point_x, 'r', '--')
plt.vlines(lowest_point_x, plot_y_min, lowest_point_y, 'r', '--')
plt.xlim(plot_x_min, plot_x_max)
plt.ylim(plot_y_min, plot_y_max)
plt.text(lowest_point_x, lowest_point_y+2, f'$x={lowest_point_x},f({lowest_point_x})={lowest_point_y}$', horizontalalignment ='center')
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305221620829.png-wm04#vwid=912&vhei=657" src="https://image.manyacan.com/202305221620829.png-wm04#vwid=912&vhei=657"></figure></p><p>梯度下降求最小值：</p><table><thead><tr><th align="center">参数</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center"><code>learn_rate</code></td><td align="center">学习率，调节步长</td></tr><tr><td align="center"><code>_theta</code></td><td align="center">初始位置，开始“下山”的地方</td></tr><tr><td align="center"><code>epsilon</code></td><td align="center">迭代终止条件：当上一步与这一步相比，走的距离小于这个值时，就说明已经到达山底了</td></tr><tr><td align="center"><code>theta_history</code></td><td align="center">存放“下山”过程每一步的位置</td></tr><tr><td align="center"><code>i</code></td><td align="center">计数器，看看走几步才可以下山</td></tr></tbody></table><pre><code class="lang-python">learn_rate, _theta, epsilon = 0.1, 0, 1e-8  
theta_history = []
i = 0  # Counter
while True:
    i += 1
    gradient = f_x_diff_fcn(_theta)
    last_theta = _theta
    theta_history.append(last_theta)
    _theta = _theta - learn_rate * gradient

    if abs(f_x_fcn(last_theta) - f_x_fcn(_theta)) &lt; epsilon:
        hues.success(f'theta is {_theta}, f(x) = {f_x_fcn(_theta)}, the counter is {i}.')
        break

# Plot image and data visualization
plt.plot(x_arr, y_arr)
plt.scatter(theta_history, f_x_fcn(np.array(theta_history)), s=100, color='r', marker='+')
plt.show()</code></pre><blockquote><p>10:36:09 - SUCCESS - theta is 2.499891109642585, f(x) = -0.99999998814289, the counter is 45.</p></blockquote><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305221037405.png-watermark01#vwid=541&vhei=413" src="https://image.manyacan.com/202305221037405.png-watermark01#vwid=541&vhei=413"></figure></p><p>由上面的迭代过程可以看出，当设置学习率<code>learn_rate=0.1</code>、初始点为<code>_theta=0</code>、迭代终止条件<code>epsilon=1e-8</code>时，经过45次迭代，找到了最小值点<code>2.499891109642585</code>，其对应的函数值为<code>-0.99999998814289</code>。</p><p>当我们分别设置学习率为<code>eta_list = [0.01, 0.1, 0.8, 1.1]</code>时，对应的迭代次数分别为：</p><table><thead><tr><th align="center">学习率</th><th align="center">迭代次数</th></tr></thead><tbody><tr><td align="center">0.01</td><td align="center">423</td></tr><tr><td align="center">0.1</td><td align="center">45</td></tr><tr><td align="center">0.8</td><td align="center">21</td></tr><tr><td align="center">1.1</td><td align="center"><strong>OverflowError</strong></td></tr></tbody></table><p>由此可见，设置一个正确的学习率，对于梯度下降过程的执行效率有着至关重要的作用。</p><h2 id="toc_290">三、二元函数的梯度下降</h2><p>看懂了上面简单的一元函数梯度下降，再来一个复杂点的二元函数：</p><p>$$
z=f(x, y) =x - y + 2 x^2 + 2xy + y^2
$$</p><p>来看看。与一元函数相比，二元函数使用梯度下降求解极小值的过程才更像“走最陡峭的路下山”过程。</p><p>首先来定义下函数，并创造出数据：</p><pre><code class="lang-python">from sympy import lambdify, diff
from sympy.abc import x, y
import numpy as np
from matplotlib import pyplot as plt
import hues

num = 400;  # number of mesh grids
x_array = np.linspace(-4, 4, num)
y_array = np.linspace(-4, 4, num)
xx, yy = np.meshgrid(x_array, y_array)

# 定义函数
f_xy = x - y + 2 * x * x + 2 * x * y + y * y
f_xy_fcn = lambdify([x, y], f_xy)
# 计算网格
f_xy_zz = f_xy_fcn(xx, yy)</code></pre><p>然后绘制出图像来看下，看看曲面是什么样子的：</p><pre><code class="lang-python">plt.figure()
ax = plt.axes(projection=&quot;3d&quot;)
ax.patch.set_facecolor(&quot;white&quot;)  #设置 axes 背景颜色
ax.plot_surface(xx, yy, f_xy_zz, alpha=0.9, cmap=plt.cm.jet)
ax.set_xlabel(&quot;x&quot;)
ax.set_ylabel(&quot;y&quot;)
ax.set_zlabel(&quot;$z=f(x, y) =x - y + 2 x^2 + 2xy + y^2$&quot;)
ax.view_init(elev=30, azim=70)
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305221330902.png-wm04#vwid=820&vhei=626" src="https://image.manyacan.com/202305221330902.png-wm04#vwid=820&vhei=626"></figure></p><p>由图中可以看出来，$z=f(x, y)$近似在$(x, y)=(4, 4)$以及$(x, y)=(-4, -4)$位置取得极大值（“山”的最高点），而在$(x, y)=(4, -4)$到$(x, y)=(-4, 4)$的“山谷”中取得极小值，即这里是山底。既然这个曲线肯定是有极小值的。也就是说，使用梯度下降的方法一定是可以找到最优解的。</p><p>接下来就可以愉快地进行梯度下降吧~</p><p>首先求出$z=f(x, y)$关于$x$和$y$的偏导数，对于一个一元函数，梯度就是其导数，而对于一个二元或者多元函数，梯度就是其各个自变量的偏导数。</p><p>$$
gradf(x, y)=\nabla f(x,y) = \{\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}\}
$$</p><pre><code class="lang-python"># partial derivative with respect to x
df_dx = f_xy.diff(x)
df_dx_fcn = lambdify([x, y], df_dx)

# partial derivative with respect to y
df_dy = f_xy.diff(y)
df_dy_fcn = lambdify([x, y], df_dy)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305221335471.png-wm04#vwid=945&vhei=427" src="https://image.manyacan.com/202305221335471.png-wm04#vwid=945&vhei=427"></figure></p><p>定义了偏导数之后，就可以开始下山过程——梯度下降了🥰：</p><pre><code class="lang-python">#梯度下降
learn_rate, epsilon = 0.05, 7e-9  # 学习率与迭代终止条件
start_x, start_y = -4, -4  # 开始迭代点
descent_point = [(start_x, start_y, f_xy_fcn(start_x, start_y))]  # 记录下山的每一步

i = 1 # Counter
while True:
    x, y = descent_point[-1][0], descent_point[-1][1]  # 取出“这一步”的x，y
    new_x = x - learn_rate * df_dx_fcn(x, y)  # 根据偏导数计算“下一步”
    new_y = y - learn_rate * df_dy_fcn(x, y)
    
    # 记录“下一步”的数据
    descent_point.append((new_x, new_y, f_xy_fcn(new_x, new_y)))

    if f_xy_fcn(x, y) - f_xy_fcn(new_x, new_y) &lt; epsilon:  # 迭代终止条件
        hues.success(f'The counter is {i}, the last descent_point is {descent_point[-1]}.')
        break

    i += 1</code></pre><blockquote><p>输出：13:38:48 - SUCCESS - The counter is 226, the last descent_point is (-0.9997546279984584, 1.4996029797616182, -1.2499999167953932).</p><p>说明下山一共走了226步，山的最低点为(-0.9997546279984584, 1.4996029797616182, -1.2499999167953932)。</p></blockquote><p>取出下山过程中，每一步所处位置的x、y、z坐标值：</p><pre><code class="lang-python">descent_point_x = [i[0] for i in descent_point]
descent_point_y = [i[1] for i in descent_point]
descent_point_z = [i[2] for i in descent_point]</code></pre><p>绘制出下山每一步的点：</p><pre><code class="lang-python">plt.figure()
ax = plt.axes(projection=&quot;3d&quot;)
ax.patch.set_facecolor(&quot;white&quot;)  #设置 axes 背景颜色
ax.plot_surface(xx, yy, f_xy_zz, alpha=0.3, cmap=plt.cm.jet)
ax.set_xlabel(&quot;X&quot;)
ax.set_ylabel(&quot;Y&quot;)
ax.set_zlabel(&quot;Z&quot;)
ax.view_init(elev=30, azim=70)
ax.plot(descent_point_x, descent_point_y, descent_point_z, 'r.')
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305221344704.png-wm04#vwid=786&vhei=633" src="https://image.manyacan.com/202305221344704.png-wm04#vwid=786&vhei=633"></figure></p><p>也可以在二维平面上观察下：</p><pre><code class="lang-python"># 创建画布
fig, ax = plt.subplots()

# 绘制函数f(x, y)的热图
colorbar = ax.contourf(xx, yy, f_xy_zz, 20, cmap='RdYlBu_r')
fig.colorbar(colorbar, fraction=0.046, pad=0.17, label=f'$z=f(x, y) =x - y + 2 x^2 + 2xy + y^2$',
             orientation='horizontal')

# 绘制出函数f(x, y)的最低点+0.1的区域
ax.contour(xx, yy, f_xy_zz, levels=[np.min(f_xy_zz) + 0.1],
           colors='red',
           linestyles='-')

# 设置x、y轴限制
ax.set_xlim(xx.min(), xx.max())
ax.set_ylim(yy.min(), yy.max())
# 轴名称
ax.set_xlabel('x')
ax.set_ylabel('y')
# x、y轴等间距
plt.gca().set_aspect('equal', adjustable='box')
# 绘制图形
ax.plot(descent_point_x, descent_point_y, descent_point_z, 'r.')
plt.show()</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305221346369.png-wm04#vwid=1118&vhei=919" src="https://image.manyacan.com/202305221346369.png-wm04#vwid=1118&vhei=919"></figure></p><h2 id="toc_291">四、使用梯度下降求解线性回归问题</h2><p>首先来创建一组数据：</p><pre><code class="lang-python">import numpy as np
from matplotlib import pyplot as plt

np.random.seed(666)
x = 2 * np.random.random(size=100)
X = x.reshape(-1, 1)

y = x * 3 + 4 + np.random.normal(size=100)

X.shape, y.shape</code></pre><p><code>X</code>为一个<code>100×1</code>的特征矩阵，<code>y</code>为标签值，对应有100个。且两者之间“大概”存在为：</p><p>$$
y=3x+4
$$</p><p>的关系。</p><p>绘制出图形观察下：</p><pre><code class="lang-python">plt.scatter(X, y)</code></pre><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305221401839.png-wm04#vwid=896&vhei=665" src="https://image.manyacan.com/202305221401839.png-wm04#vwid=896&vhei=665"></figure></p><p>线性回归问题，本质上是求损失函数：</p><p>$$
\begin{equation*}
\begin{split}
J &amp;= \frac{1}{2m}\sum_{i=1}^{m} (y^{(i)} - \hat y ^{(i)})^2 \\

&amp;= \frac{1}{2m}\sum_{i=1}^{m}\left(y^{(i)}-\theta_{0}-\theta_{1} X_{1}^{(i)}-\theta_{2} X_{2}^{(i)}-\ldots-\theta_{n} X_{n}^{(i)}\right)^{2}

\end{split}
\end{equation*}
$$</p><p>令$X_0$为全为1的列向量：</p><blockquote><p>特征矩阵$X$为$m×n$，则$y$为$m×1$，$X_0$为$m×1$。将$X_0$放置到$X$最左侧“组装”成$X_b$为$m×(n+1)$。$\theta$为$n×1$，将$\theta_{0}$补充到$\theta$的第一位，那么新的$\theta$为$(n+1)×1$。</p></blockquote><p>$$
\begin{equation*}
\begin{split}
J &amp;= \frac{1}{2m}\sum_{i=1}^{m}\left(y^{(i)}-\theta_{0}X_0^{(i)}-\theta_{1} X_{1}^{(i)}-\theta_{2} X_{2}^{(i)}-\ldots-\theta_{n} X_{n}^{(i)}\right)^{2} \\

&amp;= \frac{1}{2m}\sum_{i=1}^{m}\left(y^{(i)}-\theta_{0}X_0^{(i)}-\theta_{1} X_{1}^{(i)}-\theta_{2} X_{2}^{(i)}-\ldots-\theta_{n} X_{n}^{(i)}\right)^{2} \\

&amp;= \frac{1}{2m}(y-X_b\theta)^2
\end{split}
\end{equation*}
$$</p><p>达到最小值时所对应的最优解。这个时候我们就可以来定义损失函数了：</p><pre><code class="lang-python">def loss_fun(theta, X_b, y):
    try:
        return np.sum((y - X_b.dot(theta) ** 2)) / len(X_b)
    except:
        hues.error('The return value is to large!!!')
        return np.inf</code></pre><p>对于一个多元函数，这个时候的梯度变成了：</p><p>$$
\nabla J = \begin{bmatrix}
 \frac{\partial J}{\partial \theta_0}\\
 \frac{\partial J}{\partial \theta_1}\\
 \dots\\
 \frac{\partial J}{\partial \theta_n}
\end{bmatrix} = \frac{2}{m}
\begin{bmatrix}
 \sum_{i=1}^{m} (X_b^{(i)}\theta - \hat y ^{(i)})\\
 \sum_{i=1}^{m} (X_b^{(i)}\theta - \hat y ^{(i)})X_1^{(i)}\\
 \dots\\
 \sum_{i=1}^{m} (X_b^{(i)}\theta - \hat y ^{(i)})X_n^{(i)}
\end{bmatrix}
$$</p><p>所以求导函数可以定义为：</p><pre><code class="lang-python">def get_der(theta, X_b, y):
    res = np.empty(len(theta))
    res[0] = np.sum(X_b.dot(theta) - y)
    for i in range(1, len(theta)):
        res[i] = (X_b.dot(theta) - y).dot(X_b[:, i])

    return res * 2 / len(X_b)</code></pre><p>然后就可以封装一个求梯度的函数：</p><pre><code class="lang-python">theta_history = []
def gradient_descent(X_b, y, ini_theta, eta, n_iters=1e4, eps=1e-8):
    theta = ini_theta
    i = 0
    theta_history.append(ini_theta)

    while i &lt; n_iters:
        gradient = get_der(theta, X_b, y)
        last_theta = theta
        theta = theta - eta * gradient
        theta_history.append(theta)

        if abs(loss_fun(theta, X_b, y) - loss_fun(last_theta, X_b, y)) &lt; eps:
            break

        i += 1

    return theta</code></pre><p>Try it!</p><pre><code class="lang-python">%%time
X_b = np.hstack([np.ones([len(X), 1]), X])
initial_theta = np.zeros(X_b.shape[1])
eta = 0.001

b, a = gradient_descent(X_b, y, initial_theta, eta)  # y = 3x + 4
b, a  # (3.9946613793913204, 3.029663997668306)</code></pre><p>对于上面的$\nabla J$，我们可以进一步简化：</p><p>$$
\begin{equation*}
\begin{split}
\nabla J &amp;= 
\frac{2}{m}
\begin{bmatrix}
  X_b^{(1)}\theta -y^{(1)},&amp;  X_b^{(2)}\theta -y^{(2)},&amp;  \dots,&amp;  X_b^{(m)}\theta -y^{(m)}
\end{bmatrix}
\begin{bmatrix}
  X_0^{(1)}&amp;  X_1^{(1)}&amp;  \dots&amp; X_n^{(1)} \\
  X_0^{(2)}&amp;  X_1^{(2)}&amp;  \dots&amp; X_n^{(2)} \\
  \dots &amp;  \dots &amp;  \ddots &amp; \vdots  \\
  X_0^{(m)}&amp;  X_1^{(m)}&amp;  \dots&amp; X_n^{(m)} \\
\end{bmatrix} \\
&amp;=\frac{2}{m} \cdot (X_b\theta - y)^T \cdot X_b \\
&amp;=\frac{2}{m} \cdot X_b^T  \cdot (X_b\theta - y)
\end{split}
\end{equation*}
$$</p><blockquote><p>其中$X_0$为全为1的列向量。</p></blockquote><p>那么我们的求导函数就可以进一步优化：</p><pre><code class="lang-python">def get_der(theta, X_b, y):
    return X_b.T.dot(X_b.dot(theta) - y) * 2 / len(X_b)</code></pre><h2 id="toc_292">五、归一化一定要记得</h2><p>使用波士顿房价数据集来验证我们上面实现的梯度下降：</p><p>加载数据：</p><pre><code class="lang-python">data_url = &quot;http://lib.stat.cmu.edu/datasets/boston&quot;
raw_df = pd.read_csv(data_url, sep=&quot;\s+&quot;, skiprows=22, header=None)
data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
target = raw_df.values[1::2, 2]</code></pre><p>过滤数据：</p><pre><code class="lang-python">X, y = data, target
X = X[y &lt; 50]
y = y[y &lt; 50]
X.shape, y.shape</code></pre><p>为特征数据矩阵加上一列：</p><pre><code class="lang-python">X_b = np.hstack([np.ones([len(X), 1]), X])</code></pre><p>划分数据集：</p><pre><code class="lang-python"># Split the Feature Dataset and Label Dataset
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test, = train_test_split(X_b, y, test_size=0.3, random_state=666)
X_train.shape, X_test.shape, y_train.shape, y_test.shape</code></pre><p>梯度下降：</p><pre><code class="lang-python">%%time
initial_theta = np.zeros(X_train.shape[1])
eta = 0.001

gradient_descent(X_train, y_train, initial_theta, eta)</code></pre><p>这个时候我们运行代码，会发现提示<code>Overflow</code>溢出错误：</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305221500263.png-wm04#vwid=1727&vhei=719" src="https://image.manyacan.com/202305221500263.png-wm04#vwid=1727&vhei=719"></figure></p><p>这是因为，当数据集中存在多列数据，且部分列数据的数量级非常大。<code>eta</code>如果设置的稍微一点点大，就会导致在计算部分列的导数时不收敛，进而导致溢出错误。</p><p>解决上面的问题有两种办法，第一就是我们手动设置一个极小的<code>eta=1e-6</code>，这样再次运行就不错报错了：</p><pre><code class="lang-python">calc_theta = gradient_descent(X_train, y_train, initial_theta, eta=1e-6)
y_predict = X_test.dot(calc_theta)

from sklearn.metrics import r2_score

r2_score(y_test, y_predict) # 0.30594186189467965</code></pre><p>虽然不再报错，但是我们发现，梯度下降求得的结果，R方只有0.306，这是完全不可用的。</p><p>接下来我们尝试增大迭代次数：</p><pre><code class="lang-python">%%time
calc_theta = gradient_descent(X_train, y_train, initial_theta, eta=1e-6, n_iters=1e6)
y_predict = X_test.dot(calc_theta)

from sklearn.metrics import r2_score

r2_score(y_test, y_predict)  # 0.7440227019523431</code></pre><p>当迭代次数上升至<code>n_iters=1e6</code>，R方有了显著的提高，但是程序耗时也大大增加。那么有没有什么方法可以既让耗时减小，同时又提升R方呢？</p><p>首先来分析出现该问题的根源——数据量过大，且数据表中有些列的数据量级高，进而导致<code>Overflow</code>溢出错误。这个问题，我们通过对数据进行归一化处理即可解决：</p><pre><code class="lang-python">from sklearn.preprocessing import StandardScaler

scale_scaler = StandardScaler()
scale_scaler.fit(X_train)

X_train_std = scale_scaler.transform(X_train)
X_test_std = scale_scaler.transform(X_test)
X_train_std = np.hstack([np.ones([len(X_train), 1]), X_train_std])
X_test_std = np.hstack([np.ones([len(X_test), 1]), X_test_std])</code></pre><p>归一化后，再次进行梯度下降：</p><pre><code class="lang-python">%%time
initial_theta = np.zeros(X_train_std.shape[1])
calc_theta = gradient_descent(X_train_std, y_train, initial_theta, eta=0.001)
y_predict = X_test_std.dot(calc_theta)

from sklearn.metrics import r2_score

r2_score(y_test, y_predict)  # 0.7983573625036819</code></pre><p>可以看到，虽然我们这次仍然设置了<code>eta=0.001</code>，但是却没有提示<code>Overflow</code>溢出错误，并且R方也得到了显著的提高，显著高于之前的<code>0.306</code>。说明对特征数据矩阵进行归一化处理可以解决梯度下降过程中的这个问题。</p><h2 id="toc_293">六、随机梯度下降法</h2><p>上面我们实现的过程中，每一次“下山”的过程中，都会对各个方向的路径进行求导，以便找出最陡峭的下山路径，这个过程被称为批量梯度下降法（Batch Gradient Descent）。然而实际情况中，由于数据集的量级都十分大（特征多代表下山的路径多），因此我们可以采用随机梯度下降法（Stochastic Gradient Descent）来进行优化。</p><p>所谓随机梯度下降法，就是在当前位置，我们只随机挑选几条路，然后看看这几条路的陡峭程度（求导），然后从这几条中选出最陡峭的进行“下山”。</p><p>有了想法，实现起来也就很简单了：</p><pre><code class="lang-python">def get_der(theta, X_b, y):
    rand_index = np.random.randint(len(X_b))
    X_b_i, y_i = X_b[rand_index], y[rand_index]
    # X_b_i, y_i
    return X_b_i.T.dot(X_b_i.dot(theta) - y_i) * 2</code></pre><p>上面的求导函数，我们每次只从一个维度（一个特征，即一条下山路线）计算其导数。</p><p>对于求梯度的函数，也需要更新一下：</p><pre><code class="lang-python">theta_history = []
def gradient_descent(X_b, y, ini_theta, eta, n_iters=1e4, eps=1e-8):
    theta = ini_theta
    i = 0
    theta_history.append(ini_theta)
    t_0, t_1 = 5, 50

    def learning_rate(t):
        return t_0 / (t + t_1)

    while i &lt; n_iters:
        gradient = get_der(theta, X_b, y)
        theta = theta - learning_rate(i) * gradient
        theta_history.append(theta)
        i += 1

    return theta</code></pre><p>这里我们对学习率进行了动态计算，当刚开始“下山”的时候，“步子”迈大一点，而快到山底时，每次“只走一小步”。这是因为，采用随机梯度下降的时候，由于每次只计算了一个方向的梯度，可能在下降到山底的时候，所计算下一步方向的梯度非常大，即沿这个方向可能不再是下山，而是上山了，并不能保证这个方向真是最优的。</p><p>而且，采用随机梯度下降的过程因为计算量大大减小，因此我们可以只管“下山”，而不用像以前一样每“下去”一步，就要计算这一步和上一步相比，走了多远，如果距离足够小，就说明已经到了山底。</p><p><figure><img class="" alt="" data-src="https://image.manyacan.com/202305212047790.png-wm04#vwid=1383&vhei=843" src="https://image.manyacan.com/202305212047790.png-wm04#vwid=1383&vhei=843"></figure></p><p>由上图中可以看出来，随机梯度下降并不像批量梯度下降，每一步的下一步都指向梯度最大（下降最快）的方向，但是其整体还是慢慢下山的。</p><h2 id="toc_294">七、在scikit-learn中使用梯度下降</h2><pre><code class="lang-python">from sklearn.linear_model import SGDRegressor

sgd_reg = SGDRegressor()
sgd_reg.fit(X_train_std, y_train)
sgd_reg.score(X_test_std, y_test)</code></pre><blockquote><h5 id="toc_295">注意 / WARNING</h5><p>在<code>scikit-learn</code>中，随机梯度下降类被封装到<code>linear_model</code>包中，这说明其只可以用来计算线性相关的问题</p></blockquote><pre><code class="lang-python">sgd_reg = SGDRegressor(max_iter=100)
sgd_reg.fit(X_train_std, y_train)
sgd_reg.score(X_test_std, y_test)</code></pre>
]]></content:encoded>
<slash:comments>2</slash:comments>
<comments>https://blog.manyacan.com/archives/2036/#comments</comments>
<wfw:commentRss>https://blog.manyacan.com/feed/archives/2036/</wfw:commentRss>
</item>
</channel>
</rss>